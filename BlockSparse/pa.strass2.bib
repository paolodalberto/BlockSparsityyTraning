@inproceedings{ChanGGHL2010,
title = {Evaluating Online Ad Campaigns in a Pipeline: Causal Models at Scale},
author  = {David Chan and Rong Ge and Ori Gershony and Tim Hesterberg and Diane Lambert},
year  = 2010,
booktitle = {Proceedings of ACM SIGKDD 2010},
pages = {7-15}
}

International Economic Review
Vol. 1, No. 2 (May, 1960), pp. 79-106

@Article{Mandelbrot:1960:PLL,
  author =       "Beno{\^\i}t Mandelbrot",
  title =        "The {Pareto--Levy} law and the distribution of
                 income",
  journal =      "International Economic Review",
  volume =       "1",
  number =       "2",
  pages =        "79--106",
  month =        "May",
  year =         "1960",
  CODEN =        "INERAE",
  ISSN =         "0020-6598 (print), 1468-2354 (electronic)",
  ISSN-L =       "0020-6598",
  bibdate =      "Wed Nov 23 11:07:01 2011",
  bibsource =    "http://www.math.utah.edu/pub/tex/bib/benfords-law.bib",
  URL =          "http://www.ingenta.com/journals/browse/bpl/iere",
  acknowledgement = ack-nhfb,
  fjournal =     "International Economic Review",
  journal-URL =  "http://www.jstor.org/journal/inteeconrevi",
}


@inproceedings{BarajasKAFHA2012,
 author = {Barajas, Joel and Kwon, Jaimie and Akella, Ram and Flores, Aaron and Holtan, Marius and Andrei, Victor},
 title = {Marketing Campaign Evaluation in Targeted Display Advertising},
 booktitle = {Proceedings of the Sixth International Workshop on Data Mining for Online Advertising and Internet Economy},
 series = {ADKDD '12},
 year = {2012},
 isbn = {978-1-4503-1545-6},
 location = {Beijing, China},
 pages = {5:1--5:7},
 articleno = {5},
 numpages = {7},
 url = {http://doi.acm.org/10.1145/2351356.2351361},
 doi = {10.1145/2351356.2351361},
 acmid = {2351361},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {causal attribution, marketing, online targeted advertising},
} 




@inproceedings{WangLMTYP2014,
 author = {Wang, Pengyuan and Liu, Yechao and Meytlis, Marsha and Tsao, Han-Yun and Yang, Jian and Huang, Pei},
 title = {An Efficient Framework for Online Advertising Effectiveness Measurement and Comparison},
 booktitle = {Proceedings of the 7th ACM International Conference on Web Search and Data Mining},
 series = {WSDM '14},
 year = {2014},
 isbn = {978-1-4503-2351-2},
 location = {New York, New York, USA},
 pages = {163--172},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2556195.2556235},
 doi = {10.1145/2556195.2556235},
 acmid = {2556235},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {advertising, causal inference, feature selection, gradient boosting trees, parallel computing, propensity score, subsampling},
} 


 



@ARTICLE{DAlbertoDD2012,
   author = {Paolo {D'A}lberto and Chris Drome and Ali Dasdan},
    title = "{Non-Parametric Methods Applied to the N-Sample Series Comparison}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1205.1880},
 primaryClass = "stat.CO",
 keywords = {Statistics - Computation, G.3},
     year = 2012,
    month = may,
   url = {http://adsabs.harvard.edu/abs/2012arXiv1205.1880D},
 note = {Provided by the SAO/NASA Astrophysics Data System}
}


@Unpublished{Meso,
  author = 	 {Apach Open Source},
  title = 	 {Meso},
  howpublished = "\url{http://mesos.apache.org/}",
  OPTkey = 	 {},
  OPTmonth = 	 {},
  OPTyear = 	 {},
  OPTannote = 	 {}
}

@Unpublished{Spark,
  author = 	 {ampLab and Apache Open Source},
  title = 	 {Spark},
  howpublished="\url{https://spark.apache.org/}",
  OPTmonth = 	 {},
  OPTyear = 	 {},
  OPTannote = 	 {}
}

@article{Hartigan1979,
  added-at = {2011-01-11T13:34:58.000+0100},
  author = {Hartigan, J. A. and Wong, M. A.},
  biburl = {http://www.bibsonomy.org/bibtex/20399e12b4e411a03eda28ebaf11553ec/enitsirhc},
  interhash = {f32378f161e481db5375fe5164281ee9},
  intrahash = {0399e12b4e411a03eda28ebaf11553ec},
  journal = {JSTOR: Applied Statistics},
  keywords = {kmeans clustering},
  number = 1,
  pages = {100--108},
  timestamp = {2011-01-11T13:34:58.000+0100},
  title = {A k-means clustering algorithm},
  volume = 28,
  year = 1979
}


@article{Forgy1965,
  added-at = {2006-03-23T12:22:43.000+0100},
  author = {Forgy, E.},
  biburl = {http://puma.uni-kassel.de/bibtex/21e31409932ce91df646c4731350e1207/hotho},
  interhash = {c86383cba8cfe00d5e6ef200016aca3f},
  intrahash = {1e31409932ce91df646c4731350e1207},
  journal = {Biometrics},
  keywords = {clustering kmeans},
  number = 3,
  pages = {768-769},
  timestamp = {2006-03-23T12:22:43.000+0100},
  title = {Cluster Analysis of Multivariate Data: Efficiency versus Interpretability of Classification},
  volume = 21,
  year = 1965
}

@inproceedings{DAlbertoD2009,
  added-at = {2009-06-12T00:00:00.000+0200},
  author = {D'Alberto, Paolo and Dasdan, Ali},
  biburl = {http://www.bibsonomy.org/bibtex/2a72c4fe9d30689189eef96a1be2b10f4/dblp},
  booktitle = {SDM},
  date = {2009-06-12},
  description = {dblp},
  ee = {http://www.siam.org/proceedings/datamining/2009/dm09_063_dalbertop.pdf},
  interhash = {d0de34a39d144618d29f1dbf4af62c39},
  intrahash = {a72c4fe9d30689189eef96a1be2b10f4},
  keywords = {dblp},
  pages = {685-696},
  publisher = {SIAM},
  timestamp = {2009-06-12T00:00:00.000+0200},
  title = {Non-parametric Information-Theoretic Measures of One-Dimensional Distribution Functions from Continuous Time Series.},
  url = {http://dblp.uni-trier.de/db/conf/sdm/sdm2009.html#DAlbertoD09},
  year = 2009
}





@Book{MorganW2007,
  author = 	 {Stephen Morgan and Christopher Winship},
  ALTeditor = 	 {},
  title = 	 {Counterfactuals and Causal Inference: Methods and
                  Principles for Social Research},
  publisher = 	 {Cambridge},
  ISBN ={978-0-521-67193-4},
  year = 	 {2007}
}
@Book{GuoF2015,
  author = 	 {Shenyang Goo and Mark Fraser},
  ALTeditor = 	 {},
  title = 	 {Propensity Score Analysis: statistical MEthods and
                  Applications},
  publisher = 	 {SAGE},
  year = 	 {2014},
  ISBN ={978-1-4522-3500-4}
}

@article{Dawid2000,
  added-at = {2009-10-28T04:42:52.000+0100},
  author = {Dawid, A.P.},
  biburl = {http://www.bibsonomy.org/bibtex/2b9731accd31a993f8c9d66b64d187b1f/jwbowers},
  date-added = {2007-09-03 22:45:16 -0500},
  date-modified = {2007-09-03 22:45:16 -0500},
  interhash = {c3398f0cfce9a082ddc8e55eab4f5674},
  intrahash = {b9731accd31a993f8c9d66b64d187b1f},
  journal = {Journal of the American Statistical Association},
  keywords = {imported},
  note = {with discussion},
  pages = {407--448},
  timestamp = {2009-10-28T04:42:52.000+0100},
  title = {Causal Inference without Counterfactuals},
  volume = 95,
  year = 2000
}


@article{Dawid1979,
    author = {Dawid, A. P.},
    doi = {10.2307/2984718},
    issn = {00359246},
    journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
    keywords = {1979, statistics},
    number = {1},
    pages = {1--31},
    posted-at = {2008-09-21 20:37:54},
    priority = {2},
    publisher = {Blackwell Publishing for the Royal Statistical Society},
    title = {{Conditional Independence in Statistical Theory}},
    url = {http://dx.doi.org/10.2307/2984718},
    volume = {41},
    year = {1979}
}

@article{RosenbaumR1983,
  added-at = {2009-10-28T04:42:52.000+0100},
  author = {Rosenbaum, Paul R. and Rubin, Donald B.},
  biburl = {http://www.bibsonomy.org/bibtex/28676e50c9e8dba1ac97e5a844d2fd34d/jwbowers},
  date-added = {2007-09-03 22:45:16 -0500},
  date-modified = {2007-09-03 22:45:16 -0500},
  interhash = {d36b10d9c0e12f8398076b5f4fb410d6},
  intrahash = {8676e50c9e8dba1ac97e5a844d2fd34d},
  journal = {Biometrika},
  keywords = {Discriminant Matched matching; sampling},
  local-url = {file://localhost/Users/jwbowers/Documents/Papers/Rosenbaum/RoseRubi1983.pdf},
  pages = {41--55},
  timestamp = {2009-10-28T04:42:52.000+0100},
  title = {The Central Role of the Propensity Score in Observational Studies for Causal Effects},
  volume = 70,
  year = 1983
}
@article{Rubin1976c,
  added-at = {2009-10-28T04:42:52.000+0100},
  author = {Rubin, D. B.},
  biburl = {http://www.bibsonomy.org/bibtex/2e08ecb54ff6381fdd3f369b76aaac881/jwbowers},
  date-added = {2007-09-03 22:45:16 -0500},
  date-modified = {2007-09-03 22:45:16 -0500},
  interhash = {3d515199a2899c751a3d28cec7609635},
  intrahash = {e08ecb54ff6381fdd3f369b76aaac881},
  journal = {Biometrics},
  keywords = {Discriminant Matched Non-randomized Observational Subsampling; function sampling; study;},
  pages = {109--120},
  timestamp = {2009-10-28T04:42:52.000+0100},
  title = {Multivariate Matching Methods That Are Equal Percent Bias Reducing. {I}: {S}ome Examples (Corr: {V}32 P955)},
  volume = 32,
  year = 1976
}

@article{Rubin1976b,
  added-at = {2009-10-28T04:42:52.000+0100},
  author = {Rubin, D. B.},
  biburl = {http://www.bibsonomy.org/bibtex/242f0a459f0dab04d2ee2721c7f000ec8/jwbowers},
  date-added = {2007-09-03 22:45:16 -0500},
  date-modified = {2007-09-03 22:45:16 -0500},
  interhash = {7c086e3c26cebf2e452a9c3e0c06a13d},
  intrahash = {42f0a459f0dab04d2ee2721c7f000ec8},
  journal = {Biometrics},
  keywords = {Controlling Matched Non-randomized Observational Optimization; Subsampling bias; sampling; study;},
  pages = {121--132},
  timestamp = {2009-10-28T04:42:52.000+0100},
  title = {Multivariate Matching Methods That Are Equal Percent Bias Reducing. {I}I: {M}aximums on Bias Reduction for Fixed Sample Sizes (Corr: {V}32 P955)},
  volume = 32,
  year = 1976
}

@article{RosenbaumR1985,
  abstract = {Matched sampling is a method for selecting units from a
		  large reservoir of potential controls to produce a control
		  group of modest size that is similar to a treated group
		  with respect to the distribution of observed covariates. We
		  illustrate the use of multivariate matching methods in an
		  observational study of the effects of prenatal exposure to
		  barbiturates on subsequent psychological development. A key
		  idea is the use of the propensity score as a distinct
		  matching variable.},
  added-at = {2009-10-28T04:42:52.000+0100},
  author = {Rosenbaum, Paul R. and Rubin, Donald B.},
  biburl = {http://www.bibsonomy.org/bibtex/2a4308959c39bf41e9792aa8b0de4dc66/jwbowers},
  citeulike-article-id = {147911},
  date-added = {2007-09-03 22:45:16 -0500},
  date-modified = {2007-09-03 22:45:16 -0500},
  interhash = {6697f3edfa9c16a621910deb66a2eb4a},
  intrahash = {a4308959c39bf41e9792aa8b0de4dc66},
  journal = {The American Statistician},
  keywords = {statistics},
  number = 1,
  opturl = {http://links.jstor.org/sici?sici=0003-1305%28198502%2939%3A1%3C33%3ACACGUM%3E2.0.CO%3B2-9},
  pages = {33--38},
  priority = {2},
  timestamp = {2009-10-28T04:42:52.000+0100},
  title = {Constructing a Control Group Using Multivariate Matched Sampling Methods That Incorporate the Propensity Score},
  volume = 39,
  year = 1985
}



@Article{KurorP2014,
  author = 	 {Manabu Kuroki and Judea Pearl},
  title = 	 {Measurement bias and effect restoration in causal inference},
  journal = 	 {Biometrika},
  year = 	 {2014},
  OPTkey = 	 {},
  volume = 	 {101},
  number = 	 {2},
  pages = 	 {423--437},
  month = 	 {Jun},
  doi = {http://dx.doi.org/10.1093/biomet/ast066},
  OPTnote = 	 {},
  OPTannote = 	 {}
}

@Article{HansenK2006,
    author = {Ben B. Hansen and Stephanie Olsen Klopfer},
    title = {Optimal full matching and related designs via network
      flows},
    keywords = {matched sampling, minimum cost flow, nonrandom
      treatment assignment, observational study, quasiexperiment,
      subclassification},
    journal = {Journal of Computational and Graphical Statistics},
    volume = {15},
    number = {3},
    pages = {609--627},
    year = {2006},
  }


                  

@Article{IacusKP2012,
  author = 	 {Stefano M. Iacus and Gary King and Giuseppe Porro},
  title = 	 {Causal Inference without Balance Checking:
Coarsened Exact Matching},
  journal = 	 {Political Analysis},
  year = 	 {2012},
  OPTkey = 	 {},
  volume = 	 {20},
  OPTnumber = 	 {},
  pages = 	 {1-24},
  doi = 	 {10.1093/pan/mpr013},
  OPTnote = 	 {},
  OPTannote = 	 {}
}

@Article{Griffin2014,
  author = 	 {Griffin, Beth Ann and  Daniel F. McCaffrey and Craig Martin and Lane F. Burgette and  Daniel Almirall and Rajeev Ramchand and Lisa H. Jaycox},
  title = 	 {Toolkit for Weighting and Analysis of Nonequivalent Groups (TWANG)},
  journal = 	 {RAND Corporation},
  year = 	 {2014},
  URL = 	 {http://www.rand.org/pubs/tools/TL136},
}

@article {HoImaKin07,
	title = {Matching as Nonparametric Preprocessing for Reducing Model Dependence in Parametric Causal Inference},
	journal = {Political Analysis},
	volume = {15},
	year = {2007},
	pages = {199{\textendash}236},
	abstract = {<p>Although published works rarely include causal estimates from more than a few model specifications, authors usually choose the presented estimates from numerous trial runs readers never see. Given the often large variation in estimates across choices of control variables, functional forms, and other modeling assumptions, how can researchers ensure that the few estimates presented are accurate or representative? How do readers know that publications are not merely demonstrations that it is <i>possible</i> to find a specification that fits the author{\textquoteright}s favorite hypothesis? And how do we evaluate or even define statistical properties like unbiasedness or mean squared error when no unique model or estimator even exists? Matching methods, which offer the promise of causal inference with fewer assumptions, constitute one possible way forward, but crucial results in this fast-growing methodological literature are often grossly misinterpreted. We explain how to avoid these misinterpretations and propose a unified approach that makes it possible for researchers to preprocess data with matching (such as with the easy-to-use software we offer) and then to apply the best parametric techniques they would have used anyway. This procedure makes parametric models produce more accurate and considerably less model-dependent causal inferences.</p>
},
	author = {Daniel Ho and Kosuke Imai and Gary King and Elizabeth Stuart}
}



  @Article{Sekhon2011,
    title = {Multivariate and Propensity Score Matching Software with
      Automated Balance Optimization: The {Matching} Package for {R}},
    author = {Jasjeet S. Sekhon},
    journal = {Journal of Statistical Software},
    year = {2011},
    volume = {42},
    number = {7},
    pages = {1--52},
    url = {http://www.jstatsoft.org/v42/i07/},
  }


  @Article{SekhonG2012,
    title = {A Matching Method For Improving Covariate Balance in
      Cost-Effectiveness Analyses},
    author = {Jasjeet Singh Sekhon and Richard D. Grieve},
    journal = {Health Economics},
    volume = {21},
    number = {6},
    pages = {695--714},
    year = {2012},
  }


@techreport{DehejiaW1998,
 title = "Propensity Score Matching Methods for Non-experimental Causal Studies",
 author = "Rajeev H. Dehejia and Sadek Wahba",
 institution = "National Bureau of Economic Research",
 type = "Working Paper",
 series = "Working Paper Series",
 number = "6829",
 year = "1998",
 month = "December",
 doi = {10.3386/w6829},
 URL = "http://www.nber.org/papers/w6829",
 abstract = {This paper considers causal inference and sample selection bias in non-experimental settings in which: (i) few units in the non-experimental comparison group are comparable to the treatment units, and (ii) selecting a subset of comparison units similar to the treatment units is difficult because units must be compared across a high-dimensional set of pre-treatment characteristics. We propose the use of propensity score matching methods and implement them using data from the NSW experiment.  Following Lalonde (1986), we pair the experimental treated units with non-experimental comparison units from the CPS and PSID and compare the estimates of the treatment effect obtained using our methods to the benchmark results from the experiment.  We show that the methods succeed in focusing attention on the small subset of the comparison units comparable to the treated units and, hence, in alleviating the bias due to systematic differences between the treated and comparison units.},
}

@Article{DehejiaW2002,
  author = 	 {Rajeev H. Dehejia and Sadek Wahba},
  title = 	 {Propensity Score-Matching Methods for Nonexperimental Causal Studies},
  journal = 	 {The Review of Economics and Statistics},
  year = 	 {2002},
  OPTkey = 	 {},
  volume = 	 {84},
  number = 	 {1},
  pages = 	 {151--161},
  month = 	 {Feb},
  URL = 	 {http://www.jstor.org/stable/3211745},
  OPTannote = 	 {}
}

@Book{Wald1947,
  author = 	 {Abraham Wald},
  ALTeditor = 	 {},
  title = 	 {Sequential Analysis},
  publisher = 	 {Dover},
  year = 	 {1947},
  isbn = {0-486-61579-0},
  series = 	 {Advanced Mathematics},
  OPTaddress = 	 {},
  OPTedition = 	 {},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {}
}

@inproceedings{LeeJD2013,
 author = {Lee, Kuang-Chih and Jalali, Ali and Dasdan, Ali},
 title = {Real Time Bid Optimization with Smooth Budget Delivery in Online Advertising},
 booktitle = {Proceedings of the Seventh International Workshop on Data Mining for Online Advertising},
 series = {ADKDD '13},
 year = {2013},
 isbn = {978-1-4503-2323-9},
 location = {Chicago, Illinois},
 pages = {1:1--1:9},
 articleno = {1},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/2501040.2501979},
 doi = {10.1145/2501040.2501979},
 acmid = {2501979},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {algorithmic advertising, bid optimization, budget pacing, computational advertising, online advertising, scalable algorithms, smooth budget delivery},
} 

@inproceedings{LeeODW2012,
 author = {Lee, Kuang-chih and Orten, Burkay and Dasdan, Ali and Li, Wentong},
 title = {Estimating Conversion Rate in Display Advertising from Past Erformance Data},
 booktitle = {Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '12},
 year = {2012},
 isbn = {978-1-4503-1462-6},
 location = {Beijing, China},
 pages = {768--776},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/2339530.2339651},
 doi = {10.1145/2339530.2339651},
 acmid = {2339651},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {action rate estimation, algorithemic advertising, computational advertising, logistic regression},
} 
 


@inproceedings{BadinBDN10,
  author    = {Matthew Badin and
               Lubomir Bic and
               Michael B. Dillencourt and
               Alexandru Nicolau},
  title     = {Pretty Good Accuracy in Matrix Multiplication with {GPU}s},
  booktitle = {ISPDC},
  year      = {2010},
  pages     = {49-55},
  ee        = {http://doi.ieeecomputersociety.org/10.1109/ISPDC.2010.12},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}


@INPROCEEDINGS{JunjieRS2011,
author={Junjie Li and Ranka, S. and Sahni, S.},
booktitle={Parallel and Distributed Systems (ICPADS), 2011 IEEE 17th International Conference on},
title={Strassen's Matrix Multiplication on GPUs},
year={2011},
pages={157-164},
keywords={computer graphic equipment;coprocessors;mathematics computing;matrix multiplication;CUBLAS 3.0;NVIDIA C1060 GPU;Strassen matrix multiplication;Winograd variant;integer GPU;sgemm;Complexity theory;Graphics processing unit;Kernel;Matrix decomposition;Memory management;Vectors;CUDA;GPU;Strassen's algorithm;Winograd's variant;accuracy;matrix multiplication},
doi={10.1109/ICPADS.2011.130},
ISSN={1521-9097},}



@article{Castaldoo2008,
 author = {Castaldo, Anthony M. and Whaley, R. Clint and Chronopoulos, Anthony T.},
 title = {Reducing Floating Point Error in Dot Product Using the Superblock Family of Algorithms},
 journal = {SIAM J. Sci. Comput.},
 issue_date = {November 2008},
 volume = {31},
 number = {2},
 month = dec,
 year = {2008},
 issn = {1064-8275},
 pages = {1156--1174},
 numpages = {19},
 url = {http://dx.doi.org/10.1137/070679946},
 doi = {10.1137/070679946},
 acmid = {1654172},
 publisher = {Society for Industrial and Applied Mathematics},
 address = {Philadelphia, PA, USA},
 keywords = {ATLAS, BLAS, dot product, error analysis, inner product},
} 


@inproceedings{Badin2011,
 author = {Badin, Matthew and D'Alberto, Paolo and Bic, Lubmir and Dillencourt, Michael and Nicolau, Alexandru},
 title = {Improving the Accuracy of High Performance BLAS Implementations Using Adaptive Blocked Algorithms},
 booktitle = {Proceedings of the 2011 23rd International Symposium on Computer Architecture and High Performance Computing},
 series = {SBAC-PAD '11},
 year = {2011},
 isbn = {978-0-7695-4573-8},
 pages = {120--127},
 numpages = {8},
 url = {http://dx.doi.org/10.1109/SBAC-PAD.2011.21},
 doi = {10.1109/SBAC-PAD.2011.21},
 acmid = {2085254},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {Recursive Matrix Multiply, Pairwise Summation, Hybrid Matrix Multiply},
} 

@article{DAlbertoBN2011,
 author = {D'alberto, Paolo and Bodrato, Marco and Nicolau, Alexandru},
 title = {Exploiting parallelism in matrix-computation kernels for symmetric multiprocessor systems: Matrix-multiplication and matrix-addition algorithm optimizations by software pipelining and threads allocation},
 journal = {ACM Trans. Math. Softw.},
 issue_date = {November 2011},
 volume = {38},
 number = {1},
 month = dec,
 year = {2011},
 issn = {0098-3500},
 pages = {2:1--2:30},
 articleno = {2},
 numpages = {30},
 url = {http://doi.acm.org/10.1145/2049662.2049664},
 doi = {10.1145/2049662.2049664},
 acmid = {2049664},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Matrix multiplications, fast algorithms, parallelism, software pipeline},
} 




@ARTICLE{Winograd1968,
author={Winograd, S.},
journal={Computers, IEEE Transactions on},
title={A New Algorithm for Inner Product},
year={1968},
volume={C-17},
number={7},
pages={693-694},
keywords={Index terms—Algorithm, inner product, matrix inversion, matrix multiplication, solution of linear equations.;Counting circuits;Equations;Helium;Logic design;Switches;Switching converters;Vectors;Index terms—Algorithm, inner product, matrix inversion, matrix multiplication, solution of linear equations.},
doi={10.1109/TC.1968.227420},
ISSN={0018-9340},}


@article{Miller1975,
author = {Miller, W.},
title = {Computational Complexity and Numerical Stability},
journal = {SIAM Journal on Computing},
volume = {4},
number = {2},
pages = {97-107},
year = {1975},
doi = {10.1137/0204009},

URL = {http://epubs.siam.org/doi/abs/10.1137/0204009},
eprint = {http://epubs.siam.org/doi/pdf/10.1137/0204009}
}



@article{BiniL1980,
year={1980},
issn={0029-599X},
journal={Numerische Mathematik},
volume={36},
number={1},
doi={10.1007/BF01395989},
title={Stability of fast algorithms for matrix multiplication},
url={http://dx.doi.org/10.1007/BF01395989},
publisher={Springer-Verlag},
keywords={AMS (MOS): 15A63; CR: 5.14},
author={Bini, Dario and Lotti, Grazia},
pages={63-72},
language={English}
}


@InProceedings{Bodrato:ISSAC2010,
 author =       {Bodrato, Marco},
 title =        {A {S}trassen-like matrix multiplication suited for
                 squaring and higher power computation},
 OPTpages =     {},
 note =         {\url{http://bodrato.it/papers/#ISSAC2010}},
 OPTannote =    {to appear},

 booktitle =    {ISSAC '10: Proceedings of the 2010 international symposium
on Symbolic and algebraic computation},
 OPTeditor =    {},
 year =         {2010},
 month =        {July},
 location =     {Munich, Germany},
 publisher =    {ACM},
 address =      {New York, NY, USA}
}




@InProceedings{SongMD2006,
  author = 	 {F. Song and  S. Moore and J. Dongarra},
  title = 	 {Experiments with Strassen's Algorithm: from Sequential to Parallel},
  OPTcrossref =  {},
  OPTkey = 	 {},
  booktitle = { International Conference on Parallel and Distributed Computing and Systems (PDCS06)},
  OPTpages = 	 {},
  year = 	 {2006},
  OPTeditor = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  address = 	 {Dallas, Texas},
  month = 	 {November},
  OPTorganization = {},
  OPTpublisher = {},
  OPTnote = 	 {},
  OPTannote = 	 {}
}

@book{Priestley1981,
 author = {M.B. Priestley},
 title = {Spectral Analysis and Time Series},
 year = {1981},
 isbn = {0-12-564922-3},
 publisher = {Academic Press Inc},
 address = {111 Fifth Ave, New York, New York 10003},
 }

 @book{Bernoulli1713,
  author = {Jacok Bernoulli},
  title = {Ars conjectandi, opus posthumum. Accedit Tractatus de seriebus infinitis, et epistola gallicé scripta de ludo pilae reticularis},
  year = {1713},
  oclc = {7073795},
  publisher = {Basileae, impensis Thurnisiorum, fratru}
   }

@book{McCullaghN1989,
  title={Generalized Linear Models, Second Edition},
  author={P. McCullagh and John A. Nelder},
  isbn={9780412317606},
  lccn={99013896},
  series={Chapman \& Hall/CRC Monographs on Statistics \& Applied Probability},
  year={1989},
  publisher={Taylor \& Francis}
}

@book{JohnsonKK1993,
    author = {Johnson, Norman L. and Kotz, Samuel and Kemp, Adrienne W.},
    citeulike-article-id = {11157253},
    day = {22},
    doi = {10.1002/0471715816.ch6},
    edition = {2},
    howpublished = {Hardcover},
    isbn = {0471548979},
    keywords = {handbook, probability},
    month = feb,
    posted-at = {2012-08-30 15:56:56},
    priority = {3},
    publisher = {Wiley-Interscience},
    title = {Univariate Discrete Distributions (Wiley Series in Probability and Statistics)},
    url = {http://dx.doi.org/10.1002/0471715816.ch6},
    year = {1993}
}

@book{BrockwellD1991,
 author = {P.J. Brockwell and R.A. Davis},
 title = {Time Series: Theory and Methods},
 year = {2006},
 isbn = {0-387-97429-5},
 publisher = {Springer},
 address = {Spring Stree 233, New York, New York 10013},
 }



@book{Jaja1992,
 author = {J. J\'{a}J\'{a}},
 title = {An introduction to parallel algorithms},
 year = {1992},
 isbn = {0-201-54856-9},
 publisher = {Addison Wesley Longman Publishing Co., Inc.},
 address = {Redwood City, CA, USA},
 }

@inproceedings{dalbertoA2007,
 author = {P. D'Alberto and A. Nicolau},
 title = {Adaptive Strassen's matrix multiplication},
 booktitle = {ICS '07: Proceedings of the 21st annual international conference on Supercomputing},
 year = {2007},
 isbn = {978-1-59593-768-1},
 pages = {284--292},
 location = {Seattle, Washington},
 doi = {http://doi.acm.org/10.1145/1274971.1275010},
 publisher = {ACM},
 address = {New York, NY, USA},
 }

@inproceedings{NicolauKG2009,
 author = {A. Nicolau and  G. Li and A. Kejariwal},
 title = {Techniques for Efficient Placement of Synchronization Primitives},
 booktitle = {PPoPP '09: 14th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
 year = {2009},
 location = {North Carolina}
 }

@Article{DAlberto:2009:AWM,
  author =       "P. D'Alberto and A. Nicolau",
  title =        "Adaptive {Winograd's} Matrix Multiplications",
  journal =      "{ACM} Transactions on Mathematical Software",
  volume =       "36",
  number =       "1",
  year      ="2009"
}

@article{Jean-GuillaumePC2009,
 author = {Dumas, Jean-Guillaume and Giorgi, Pascal and Pernet, Cl\'{e}ment},
 title = {Dense Linear Algebra over Word-Size Prime Fields: the {FFLAS} and {FFPACK} Packages},
 Journal = {ACM Trans. Math. Softw.},
 volume = {35},
 number = {3},
 year = {2008},
 issn = {0098-3500},
 pages = {1--42},
 doi = {http://doi.acm.org/10.1145/1391989.1391992},
 publisher = {ACM},
 address = {New York, NY, USA},
 }

@inproceedings{BoyerDPZ09,
  author    = {Brice Boyer and
               Jean-Guillaume Dumas and
               Cl{\'e}ment Pernet and

               Wei Zhou},
  title     = {Memory efficient scheduling of {S}trassen-{W}inograd's matrix
               multiplication algorithm},
  booktitle = {ISSAC},
  year      = {2009},
  pages     = {55-62},

  ee        = {http://doi.acm.org/10.1145/1576702.1576713},
  bibsource = {DBLP, http://dblp.uni-trier.de}

}


@inproceedings{DongarraPRV08,
  author    = {J. Dongarra and
               J.F. Pineau and
               Y. Robert and
               F. Vivien},
  title     = {Matrix product on heterogeneous master-worker platforms},
  booktitle = {PPOPP},
  year      = {2008},
  pages     = {53-62},
  ee        = {http://doi.acm.org/10.1145/1345206.1345217},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}



@inproceedings{DongarraPRSV07,
  author    = {J. Dongarra and
               J.F. Pineau and
               Y. Robert and
               Z. Shi and
               F. Vivien},
  title     = {Revisiting Matrix Product on Master-Worker Platforms},
  booktitle = {IPDPS},
  year      = {2007},
  pages     = {1-8},
  ee        = {http://dx.doi.org/10.1109/IPDPS.2007.370466},
  crossref  = {DBLP:conf/ipps/2007},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}


@InProceedings{AggarwalACS87,
  author = 	 {A. Aggarwal and B. Alpern and A.K. Chandra and  M. Snir},
  title = 	 {A model for hierarchical memory},
  booktitle = {Proceedings of 19th Annual ACM Symposium on the Theory of Computing},
  pages = 	 {305-314},
  year = 	 {1987},
  address = 	 {New York},
  }


@InProceedings{AggarwalCS87,
  author = 	 {  A. Aggarwal and A.K. Chandra  and M. Snir},
  title = 	 {Hierarchical memory with block transfer},
  booktitle = {28th Annual Symposium on Foundations of Computer Science},
  pages = 	 { 204-216},
  year = 	 {1987},
  address = 	 {Los Angeles, California},
  month = 	 {October},
  }
@Book{AndersonBBDDDGHMOS95,
  author = 	 {E. Anderson and Z. Bai and C. Bischof and J. Demmel
        J. Dongarra and J. DuCroz and A. Greenbaum and S. Hammarling and A. McKenney
        and S. Ostrouchov and D. Sorensen},
  title = 	 {{LAPACK} User' Guide, Release 2.0},
  publisher = 	 {SIAM},
  year = 	 {1995},
  edition = 	 {2},
}

@inproceedings{BaileyG88,
 author = {D. H. Bailey and H. R. P. Gerguson},
 title = {A {S}trassen-{N}ewton algorithm for high-speed parallelizable matrix inversion},
 booktitle = {Supercomputing '88: Proceedings of the 1988 ACM/IEEE conference on Supercomputing},
 year = {1988},
 isbn = {0-8186-0882-X},
 pages = {419--424},
 location = {Orlando, Florida, United States},
 publisher = {IEEE Computer Society Press},
 }

@article{BaileyLS1990,
 author = {D. Bailey and K. Lee and H. Simon},
 title = {Using Strassen's algorithm to accelerate the solution of linear systems},
 journal = {J. Supercomput.},
 volume = {4},
 number = {4},
 year = {1990},
 issn = {0920-8542},
 pages = {357--371},
 doi = {http://dx.doi.org/10.1007/BF00129836},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 }
@Article{BientinesiDv2005,
  author = 	 {P. Bientinesi and  I.S. Dhillon, and R.A. van de Geijn},
  title = 	 {A Parallel Eigensolver for Dense Symmetric Matrices Based on Multiple Relatively Robust Representations},
  journal = 	 {SIAM Journal on Scientific Computing},
  year = 	 {2005},
  volume = 	 {27},
  number = 	 {1},
  pages = 	 {43--66},
}

@InProceedings{BilardiDN01,
  author = 	 {G. Bilardi and P. D'Alberto and A. Nicolau },
  title = 	 {Fractal matrix multiplication: a case study on portability of 
                  cache performance},
  booktitle = {Workshop on Algorithm Engineering 2001},
  year = 	 {2001},
  address = 	 {Aarhus, Denmark},
  }

@InProceedings{BilmesACD97,
  author = 	 { J. Bilmes and K. Asanovic and C. Chin and J. Demmel},
  title = 	 {Optimizing matrix multiply using {PH}i{PAC}: a portable, 
                  high-performance, {A}nsi {C} coding methodology},
  booktitle = {International Conference on Supercomputing},
  year = 	 {1997},
  month = 	 {July},
  }
@TechReport{Brent1970B,
  author = 	 {R. P. Brent},
  title = 	 {Algorithms for matrix multiplication},
  institution =  {Stanford University},
  year = 	 {1970},

  number = 	 {TR-CS-70-157},
  month = 	 {Mar},
  doi = {http://web.comlab.ox.ac.uk/oucl/work/richard.brent/pd/rpb002i.pdf}

}


@Article{Brent1970,
  author = 	 {R. P. Brent},
  title = 	 {Error analysis of algorithms for matrix multiplication and triangular decomposition using {W}inograd's identity},
  journal = 	 {Numerische Mathematik},
  year = 	 {1970},
  volume = 	 {16},
  pages = 	 {145-156},
  doi = {http://web.comlab.ox.ac.uk/oucl/work/richard.brent/pd/rpb004.pdf},
}

@misc{CohnKSU2005,
	author = {H. Cohn   and R. Kleinberg and B. Szegedy   and C. Umans},
	citeulike-article-id = {402464},
	eprint = {math.GR/0511460},
	keywords = {algorithm algorithms combinatorics cs graph group-theory math mathematics matrix matrix-multiplication pre-print},
	month = {Nov},
	title = {Group-theoretic algorithms for matrix multiplication},
	url = {http://arxiv.org/abs/math.GR/0511460},
	year = {2005}
}

@InProceedings{CoppersmithW87,
  author = 	 { D. Coppersmith and S. Winograd},
  title = 	 { Matrix Multiplication via Arithmetic Progressions},
  booktitle = {Proceedings of the 19-th annual ACM conference on 
                  Theory of computing},
  pages = 	 {1-6},
  year  =        {1987},
  }

@inproceedings{DAlbertoN2007,
 author = {Paolo D'Alberto and Alexandru Nicolau},
 title = {Adaptive Strassen's matrix multiplication},
 booktitle = {ICS '07: Proceedings of the 21st annual international conference on Supercomputing},
 year = {2007},
 isbn = {978-1-59593-768-1},
 pages = {284--292},
 location = {Seattle, Washington},
 doi = {http://doi.acm.org/10.1145/1274971.1275010},
 publisher = {ACM},
 address = {New York, NY, USA},
 }



@InProceedings{DalbertoN2005a,
  author = 	 {P. D'Alberto and A. Nicolau},
  title = 	 {Using Recursion to Boost {ATLAS}'s Performance},
  OPTcrossref =  {},
  OPTkey = 	 {},
  booktitle = {The Sixth International Symposium on High Performance Computing (ISHPC-VI)},
  year = 	 {2005}

}

@InProceedings{DalbertoN2005,
  author = 	 {P. D'Alberto and A. Nicolau},
  title = 	 {Adaptive {S}trassen and {ATLAS}'s {DGEMM}: A Fast Square-Matrix Multiply for Modern High-Performance Systems},
  OPTcrossref =  {},
  OPTkey = 	 {},
  booktitle = { The 8th International Conference on High Performance Computing in Asia Pacific Region (HPC asia)},
  pages = 	 {45-52},
  year = 	 {2005},
  OPTeditor = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  address = 	 {Beijing},
  month = 	 {Dec},
  OPTorganization = {},
  OPTpublisher = {},
  OPTnote = 	 {},
  OPTannote = 	 {}
}



@Unpublished{DalbertoN2006siam,
  author = 	 {P. D'Alberto and A. Nicolau},
  title = 	 {Adaptive Strassen Matrix Multiply},
  note = 	 {Submitted to SISC},
  OPTkey = 	 {},
  OPTmonth = 	 {},
  OPTyear = 	 {},
  OPTannote = 	 {}
}

@article{DemmelH92,
    author = "J. Demmel and N. Higham",
    title = "Stability of Block Algorithms with Fast Level-3 {BLAS}",
    journal = "ACM Transactions on Mathematical Software",
    volume = "18",
    number = "3",
    pages = "274--291",
    year = "1992",
    url = "citeseer.ist.psu.edu/demmel92stability.html" }


@ARTICLE{whaley04,
AUTHOR = "R. Clint Whaley and Antoine Petitet",
TITLE  = "Minimizing development and maintenance costs in supporting
          persistently optimized {BLAS}",
JOURNAL= "Software: Practice and Experience",
volume = "35",
number = "2",
pages  = "101-121",
month  = "February",
YEAR   = "2005",
NOTE           = {\verb+http://www.cs.utsa.edu/~whaley/papers/spercw04.ps+}
}


@ARTICLE{Demmel:05,
AUTHOR = {J. Demmel and J. Dongarra and E. Eijkhout and E. Fuentes and E. Petitet and V. Vuduc and R.C. Whaley and K. Yelick},
TITLE = {Self-{A}dapting linear algebra algorithms and software},
JOURNAL = {Proceedings of the IEEE, special issue on "Program Generation, Optimization, and Adaptation"},
VOLUME = {93},
NUMBER = 2,
YEAR={2005}
}

@misc{DemmelDHK2006,
	author = {J. Demmel   and J. Dumitriu and O. Holtz   and R. Kleinberg},
	citeulike-article-id = {543540},
	eprint = {math.NA/0603207},
	keywords = {algorithms computation mathematics},
	month = {Mar},
	priority = {2},
	title = {Fast matrix multiplication is stable},
	url = {http://arxiv.org/abs/math.NA/0603207},
	year = {2006}
}

@article{DouglasHSSS94,
    author = "C.C. Douglas and M. Heroux and G. Slishman and R.M. Smith",
    title = "{GEMMW}: {A} Portable Level 3 {BLAS Winograd} Variant of {Strassen's} Matrix--Matrix Multiply Algorithm",
    journal = "J. Comp. Phys.",
    volume = "110",
    pages = "1--10",
    year = "1994",
    url = "citeseer.ist.psu.edu/douglas94gemmw.html" }

@InProceedings{EironRS98,
  author = 	 { N. Eiron and M. Rodeh and I. Steinwarts},
  title = 	 { Matrix multiplication: a case study of algorithm engineering},
  booktitle = {Proceedings WAE'98},
  year = 	 {1998},
  address = 	 {Saarbr\.ucken, Germany},
  month = 	 {Aug},
  }

@Article{FFTW05,
  author = 	 {M. Frigo and S. Johnson},
  title = 	 {The Design and Implementation of {FFTW3}},
  journal = 	 {Proceedings of the IEEE, special issue on "Program Generation, Optimization, and Adaptation"},
  year = 	 {2005},
  volume =	 {93},
  number =	 {2},
  pages =	 {216--231},
  }

@InProceedings{FrigoLPR99,
  author = 	 {M. Frigo and C.E. Leiserson and H. Prokop and S. Ramachandran },
  title = 	 {Cache oblivious algorithms},
  booktitle = {Proceedings 40th Annual Symposium on Foundations of Computer Science},
  year = 	 {1999},
  }

@ARTICLE{Welch1969,
author={Welch, Peter D.},
journal={Audio and Electroacoustics, IEEE Transactions on},
title={A fixed-point fast Fourier transform error analysis},
year={1969},
volume={17},
number={2},
pages={151-157},
keywords={Algorithm design and analysis;Equations;Error analysis;Fast Fourier transforms;Fourier transforms;Region 1},
doi={10.1109/TAU.1969.1162035},
ISSN={0018-9278},}

@Article{FrensW97,
  author = 	 {J.D. Frens and D.S. Wise},
  title = 	 { Auto-{B}locking matrix-multiplication or tracking {BLAS3} 
                   performance from source code},
  journal = { Proc. 1997 ACM Symp. on Principles and Practice of Parallel
                Programming},
  pages = 	 {206-216},
  year = 	 {1997},
  volume = 	 {32},
  number = 	 {7},
  month = 	 {July},
}


@Unpublished{Wise,
  author = 	 {S. Loos and D.S. Wise},
  title = 	 {Strassen's Matrix Multiplication Relabeled},
  url   =        {http://www.acm.org/src/loos/loos.html},
  note  =        {}
}



@Unpublished{GotoG2006,
  author = 	 {K. Goto and R.A. van de Geijn},
  title = 	 {Anatomy of High-Performance Matrix Multiplication},
  note = 	 {ACM Transactions on Mathematical Software},
  OPTkey = 	 {},
  OPTmonth = 	 {},
  year = 	 {2008},
  OPTannote = 	 {}
}


@article{Shannon1948,
  added-at = {2009-01-08T03:13:35.000+0100},
  author = {Shannon, Claude},
  biburl = {http://www.bibsonomy.org/bibtex/244eefdcbe008f7f0406568a9bc9f896e/pdturney},
  interhash = {754130207906fcec16a53d330eeff348},
  intrahash = {44eefdcbe008f7f0406568a9bc9f896e},
  journal = {Bell System Technical Journal},
  key = {Shannon},
  keywords = {imported},
  pages = {379--423, 623--656},
  timestamp = {2009-01-08T03:13:35.000+0100},
  title = {A Mathematical Theory of Communication},
  volume = 27,
  year = 1948
}


@techreport{grayson95high,
    author = "B. Grayson and A. Pankaj Shah and R.A. van de Geijn",
    title = "A High Performance Parallel Strassen Implementation",
    number = "CS-TR-95-24",
    month = "1,",
    year = "1995",
    url = "citeseer.ist.psu.edu/grayson95high.html" }

@Article{Gunnels:2001:FFL,
  author =       "J.A. Gunnels and F.G. Gustavson and G.M. Henry and R.A. van de Geijn",
  title =        "{FLAME}: {Formal Linear Algebra Methods Environment}",
  journal =      "{ACM} Transactions on Mathematical Software",
  volume =       "27",
  number =       "4",
  pages =        "422--455",
  month =        dec,
  year =         "2001",
  CODEN =        "ACMSCU",
  ISSN =         "0098-3500",
  bibsource =    "http://www.acm.org/pubs/contents/journals/toms/",
  URL =          "http://doi.acm.org/10.1145/504210.504213",
 }





@article{Higham1990,
 author = {N.J. Higham},
 title = {Exploiting fast matrix multiplication within the level 3 {BLAS}},
 journal = {ACM Trans. Math. Softw.},
 volume = {16},
 number = {4},
 year = {1990},
 issn = {0098-3500},
 pages = {352--368},
 doi = {http://doi.acm.org/10.1145/98267.98290},
 publisher = {ACM Press},
 }



@Book{Higham2002,
  author = 	 {N.J. Higham},
  ALTeditor = 	 {},
  title = 	 {Accuracy and Stability of Numerical Algorithms, Second Edition},
  publisher = 	 {SIAM},
  year = 	 {2002},
}

@inproceedings{Huss-LedermanJTTJ96,
 author = {S. Huss-Lederman and E.M. Jacobson and A. Tsao and T. Turnbull and J.R. Johnson},
 title = {Implementation of {S}trassen's algorithm for matrix multiplication},
 booktitle = {Supercomputing '96: Proceedings of the 1996 ACM/IEEE conference on Supercomputing (CDROM)},
 year = {1996},
 isbn = {0-89791-854-1},
 pages = {32},
 location = {Pittsburgh, Pennsylvania, United States},
 doi = {http://doi.acm.org/10.1145/369028.369096},
 publisher = {ACM Press},
 }

@TechReport{Huss-LedermanJJTT96,
  author = "S. Huss-Lederman and E. Jacobson and J. Johnson and A. Tsao and T. Turnbull",
  title = "Strassen's algorithm for matrix multiplication: Modeling analysis, and implementation.",
  OPTtext = "Steven Huss-Lederman, Elaine M. Jacobson, J. R. Johnson, Anna Tsao, and
    Thomas Turnbull. Strassen's algorithm for matrix multiplication: Modeling,
    analysis, and implementation. Technical Report Technical Report CCS-TR-96-147,
    Center for Computing Sciences, November 1996. 45",
  number = 	 {CCS-TR-96-14},
  institution =  {Center for Computing Sciences},
  year = "1996",
  url = "citeseer.ist.psu.edu/huss-lederman96strassens.html" }

@inproceedings{LiGP05,
  author = "X. Li and M. Garzaran and D. Padua",
  title = "Optimizing Sorting with Genetic Algorithms",
  booktitle = "In In Proc. of the Int. Symp. on Code Generation and Optimization",
  pages = "99--110", 
  month = "March",
  year = "2005",
  url = "citeseer.ist.psu.edu/li05optimizing.html" }

@article{Kaporin2004,
 author = {Igor Kaporin},
 title = {The aggregation and cancellation techniques as a practical tool for faster matrix multiplication},
 journal = {Theor. Comput. Sci.},
 volume = {315},
 number = {2-3},
 year = {2004},
 issn = {0304-3975},
 pages = {469--510},
 doi = {http://dx.doi.org/10.1016/j.tcs.2004.01.004},
 publisher = {Elsevier Science Publishers Ltd.},
 address = {Essex, UK},
 }




@Article{Kaporin1999,
  author = 	 {I. Kaporin},
  title = 	 {A practical algorithm for faster matrix multiplication},
  journal = 	 {Numerical Linear Algebra with Applications},
  year = 	 {1999},
  OPTkey = 	 {},
  volume = 	 {6},
  number = 	 {8},
  pages = 	 {687-700},
  OPTmonth = 	 {},
  note = 	 {Centre for Supercomputer and Massively Parallel Applications, Computing Centre of the Russian Academy of Sciences, Vavilova 40, Moscow 117967, Russia},
  OPTannote = 	 {}
}

@Article{KagstromLVL981,
  author = 	 {B. Kagstrom  and P. Ling  and C. van Loan },
  title = 	 {Algorithm 784: {GEMM}-based level 3 {BLAS}: portability and 
	optimization issues},
  journal = 	 {ACM Transactions on Mathematical Software},
  year = 	 {1998},
  volume = 	 {24},
  number = 	 {3},
  pages = 	 {303-316},
  month = 	 {Sept},
  }
@Article{KagstromLVL982,
  author = 	 {B. Kagstrom  and P. Ling  and C. van Loan },
  title = 	 {{GEMM}-based level 3 {BLAS}: high-performance model implementations 
                  and performance evaluation benchmark},
  journal = 	 {ACM Transactions on Mathematical Software},
  year = 	 {1998},
  volume = 	 {24},
  number = 	 {3},
  pages = 	 {268-302},
  month = 	 {Sept},
  }

@article{ChatterjeeLPT2002,
 author = {S. Chatterjee and Alvin R. and P. Patnala and M. Thottethodi},
 title = {Recursive Array Layouts and Fast Matrix Multiplication},
 journal = {IEEE Trans. Parallel Distrib. Syst.},
 volume = {13},
 number = {11},
 year = {2002},
 issn = {1045-9219},
 pages = {1105--1123},
 doi = {http://dx.doi.org/10.1109/TPDS.2002.1058095},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
 }


@article{PandaNDN1999,
 author = {P.R. Panda and H. Nakamura and N. Dutt and A. Nicolau},
 title = {Augmenting Loop Tiling with Data Alignment for Improved Cache Performance},
 journal = {IEEE Trans. Comput.},
 volume = {48},
 number = {2},
 year = {1999},
 issn = {0018-9340},
 pages = {142--149},
 doi = {http://dx.doi.org/10.1109/12.752655},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 }


@Article{Knight1995,
  author = 	 {P. Knight},
  title = 	 {Fast rectangular matrix multiplication and {QR}-Decomposition},
  journal = 	 {Linear algebra and its applications},
  year = 	 {1995},
  OPTkey = 	 {},
  volume = 	 {221},
  OPTnumber = 	 {},
  pages = 	 {69--81},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {}
}




@InProceedings{NguyenLBH2005,
  author = 	 {D. Nguyen and  I.Lavallee and  M.Bui and  Q.Ha},
  title = 	 {A General Scalable Implementation of Fast Matrix Multiplication Algorithms on Distributed Memory Computers},
  booktitle = {Proceedings Sixth International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing and First ACIS International Workshop on Self-Assembling Wireless Networks},
  pages = 	 {116-122},
  year = 	 {2005},
  note = 	 {http://doi.ieeecomputersociety.org/10.1109/SNPD-SAWN.2005.2}
}

@InProceedings{OhtakiTBS2004,
  author = 	 {Y. Ohtaki and  D. Takahashi and T. Boku and  M. Sato},
  title = 	 {Parallel Implementation of Strassen's Matrix Multiplication Algorithm for Heterogeneous Clusters},
  booktitle = {Proceedings of the 18th International Parallel and Distributed Processing Symposium},
  pages = 	 {112},
  year = 	 {2004},
  note = 	 {http://doi.ieeecomputersociety.org/10.1109/IPDPS.2004.1303066}
}


@article{Pan1984,
author = {V. Pan},
collaboration = {},
title = {How Can We Speed Up Matrix Multiplication?},
publisher = {SIAM},
year = {1984},
journal = {SIAM Review},
volume = {26},
number = {3},
pages = {393-415},
url = {http://link.aip.org/link/?SIR/26/393/1},
doi = {10.1137/1026076}
}

@inproceedings{Pan1978,
  author    = {V. Pan},
  title     = {Strassen's Algorithm Is not Optimal: Trililnear Technique
               of Aggregating, Uniting and Canceling for Constructing Fast
               Algorithms for Matrix Operations},
  booktitle = {FOCS},
  year      = {1978},
  pages     = {166-176},
  OPTcrossref  = {DBLP:conf/focs/FOCS19},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}


@inproceedings{Priest91,
    author = "D. Priest",
    title = "Algorithms for arbitrary precision floating point arithmetic",
    booktitle = "Proceedings of the 10th {IEEE} Symposium on Computer Arithmetic (Arith-10)",
    publisher = "IEEE Computer Society Press, Los Alamitos, CA",
    address = "Grenoble, France",
    editor = "P. Kornerup and D.~W. Matula",
    pages = "132--144",
    year = "1991",
    url = "citeseer.ist.psu.edu/priest91algorithms.html" }

@ARTICLE{Pueschel:05,
AUTHOR = {M. P{\"u}schel and J.M.F. Moura and J. Johnson and D. Padua and M. Veloso and B.W. Singer and J. Xiong and F. Franchetti and A. Ga\v{c}i\'{c} and Y. Voronenko and K. Chen and R.W. Johnson and N. Rizzolo},
TITLE = {{SPIRAL}: Code Generation for {DSP} Transforms},
JOURNAL = {Proceedings of the IEEE, special issue on "Program Generation, Optimization, and Adaptation"},
VOLUME = {93},
NUMBER = 2,
YEAR={2005}
}

@Article{Strassen69,
  author = 	 {V. Strassen},
  title = 	 {Gaussian elimination is not optimal.},
  journal = 	 {Numerische Mathematik},
  year = 	 {1969},
  volume = 	 {14},
  number = 	 {3},
  pages = 	 {354-356},
  }
@InProceedings{ThottethodiCL98,
  author = 	 {M. Thottethodi and  S. Chatterjee and A.R. Lebeck},
  title = 	 {Tuning {S}trassen's matrix multiplication for memory efficiency.},
  booktitle = {Proc. Supercomputing },
  year = 	 {1998},
  address = 	 {Orlando, FL},
  month = 	 {nov},
}
@inproceedings{WhaleyD98,
 author = {R. Whaley and J. Dongarra},
 title = {Automatically tuned linear algebra software},
 booktitle = {Proceedings of the 1998 ACM/IEEE conference on Supercomputing (CDROM)},
 year = {1998},
 isbn = {0-89791-984-X},
 pages = {1--27},
 location = {San Jose, CA},
 publisher = {IEEE Computer Society},
 }


@Article{LawsonHKK1979,
  author = 	 {C. L. Lawson and  R. J. Hanson and D. Kincaid and F. T. Krogh},
  title = 	 {{B}asic {L}inear {A}lgebra {S}ubprograms for {FORTRAN} usage},
  journal = 	 {ACM Transaction in Mathemathical Software},
  year = 	 {1979},
  volume = 	 {5},
  pages = 	 {308--323},
}


@Article{DongarraDDH1990,
  author = 	 {J. J. Dongarra and J. Du Croz and I. S. Duff and and S. Hammarling},
  title = 	 {A set of Level 3 {B}asic {L}inear {A}lgebra {S}ubprograms},
  journal = 	 {ACM Transaction in Mathemathical Software},
  year = 	 {1990},
  volume = 	 {16},
  pages = 	 {1--17},
}
@Article{DongarraDDH21990,
  author = 	 {J. J. Dongarra and J. Du Croz and I. S. Duff and and S. Hammarling},
  title = 	 {Algorithm 679: A set of Level 3 {B}asic {L}inear {A}lgebra {S}ubprograms},
  journal = 	 {ACM Transaction in Mathemathical Software},
  year = 	 {1990},
  volume = 	 {16},
  pages = 	 {18--28},
}


@Article{BlackfordDDDHHHKLPPRW2002,
  author = 	 {L. S. Blackford and J. Demmel and J. Dongarra and I. Duff and
                  S. Hammarling and G. Henry and M. Heroux and L. Kaufman and
                  A. Lumsdaine and A. Petitet and R. Pozo and K. Remington and
                  R. C. Whaley},
  title = 	 {An Updated Set of Basic Linear Algebra Subprograms ({BLAS})},
  journal = 	 {ACM Transaction in Mathemathical Software},
  year = 	 {2002},
  volume = 	 {28},
  number = 	 {2},
  pages = 	 {135-151},
}



%%%% Added from https://github.com/jbryer/psa/blob/master/book/PSA.bib

@article{WeitzenEtAl2004,
	Author = {S. Weitzen and K. Lapane and A. Toledano and A. Hume and V. Mor},
	Date-Added = {2014-04-29 14:03:33 +0000},
	Date-Modified = {2014-04-29 14:04:46 +0000},
	Journal = {Pharmacoepidemiology and Drug Safety},
	Number = {841-853},
	Title = {Principles for modeling propensity scores in medical research: A systematic literature review},
	Year = {13}}

@article{Austin2008b,
	Author = {Peter Austin},
	Date-Added = {2014-04-29 14:02:29 +0000},
	Date-Modified = {2014-04-29 14:03:30 +0000},
	Journal = {Circulation-Cardiovascular Quality and Outcomes},
	Pages = {62-67},
	Title = {Primer on statistical interpretation or methods report card on propensity-score matcing in the cardiology literature from 2004 to 2006: A systematic review},
	Volume = {1},
	Year = {2008}}

@article{Austin2008a,
	Author = {Peter Austin},
	Date-Added = {2014-04-29 14:01:37 +0000},
	Date-Modified = {2014-04-29 14:02:26 +0000},
	Journal = {Statistics in Medicine},
	Pages = {2037-2049},
	Title = {A critical appraisal of propensity-score matching in the medical literature between 1996 and 2003},
	Volume = {27},
	Year = {2008}}

@article{Austin2007,
	Author = {Peter Austin},
	Date-Added = {2014-04-29 14:00:19 +0000},
	Date-Modified = {2014-04-29 14:01:31 +0000},
	Journal = {The Journal of Thoracic and Cardiovascular Surgery},
	Pages = {1128-1135},
	Title = {Propensity-score matching in the the cardiovascular surgery literature from 2004 to 2006: A systematic review and suggestions for improvement},
	Volume = {134},
	Year = {2007}}

@article{BryerPruzek2011,
	Author = {Jason Bryer and Robert Pruzek},
	Date-Added = {2014-04-22 21:39:52 +0000},
	Date-Modified = {2014-04-22 21:40:28 +0000},
	Journal = {Multivariate Behavioral Research},
	Number = {6},
	Title = {An international comparison of private and public schools using multilevel propensity score methods and graphics (Abstract)},
	Volume = {46},
	Year = {2011}}

@article{Holland1986,
	Abstract = {Problems involving causal inference have dogged at the heels of statistics since its earliest days. Correlation does not imply causation, and yet causal conclusions drawn from a carefully designed experiment are often valid. What can a statistical model say about causation? This question is addressed by using a particular model for causal inference (Holland and Rubin 1983; Rubin 1974) to critique the discussions of other writers on causation and causal inference. These include selected philosophers, medical researchers, statisticians, econometricians, and proponents of causal modeling.},
	Author = {Paul W. Holland},
	Date-Added = {2013-04-25 11:40:39 +0000},
	Date-Modified = {2014-04-22 21:22:54 +0000},
	Journal = {Journal of the American Statistical Association},
	Number = {396},
	Pages = {945--960},
	Title = {Statistics and Causal Inference},
	Volume = {81},
	Year = {1986}}

@article{HelmreichPruzek2009,
	Abstract = {Propensity score analysis is a technique for adjusting for selection bias in observational data. Estimated propensity scores (probability of treatment given observed covariates) are used for stratification of observations. Within strata covariates should be more balanced between the two treatments than without the stratification. PSAgraphics is an R package that provides flexible graphical tools to assess within strata balance between treatment groups, as well as how covariate distributions differ across strata. Additional graphical tools facilitate estimation of treatment effects having adjusted for covariate differences. Several new and conventional numerical measures of balance are also provided.},
	Author = {Helmreich, James E and Pruzek, Robert M},
	Date-Modified = {2013-04-25 11:43:03 +0000},
	File = {:Users/jbryer/Dropbox/Projects/Intro to PSA with R/Articles/Helmreich \& Pruzek (2009) PSAgraphics.pdf:pdf},
	Journal = {Journal of Statistical Software},
	Mendeley-Tags = {visualization},
	Number = {6},
	Title = {{PSAgraphics : An R Package to Support Propensity}},
	Volume = {29},
	Year = {2009}}

@article{RosenbaumRubin1983,
	Author = {Rosenbaum, P.R. and Rubin, D.B.},
	Issue = {1},
	Journal = {Biometrika},
	Title = {The central role of the propensity score in observational studies for causal effects},
	Volume = {70},
	Year = {1983}}

@manual{rcore,
	Address = {Vienna, Austria},
	Author = {{R Development Core Team}},
	Note = {{ISBN} 3-900051-07-0},
	Organization = {R Foundation for Statistical Computing},
	Title = {R: A Language and Environment for Statistical Computing},
	Url = {http://www.R-project.org/},
	Year = {2011},
	Bdsk-Url-1 = {http://www.R-project.org/}}

@book{ggplot2,
	Author = {Hadley Wickham},
	Isbn = {978-0-387-98140-6},
	Publisher = {Springer New York},
	Title = {ggplot2: elegant graphics for data analysis},
	Url = {http://had.co.nz/ggplot2/book},
	Year = {2009},
	Bdsk-Url-1 = {http://had.co.nz/ggplot2/book}}

@manual{devtools,
	Author = {Hadley Wickham},
	Note = {R package version 0.6},
	Title = {devtools: Tools to make developing R code easier},
	Url = {http://CRAN.R-project.org/package=devtools},
	Year = {2012},
	Bdsk-Url-1 = {http://CRAN.R-project.org/package=devtools}}

@inbook{StuartRubin2008,
	Author = {Elizabeth A. Stuart and Donald B. Rubin},
	Chapter = {Best practices in quasi-experimental designs: Matching methods for causal inference},
	Date-Added = {2011-10-31 22:50:15 +0000},
	Date-Modified = {2011-10-31 22:53:27 +0000},
	Editor = {Jason Osborne},
	Pages = {155-176},
	Publisher = {Sage Publications},
	Title = {Best Practices in Quantitative Methods},
	Year = {2008}}

@incollection{Ripley1997,
	Author = {B. D. Ripley},
	Booktitle = {Encyclopedia of Statistical Sciences},
	Date-Added = {2009-11-29 13:52:08 -0500},
	Date-Modified = {2009-11-29 13:55:56 -0500},
	Editor = {Samuel Kotz and David L. Banks and Campbell B. Read},
	Pages = {110-116},
	Publisher = {John Wiley \& Sons},
	Title = {Classification},
	Volume = {2},
	Year = {1997}}

@electronic{rpart,
	Author = {Terry M. Therneau and Beth Atkinson},
	Date-Added = {2009-11-29 13:46:31 -0500},
	Date-Modified = {2009-11-29 13:47:36 -0500},
	Title = {[Computer software]. \lowercase{rpart}: Recusrive Partitioning},
	Url = {http://cran.r-project.org/web/packages/rpart/index.html},
	Urldate = {November 29},
	Bdsk-Url-1 = {http://cran.r-project.org/web/packages/rpart/index.html}}

@electronic{Therneau1997,
	Author = {Terry M. Therneau and Elizabeth J. Atkinson and Mayo Foundation},
	Date-Added = {2009-11-29 13:43:21 -0500},
	Date-Modified = {2009-12-06 11:32:28 -0500},
	Title = {An Introduction to Recursive Partitioning Using the RPART Routines},
	Url = {http://www.mayo.edu/hsr/techrpt/61.pdf},
	Urldate = {November 29, 2009},
	Bdsk-Url-1 = {http://www.google.com/url?sa=t&source=web&ct=res&cd=1&ved=0CAcQFjAA&url=http://www.mayo.edu/hsr/techrpt/61.pdf&ei=_r8SS4_jMJWzlAf5x7GxAg&usg=AFQjCNFS90E5JdRXui2HmdtdfBWPADHqgA&sig2=Dj4Nyx_3jRqXjNYQm_lEFw}}

@book{Breiman1984,
	Address = {Belmont, CA},
	Author = {L. Breiman and J. H. Friedman and R. A. Olshen and C. J. Stone},
	Date-Added = {2009-11-29 13:36:38 -0500},
	Date-Modified = {2009-11-29 13:37:36 -0500},
	Publisher = {Wadsworth},
	Title = {Classification and Regression Trees},
	Year = {1984}}

@article{Rubin1996psa,
	Author = {D. B. Rubin and N. Thomas},
	Date-Added = {2009-11-28 17:37:05 -0500},
	Date-Modified = {2011-10-31 21:43:03 +0000},
	Journal = {Biometrics},
	Pages = {249-264},
	Title = {Matching using propensity scores: Relating theory to practice},
	Volume = {52},
	Year = {1996}}

@article{LuellenShadishClark2005,
	Author = {Jason K. Luellen and William R. Shadish and M. H. Clark},
	Date-Added = {2009-11-28 17:17:35 -0500},
	Date-Modified = {2009-11-28 17:19:17 -0500},
	Journal = {Evaluation Review},
	Number = {6},
	Pages = {530-558},
	Title = {Propensity Scores: An Introduction and Experimental Test},
	Volume = {29},
	Year = {2005}}

@book{Rosenbaum2002,
	Address = {New York, NY},
	Author = {Paul R. Rosenbaum},
	Date-Added = {2009-11-28 17:12:03 -0500},
	Date-Modified = {2009-11-28 17:13:47 -0500},
	Edition = {2nd},
	Publisher = {Springer},
	Title = {Observational Studies},
	Year = {2002}}

@webpage{ZeileisHothornHornik2009,
	Author = {Achim Zeileis and Torsten Hothorn and Kurt Hornik},
	Date-Added = {2009-11-28 16:58:21 -0500},
	Date-Modified = {2009-11-28 17:06:10 -0500},
	Lastchecked = {November 28, 2009},
	Title = {\lowercase{party} with the mob: Model-based Recursive Partitioning in \uppercase{R}},
	Url = {http://cran.mtu.edu/web/packages/party/vignettes/MOB.pdf},
	Urldate = {September 24, 2009},
	Year = {2009},
	Bdsk-Url-1 = {http://cran.mtu.edu/web/packages/party/vignettes/MOB.pdf}}

@webpage{HothornHornikZeileis2009,
	Author = {Torsten Hothorn and Kurt Hornik and Achim Zeileis},
	Date-Added = {2009-11-28 16:54:54 -0500},
	Date-Modified = {2009-11-28 17:05:26 -0500},
	Lastchecked = {November 28, 2009},
	Title = {\lowercase{party}: A Laboratory for Recursive Partytioning},
	Url = {http://cran.mtu.edu/web/packages/party/vignettes/party.pdf},
	Urldate = {September 24, 2009},
	Year = {2009},
	Bdsk-Url-1 = {http://cran.mtu.edu/web/packages/party/vignettes/party.pdf}}

@article{Vanbuuren,
	Author = {Stef van{\ }Buuren and Karin Groothuis-Oudshoorn},
	Date-Modified = {2009-11-28 17:00:06 -0500},
	Journal = {Journal of Statistical Software},
	Title = {\uppercase{MICE}: Multivariate imputation by chained equations in R},
	Year = {n.d.}}

@book{Tufte2001,
	Author = {Edward Tufte},
	Location = {Cheshire, CT},
	Publisher = {Graphics Press LLC},
	Title = {The Visual Display of Quantitative Information},
	Year = {2001}}

@book{Cleveland1988,
	Author = {W. S. Cleveland},
	Location = {Pacific Grove, CA},
	Publisher = {Wadsworth and Brooks},
	Title = {The Collected Works of John W. Tukey, Volume V Graphics},
	Year = {1988}}

@book{Cleveland1993,
	Author = {W. S. Cleveland},
	Location = {Murray Hill, NJ},
	Publisher = {AT\&T Bell Laboratories},
	Title = {Visualizing data},
	Year = {1993}}

@book{Cleveland1994,
	Author = {W. S. Cleveland},
	Location = {Murray Hill, NJ},
	Publisher = {AT\&T Bell Laboratories},
	Title = {The elements of graphing data (Rev. ed.)},
	Year = {1994}}

@book{Chambers1983,
	Author = {J. M. Chambers and W. S. Cleveland and B Kleiner and P. A. Tukey},
	Location = {Belmont, CA},
	Publisher = {Belmont},
	Title = {Graphical methods for data analysis},
	Year = {1983}}

@book{Wilkinson2005,
	Author = {L. Wilkinson},
	Location = {New York, NY},
	Publisher = {Springer},
	Title = {The grammar of graphics (2nd Ed)},
	Year = {2005}}

@article{Akaike1974,
	Author = {H. Akaike},
	Issue = {6},
	Journal = {IEEE Transactions on Automatic Control},
	Pages = {716-723},
	Title = {A new look at the statistical model identification},
	Volume = {19},
	Year = {1974}}

@book{mass,
	Address = {New York},
	Author = {W. N. Venables and B. D. Ripley},
	Edition = {Fourth},
	Note = {ISBN 0-387-95457-0},
	Publisher = {Springer},
	Title = {Modern Applied Statistics with S},
	Url = {http://www.stats.ox.ac.uk/pub/MASS4},
	Year = {2002},
	Bdsk-Url-1 = {http://www.stats.ox.ac.uk/pub/MASS4}}

@article{ThoemmesKim2011,
	Author = {F. J. Thoemmes and E. S. Kim},
	Issue = {1},
	Journal = {Multivariate Behavioral Research},
	Pages = {90-118},
	Title = {A systematic review of preonsity score methods in the social sciences},
	Volume = {46},
	Year = {2011}}

@article{Dawid2000,
	Author = {A. P. Dawid},
	Issue = {450},
	Journal = {Journal of the American Statistical Association},
	Pages = {407-424},
	Title = {Causal inference without counterfactuals},
	Volume = {95},
	Year = {2000}}

@book{ArpinoMealli2008,
	Author = {B. Arpino and F. Mealli},
	Institution = {Carlo F. Dondena Centre for Research on Social Dynamics},
	Publisher = {Munich Personal RePEc Archive},
	Title = {The specification of the propensity score in multilevel observational studies},
	Url = {http://mpra.ub.uni-muenchen.de/17407},
	Year = {2008},
	Bdsk-Url-1 = {http://mpra.ub.uni-muenchen.de/17407}}

@article{Rubin1997,
	Author = {D. B. Rubin},
	Issue = {2},
	Journal = {Annals of Internal Medicine},
	Pages = {757-763},
	Title = {Estimation from nonrandomized treatment comparisons using subclassifications on propensity scores.},
	Volume = {8},
	Year = {1997}}

@article{Rubin1996mi,
	Author = {D. B. Rubin},
	Date-Modified = {2011-10-31 21:42:58 +0000},
	Issue = {434},
	Journal = {Journal of the American Statistical Association},
	Pages = {473-489},
	Title = {Multiple imputation after 18+ years.},
	Volume = {91},
	Year = {1996}}

@article{Stuart2010,
	Author = {E. A. Stuart},
	Issue = {1},
	Journal = {Statistical Science},
	Pages = {1-21},
	Title = {Matching methods for causal inference: A review and a look forward},
	Volume = {25},
	Year = {2010}}

@article{Austin2011,
	Author = {P. C. Austin},
	Journal = {Statistical in Medicine},
	Pages = {1292-1301},
	Title = {Comparing paired vs non-paired statistical methods of analyses when making inferences about absolute risk reductions in propensity-score matched smaples.},
	Volume = {30},
	Year = {2011}}

@article{HorthornHornikZeileis2006,
	Author = {T. Hothorn and K. Hornik and A. Zeileis},
	Issue = {3},
	Journal = {Journal of Computational and Graphical Statistics},
	Pages = {651-674},
	Title = {Unbiased recursive partitioning: A conditional inference framework},
	Volume = {15},
	Year = {2006}}

@article{Rosenbaum2012,
	Author = {P. R. Rosenbaum},
	Issue = {4},
	Journal = {Biometrika},
	Pages = {763-774},
	Title = {Testing one hypothesis twice in observational studies},
	Volume = {99},
	Year = {2012}}

@book{Rubin1987,
	Author = {D. B. Rubin},
	Location = {New York},
	Publisher = {Wiley},
	Title = {Multiple imputation for nonresponse in surveys},
	Year = {1987}}

@manual{multilevelPSA,
	Author = {Jason Bryer},
	Note = {R package version 1.0},
	Title = {multilevelPSA: Multilevel Propensity Score Analysis},
	Url = {http://multilevelpsa.r-forge.r-project.org},
	Year = {2011},
	Bdsk-Url-1 = {http://multilevelpsa.r-forge.r-project.org}}

@manual{pisa,
	Author = {{Organisation for Economic Co-Operation and Development}},
	Title = {Programme of International Student Assessment},
	Url = {http://www.oecd.org/pisa/},
	Year = {2009},
	Bdsk-Url-1 = {http://www.oecd.org/pisa/}}

@article{mice,
	Author = {Stef {van Buuren} and Karin Groothuis-Oudshoorn},
	Journal = {Journal of Statistical Software},
	Number = {3},
	Pages = {1--67},
	Title = {{mice}: Multivariate Imputation by Chained Equations in R},
	Url = {http://www.jstatsoft.org/v45/i03/},
	Volume = {45},
	Year = {2011},
	Bdsk-Url-1 = {http://www.jstatsoft.org/v45/i03/}}

@article{matching,
	Accepted = {2007-06-16},
	Author = {Jasjeet S. Sekhon},
	Bibdate = {2007-06-16},
	Coden = {JSSOBK},
	Day = {14},
	Issn = {1548-7660},
	Journal = {Journal of Statistical Software},
	Month = {6},
	Number = {7},
	Pages = {1--52},
	Submitted = {2007-02-07},
	Title = {Multivariate and Propensity Score Matching Software with Automated Balance Optimization: The Matching package for R},
	Url = {http://www.jstatsoft.org/v42/i07},
	Volume = {42},
	Year = {2011},
	Bdsk-Url-1 = {http://www.jstatsoft.org/v42/i07}}

@article{Hill2008,
	Author = {Jennifer Hill},
	Journal = {Statistics in Medicine},
	Pages = {2055--2061},
	Title = {Discussion of research using propensity-score matching: Comments on 'A critical appraisal of propensity-score matching in the medical literature between 1996 and 2003' by {Peter Austin}},
	Volume = {27},
	Year = {2008}}

@article{CookShadishWong2008,
	Author = {Thomas D. Cook and William R. Shadish and Vivian C. Wong},
	Journal = {Journal of Policy Analysis and Management},
	Number = {4},
	Title = {Three conditions under which experiments and observational studies produce comparable causal estimates: New findings from within-study comparisons},
	Volume = {27},
	Year = {2008}}

@misc{RaudenbushHongRowan2003,
	Author = {Stephen W. Raudenbush and Guanglei Hong and Brian Rowan},
	Title = {Studying the causal effects of instruction with application to primary-school mathematics. Invited talk at the Research Seminar II: Instructional and Performance Consequences of High Poverty Schooling},
	Year = {2003}}

@book{SchneiderEtAl2007,
	Author = {Barbara Schneider and Martin Carnoy and Jeremy Kilpatrick and William H. Schmidt and Richard J. Shavelson},
	Location = {New York, NY},
	Publisher = {American Educational Research Association},
	Title = {Estimating Causal Effects Using Experimental and Observational Designs},
	Year = {2007}}

@article{ShadishClarkSteiner2008,
	Author = {William R. Shadish and M. H. Clark and Peter M. Steiner},
	Journal = {Journal of the American Statistical Association},
	Number = {484},
	Pages = {1334--1343},
	Title = {Can Nonrandomized Experiments Yield Accurate Answers? A Randomized Experiment Comparing Random and Nonrandom Assignments},
	Volume = {103},
	Year = {2008}}

@article{DehejiaWahba1999,
	Author = {Rajeev H. Dehejia and Sadek Wahba},
	Journal = {Journal of the American Statistical Association},
	Number = {448},
	Pages = {1053--1062},
	Title = {Causal Effects in Nonexperimental Studies: Reevaluating the Evaluation of Training Programs},
	Volume = {94},
	Year = {1999}}

@book{Pearl2009,
	Author = {Judea Pearl},
	Location = {New York, NY},
	Publisher = {Cambridge University Press},
	Title = {Causality: Models, Reasoning and Inference (2nd ed.)},
	Year = {2009}}

@misc{HeckmanEtAl1997,
	Author = {James Heckman and Hidehiko Ichimura and Jeffery Smith and Petra Todd},
	Title = {Characterizing Selection Bias Using Experimental Data},
	Url = {http://athens.src.uchicago.edu/jenni/dvmaster/FILES/matchingf.pdf},
	Year = {1997},
	Bdsk-Url-1 = {http://athens.src.uchicago.edu/jenni/dvmaster/FILES/matchingf.pdf}}

@article{Shadish2013,
	Author = {William R. Shadish},
	Journal = {Journal of Experimental Criminology},
	Number = {2},
	Pages = {128--144},
	Title = {Propensity score analysis: promise, reality and irrational exuberance},
	Volume = {9},
	Year = {2013}}



%%%%%%% bootstrap 

@TECHREPORT{RePEc:idb:spdwps:1005,
title = {A Primer for Applying Propensity-Score Matching},
author = {Heinrich, Carolyn and Maffioli, Alessandro and Vázquez, Gonzalo},
year = {2010},
institution = {Inter-American Development Bank, Office of Strategic Planning and Development Effectiveness (SPD)},
type = {SPD Working Papers},
number = {1005},
abstract = {The use of microeconometric techniques to estimate the effects of development policies has become a common approach not only for scholars, but also for policy-makers engaged in designing, implementing and evaluating projects in different fields. Among these techniques, Propensity-Score Matching (PSM) is increasingly applied in the policy evaluation community. This technical note provides a guide to the key aspects of implementing PSM methodology for an audience of practitioners interested in understanding its applicability to specific evaluation problems. The note summarizes the basic conditions under which PSM can be used to estimate the impact of a program and the data required. It explains how the Conditional Independence Assumption, combined with the Overlap Condition, reduces selection bias when participation in a program is determined by observable characteristics. It also describes different matching algorithms and some tests to assess the quality of the matching. Case studies are used throughout to illustrate important concepts in impact evaluation and PSM. In the annexes, the note provides an outline of the main technical aspects and a list of statistical and econometric software for implementing PSM.},
keywords = {Policy Evaluation; Microeconometrics; Propensity-Score Matching; Average Treatment Effect on the Treated; Development Effectiveness},
url = {http://EconPapers.repec.org/RePEc:idb:spdwps:1005}
}

@article{44152,
    abstract = {{Randomized controlled trials are the "gold standard" for estimating the causal effects of treatments. However, it is often not feasible to conduct such a trial because of ethical concerns or budgetary constraints. We expand upon an approach to the analysis of observational data sets that mimics a sequence of randomized studies by implementing propensity score models within each trial to achieve covariate balance, using weighting and matching. The methods are illustrated using data from a safety study of the relationship between second-generation antipsychotics and type 2 diabetes (outcome) in Medicaid-insured children aged 10-18 years across the United States from 2003 to 2007. Challenges in this data set include a rare outcome, a rare exposure, substantial and important differences between exposure groups, and a very large sample size.}},
    author = {Ross, M. E. and Kreider, A. R. and Huang, Y. S. and Matone, M. and Rubin, D. M. and Localio, A. R.},
    citeulike-article-id = {13878082},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/aje/kwu469},
    doi = {10.1093/aje/kwu469},
    isbn = {1476-6256; 0002-9262},
    journal = {American Journal of Epidemiology},
    keywords = {data---rare---zero-events, exportrecords, observational-study---methods, propensity-scores},
    number = {12},
    pages = {989--995},
    posted-at = {2015-12-09 01:12:41},
    priority = {3},
    title = {{Propensity Score Methods for Analyzing Observational Data Like Randomized Experiments: Challenges and Solutions for Rare Outcomes and Exposures}},
    url = {http://dx.doi.org/10.1093/aje/kwu469},
    volume = {181},
    year = {2015}
}

@article{44072,
    abstract = {{Observational studies of multilevel data to estimate treatment effects must consider both the nonrandom treatment assignment mechanism and the clustered structure of the data. We present an approach for implementation of four propensity score (PS) methods with multilevel data involving creation of weights and three types of weight scaling (normalized, cluster-normalized and effective), followed by estimation of multilevel models with the multilevel pseudo-maximum likelihood estimation method. Using a Monte Carlo simulation study, we found that the multilevel model provided unbiased estimates of the Average Treatment Effect on the Treated (ATT) and its standard error across manipulated conditions and combinations of PS model, PS method, and type of weight scaling. Estimates of between-cluster variances of the ATT were biased, but improved as cluster sizes increased. We provide a step-by-step demonstration of how to combine PS methods and multilevel modeling to estimate treatment effects using multilevel data from the Early Childhood Longitudinal Study–Kindergarten Cohort (ECLS-K).}},
    author = {Leite, W. L. and Jimenez, F. and Kaya, Y. and Stapleton, L. M. and MacInnes, J. W. and Sandbach, R.},
    citeulike-article-id = {13878058},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/00273171.2014.991018},
    doi = {10.1080/00273171.2014.991018},
    isbn = {0027-3171; 1532-7906},
    journal = {Multivariate Behavioral Research},
    keywords = {bias---selection, exportrecords, propensity-scores},
    number = {3},
    pages = {265--284},
    posted-at = {2015-12-09 01:12:40},
    priority = {3},
    title = {{An Evaluation of Weighting Methods Based on Propensity Scores to Reduce Selection Bias in Multilevel Observational Studies}},
    url = {http://dx.doi.org/10.1080/00273171.2014.991018},
    volume = {50},
    year = {2015}
}

@article{43957,
    abstract = {{Propensity scores are widely adopted in observational research because they enable adjustment for high-dimensional confounders without requiring models for their association with the outcome of interest. The results of statistical analyses based on stratification, matching or inverse weighting by the propensity score are therefore less susceptible to model extrapolation than those based solely on outcome regression models. This is attractive because extrapolation in outcome regression models may be alarming, yet difficult to diagnose, when the exposed and unexposed individuals have very different covariate distributions. Standard regression adjustment for the propensity score forms an alternative to the aforementioned propensity score methods, but the benefits of this are less clear because it still involves modelling the outcome in addition to the propensity score. In this article, we develop novel insights into the properties of this adjustment method. We demonstrate that standard tests of the null hypothesis of no exposure effect (based on robust variance estimators), as well as particular standardised effects obtained from such adjusted regression models, are robust against misspecification of the outcome model when a propensity score model is correctly specified; they are thus not vulnerable to the aforementioned problem of extrapolation. We moreover propose efficient estimators for these standardised effects, which retain a useful causal interpretation even when the propensity score model is misspecified, provided the outcome regression model is correctly specified.}},
    author = {Vansteelandt, S. and Daniel, R. M.},
    citeulike-article-id = {13878054},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6207},
    doi = {10.1002/sim.6207},
    isbn = {1097-0258; 0277-6715},
    journal = {Statistics in Medicine},
    keywords = {exportrecords, observational-study---general, propensity-scores},
    number = {23},
    pages = {4053--4072},
    posted-at = {2015-12-09 01:12:40},
    priority = {3},
    title = {{On regression adjustment for the propensity score}},
    url = {http://dx.doi.org/10.1002/sim.6207},
    volume = {33},
    year = {2014}
}

@article{35829,
    abstract = {{We assess the asymptotic bias of estimates of exposure effects conditional on covariates when summary scores of confounders, instead of the confounders themselves, are used to analyze observational data. First, we study regression models for cohort data that are adjusted for summary scores. Second, we derive the asymptotic bias for case-control studies when cases and controls are matched on a summary score, and then analyzed either using conditional logistic regression or by unconditional logistic regression adjusted for the summary score. Two scores, the propensity score (PS) and the disease risk score (DRS) are studied in detail. For cohort analysis, when regression models are adjusted for the PS, the estimated conditional treatment effect is unbiased only for linear models, or at the null for non-linear models. Adjustment of cohort data for DRS yields unbiased estimates only for linear regression; all other estimates of exposure effects are biased. Matching cases and controls on DRS and analyzing them using conditional logistic regression yields unbiased estimates of exposure effect, whereas adjusting for the DRS in unconditional logistic regression yields biased estimates, even under the null hypothesis of no association. Matching cases and controls on the PS yield unbiased estimates only under the null for both conditional and unconditional logistic regression, adjusted for the PS. We study the bias for various confounding scenarios and compare our asymptotic results with those from simulations with limited sample sizes. To create realistic correlations among multiple confounders, we also based simulations on a real dataset. Copyright (c) 2015 John Wiley \& Sons, Ltd.}},
    author = {Pfeiffer, R. M. and Riedl, R.},
    citeulike-article-id = {13877956},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6467},
    doi = {10.1002/sim.6467},
    isbn = {1097-0258; 0277-6715},
    journal = {Statistics in Medicine},
    keywords = {confounding, exportrecords, observational-study---methods, propensity-scores},
    number = {18},
    pages = {2618--2635},
    posted-at = {2015-12-09 01:12:38},
    priority = {3},
    title = {{On the use and misuse of scalar scores of confounders in design and analysis of observational studies}},
    url = {http://dx.doi.org/10.1002/sim.6467},
    volume = {34},
    year = {2015}
}

@article{44045,
    abstract = {{OBJECTIVES: Propensity score (PS) and instrumental variable (IV) are analytical techniques used to adjust for confounding in observational research. More and more, they seem to be used simultaneously in studies evaluating health interventions. The present review aimed to analyze the agreement between PS and IV results in medical research published to date. STUDY DESIGN AND SETTING: Review of all published observational studies that evaluated a clinical intervention using simultaneously PS and IV analyses, as identified in MEDLINE and Web of Science. RESULTS: Thirty-seven studies, most of them published during the previous 5 years, reported 55 comparisons between results from PS and IV analyses. There was a slight/fair agreement between the methods [Cohen's kappa coefficient = 0.21 (95\% confidence interval: 0.00, 0.41)]. In 23 cases (42\%), results were nonsignificant for one method and significant for the other, and IV analysis results were nonsignificant in most situations (87\%). CONCLUSION: Discrepancies are frequent between PS and IV analyses and can be interpreted in various ways. This suggests that researchers should carefully consider their analytical choices, and readers should be cautious when interpreting results, until further studies clarify the respective roles of the two methods in observational comparative effectiveness research. Copyright {\copyright} 2015 Elsevier Inc. All rights reserved.}},
    author = {Laborde-Cast\'{e}rot, H. and Agrinier, N. and Thilly, N.},
    citeulike-article-id = {13877906},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2015.04.003},
    doi = {10.1016/j.jclinepi.2015.04.003},
    isbn = {1878-5921; 0895-4356},
    journal = {Journal of Clinical Epidemiology},
    keywords = {confounding, exportrecords, instrumental-variables, observational-study---criticism, observational-study---methods, propensity-scores, statistics},
    number = {10},
    pages = {1232--1240},
    posted-at = {2015-12-09 01:12:36},
    priority = {3},
    title = {{Performing both propensity score and instrumental variable analyses in observational studies often leads to discrepant results: a systematic review}},
    url = {http://dx.doi.org/10.1016/j.jclinepi.2015.04.003},
    volume = {68},
    year = {2015}
}

@proceedings{43631,
    abstract = {{It is essential to reduce potential bias by adjusting for confounders when performing real world data analysis. It is informative to investigate usage of various methods for adjusting confounders in estimating comparative effectiveness.}},
    author = {Choi, S.},
    booktitle = {ISPOR 20th Annual International Meeting Research Abstracts},
    citeulike-article-id = {13877743},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jval.2015.03.076},
    doi = {10.1016/j.jval.2015.03.076},
    issn = {1098-3015},
    journal = {Value in Health},
    keywords = {confounding, exportrecords, instrumental-variables, propensity-scores},
    number = {3},
    pages = {A11--A12},
    posted-at = {2015-12-09 01:12:33},
    priority = {3},
    title = {{Usage Of Propensity Score, Instrumental Variable, Or Machine Learning For Real World Data Analysis}},
    url = {http://dx.doi.org/10.1016/j.jval.2015.03.076},
    volume = {18},
    year = {2015}
}

@article{32016,
    abstract = {{Propensity-score matching is frequently used to estimate the effect of treatments, exposures, and interventions when using observational data. An important issue when using propensity-score matching is how to estimate the standard error of the estimated treatment effect. Accurate variance estimation permits construction of confidence intervals that have the advertised coverage rates and tests of statistical significance that have the correct type I error rates. There is disagreement in the literature as to how standard errors should be estimated. The bootstrap is a commonly used resampling method that permits estimation of the sampling variability of estimated parameters. Bootstrap methods are rarely used in conjunction with propensity-score matching. We propose two different bootstrap methods for use when using propensity-score matching without replacementand examined their performance with a series of Monte Carlo simulations. The first method involved drawing bootstrap samples from the matched pairs in the propensity-score-matched sample. The second method involved drawing bootstrap samples from the original sample and estimating the propensity score separately in each bootstrap sample and creating a matched sample within each of these bootstrap samples. The former approach was found to result in estimates of the standard error that were closer to the empirical standard deviation of the sampling distribution of estimated effects. (c) 2014 The Authors Statistics in Medicine Published by John Wiley \& Sons, Ltd.}},
    author = {Austin, P. C. and Small, D. S.},
    citeulike-article-id = {13877358},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6276},
    doi = {10.1002/sim.6276},
    isbn = {1097-0258; 0277-6715},
    journal = {Statistics in Medicine},
    keywords = {exportrecords, propensity-scores},
    number = {24},
    pages = {4306--4319},
    posted-at = {2015-12-09 01:12:22},
    priority = {3},
    title = {{The use of bootstrapping when using propensity-score matching without replacement: a simulation study}},
    url = {http://dx.doi.org/10.1002/sim.6276},
    volume = {33},
    year = {2014}
}

@article{31681,
    abstract = {{Propensity-score matching is frequently used to reduce the effects of confounding when using observational data to estimate the effects of treatments. Matching allows one to estimate the average effect of treatment in the treated. Rosenbaum and Rubin coined the term "bias due to incomplete matching" to describe the bias that can occur when some treated subjects are excluded from the matched sample because no appropriate control subject was available. The presence of incomplete matching raises important questions around the generalizability of estimated treatment effects to the entire population of treated subjects. We describe an analytic solution to address the bias due to incomplete matching. Our method is based on using optimal or nearest neighbor matching, rather than caliper matching (which frequently results in the exclusion of some treated subjects). Within the sample matched on the propensity score, covariate adjustment using the propensity score is then employed to impute missing potential outcomes under lack of treatment for each treated subject. Using Monte Carlo simulations, we found that the proposed method resulted in estimates of treatment effect that were essentially unbiased. This method resulted in decreased bias compared to caliper matching alone and compared to either optimal matching or nearest neighbor matching alone. Caliper matching alone resulted in design bias or bias due to incomplete matching, while optimal matching or nearest neighbor matching alone resulted in bias due to residual confounding. The proposed method also tended to result in estimates with decreased mean squared error compared to when caliper matching was used.}},
    author = {Austin, P. C.},
    citeulike-article-id = {13877354},
    citeulike-linkout-0 = {http://dx.doi.org/10.1177/0962280214543508},
    doi = {10.1177/0962280214543508},
    isbn = {1477-0334; 0962-2802},
    journal = {Statistical Methods in Medical Research},
    keywords = {exportrecords, propensity-scores},
    posted-at = {2015-12-09 01:12:22},
    priority = {3},
    title = {{Double propensity-score adjustment: A solution to design bias or bias due to incomplete matching}},
    url = {http://dx.doi.org/10.1177/0962280214543508}
}

@article{31393,
    abstract = {{BACKGROUND AND OBJECTIVES: Sepsis is a leading cause of mortality and morbidity in the intensive care unit, and many studies have been conducted aiming to improve its outcome. Randomized controlled trials (RCTs) and observational studies using propensity score (PS) method are commonly used for this purpose. However, the agreement between these two major methodological designs has never been investigated in this specific area. The present study aimed to compare the effect sizes between RCTs and PS-based studies. METHODS: Electronic databases including Pubmed, Scopus, and EBSCO were searched to obtain PS-based studies in the area of sepsis. The studies were matched to RCTs or systematic reviews and meta-analysis in terms of population, intervention, control, and outcome. When there were multiple PS-based studies or RCTs in one area, the effect sizes were pooled by using random-effects model and inverse variance method. The comparisons were performed by using differences in the effect size. RESULTS: A total of 8 topics were identified fulfilling the criterion that at least 1 pair of RCT and PS-based study could be matched. The interventions included activated protein C, low-dose steroid, antithrombin III, combination antibiotic therapy, fish oil supplementation, statin, etomidate for intubation, and recombinant human soluble thrombomodulin. The effect sizes were statistically different between RCTs and PS-based studies in most circumstances (6/8). The pooled mean difference in effect sizes was -0.16 (95\% confidence interval, -0.33 to 0.01), indicating a trend towards larger treatment effect in PS studies than in RCTs. The result remains unaltered by restricting to RCTs and PS studies with the largest sample sizes. CONCLUSION: Our study shows that PS studies tend to report larger treatment effect than RCTs in the field of sepsis, indicating the difference between efficacy trials and effectiveness studies. Copyright {\copyright} 2014 Elsevier Inc. All rights reserved.}},
    author = {Zhang, Z. and Ni, H. and Xu, X.},
    citeulike-article-id = {13877334},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jcrc.2014.05.023},
    doi = {10.1016/j.jcrc.2014.05.023},
    isbn = {1557-8615; 0883-9441},
    journal = {Journal of Critical Care},
    keywords = {discordant-results, exportrecords, propensity-scores, randomized-vs-non-randomized-study-designs},
    number = {5},
    pages = {886.e9-15+},
    posted-at = {2015-12-09 01:12:21},
    priority = {3},
    title = {{Do the observational studies using propensity score analysis agree with randomized controlled trials in the area of sepsis?}},
    url = {http://dx.doi.org/10.1016/j.jcrc.2014.05.023},
    volume = {29},
    year = {2014}
}

@article{30419,
    abstract = {{BACKGROUND AND OBJECTIVE: Propensity score (PS) analysis has been increasingly used in critical care medicine; however, its validation has not been systematically investigated. The present study aimed to compare effect sizes in PS-based observational studies vs. randomized controlled trials (RCTs) (or meta-analysis of RCTs). METHODS: Critical care observational studies using PS were systematically searched in PubMed from inception to April 2013. Identified PS-based studies were matched to one or more RCTs in terms of population, intervention, comparison, and outcome. The effect sizes of experimental treatments were compared for PS-based studies vs. RCTs (or meta-analysis of RCTs) with sign test. Furthermore, ratio of odds ratio (ROR) was calculated from the interaction term of treatment × study type in a logistic regression model. A ROR < 1 indicates greater benefit for experimental treatment in RCTs compared with PS-based studies. RORs of each comparison were pooled by using meta-analytic approach with random-effects model. RESULTS: A total of 20 PS-based studies were identified and matched to RCTs. Twelve of the 20 comparisons showed greater beneficial effect for experimental treatment in RCTs than that in PS-based studies (sign test P = 0.503). The difference was statistically significant in four comparisons. ROR can be calculated from 13 comparisons, of which four showed significantly greater beneficial effect for experimental treatment in RCTs. The pooled ROR was 0.71 (95\% CI: 0.63, 0.79; P = 0.002), suggesting that RCTs (or meta-analysis of RCTs) were more likely to report beneficial effect for the experimental treatment than PS-based studies. The result remained unchanged in sensitivity analysis and meta-regression. CONCLUSION: In critical care literature, PS-based observational study is likely to report less beneficial effect of experimental treatment compared with RCTs (or meta-analysis of RCTs). Copyright {\copyright} 2014 Elsevier Inc. All rights reserved.}},
    author = {Zhang, Z. and Ni, H. and Xu, X.},
    citeulike-article-id = {13877329},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2014.02.018},
    doi = {10.1016/j.jclinepi.2014.02.018},
    isbn = {1878-5921; 0895-4356},
    journal = {Journal of Clinical Epidemiology},
    keywords = {effect-size, exportrecords, observational-study---criticism, propensity-scores},
    number = {8},
    pages = {932--939},
    posted-at = {2015-12-09 01:12:21},
    priority = {3},
    title = {{Observational studies using propensity score analysis underestimated the effect sizes in critical care medicine}},
    url = {http://dx.doi.org/10.1016/j.jclinepi.2014.02.018},
    volume = {67},
    year = {2014}
}

@article{45235,
    abstract = {{PURPOSE: We use simulations and an empirical example to evaluate the performance of disease risk score (DRS) matching compared with propensity score (PS) matching when controlling large numbers of covariates in settings involving newly introduced treatments. METHODS: We simulated a dichotomous treatment, a dichotomous outcome, and 100 baseline covariates that included both continuous and dichotomous random variables. For the empirical example, we evaluated the comparative effectiveness of dabigatran versus warfarin in preventing combined ischemic stroke and all-cause mortality. We matched treatment groups on a historically estimated DRS and again on the PS. We controlled for a high-dimensional set of covariates using 20\% and 1\% samples of Medicare claims data from October 2010 through December 2012. RESULTS: In simulations, matching on the DRS versus the PS generally yielded matches for more treated individuals and improved precision of the effect estimate. For the empirical example, PS and DRS matching in the 20\% sample resulted in similar hazard ratios (0.88 and 0.87) and standard errors (0.04 for both methods). In the 1\% sample, PS matching resulted in matches for only 92.0\% of the treated population and a hazard ratio and standard error of 0.89 and 0.19, respectively, while DRS matching resulted in matches for 98.5\% and a hazard ratio and standard error of 0.85 and 0.16, respectively. CONCLUSIONS: When PS distributions are separated, DRS matching can improve the precision of effect estimates and allow researchers to evaluate the treatment effect in a larger proportion of the treated population. However, accurately modeling the DRS can be challenging compared with the PS. Copyright {\copyright} 2015 John Wiley \& Sons, Ltd. Copyright {\copyright} 2015 John Wiley \& Sons, Ltd.}},
    author = {Wyss, R. and Ellis, A. R. and Brookhart, M. A. and Jonsson Funk, M. and Girman, C. J. and Simpson and St\"{u}rmer, T.},
    citeulike-article-id = {13877312},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.3810},
    doi = {10.1002/pds.3810},
    isbn = {1099-1557; 1053-8569},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {comparative-effectiveness-research---methods, disease-risk-scores, exportrecords, propensity-scores},
    posted-at = {2015-12-09 01:12:21},
    priority = {3},
    title = {{Matching on the disease risk score in comparative effectiveness research of new treatments}},
    url = {http://dx.doi.org/10.1002/pds.3810}
}

@article{45573,
    abstract = {{Considering that the absence of measurement error in research is a rare phenomenon and its effects can be dramatic, we examine the impact of measurement error on propensity score (PS) analysis used to minimize selection bias in behavioral and social observational studies. A Monte Carlo study was conducted to explore the effects of measurement error on the treatment effect and balance estimates in PS analysis across seven different PS conditioning methods. In general, the results indicate that even low levels of measurement error in the covariates lead to substantial bias in estimates of treatment effects and concomitant reduction in confidence interval coverage across all methods of conditioning on the PS.}},
    author = {Rodr\'{\i}guez de Gil, P. and Bellara, A. P. and Lanehart, R. E. and Lee, R. S. and Kim, E. S. and Kromrey, J. D.},
    citeulike-article-id = {13877251},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/00273171.2015.1022643},
    doi = {10.1080/00273171.2015.1022643},
    isbn = {0027-3171; 1532-7906},
    journal = {Multivariate Behavioral Research},
    keywords = {exportrecords, observational-study---general, propensity-scores},
    posted-at = {2015-12-09 01:12:19},
    priority = {3},
    title = {{How Do Propensity Score Methods Measure Up in the Presence of Measurement Error? A Monte Carlo Study}},
    url = {http://dx.doi.org/10.1080/00273171.2015.1022643}
}

@article{45260,
    abstract = {{OBJECTIVE: To assess the degree of agreement between propensity score studies and randomized clinical trials in critical care research. DATA SOURCES: Propensity score studies published in highly cited critical care or general medicine journals or included in a previous systematic review; corresponding randomized clinical trials included in Cochrane Systematic Reviews or published in PubMed. STUDY SELECTION: We identified propensity score studies of the effects of therapeutic interventions on short- or long-term mortality. We systematically matched propensity score studies to randomized clinical trials based on patient selection criteria, interventions, and outcomes. DATA EXTRACTION: We appraised the methods of included studies and extracted treatment effect estimates to compare the results of propensity score studies and randomized clinical trials. When multiple studies were identified for the same topic, we performed meta-analyses to obtain summary treatment effect estimates. DATA SYNTHESIS: We matched 21 propensity score studies with 58 randomized clinical trials in 18 distinct comparisons (median, one propensity score study and two randomized clinical trials per comparison), for short- and long-term mortality. We found one statistically significant difference between designs (hyperoncotic albumin vs crystalloid fluids) among these 18 comparisons. Propensity score studies did not produce systematically higher (or lower) treatment effect estimates compared with randomized clinical trials, but estimates from the two designs differed by more than 30\% in one third of the comparisons examined. Observational studies in critical care met widely accepted methodological standards for propensity score analyses. CONCLUSIONS: Across diverse critical care topics, propensity score studies published in high-impact journals produced results that were generally consistent with the findings of randomized clinical trials. However, caution is needed when interpreting propensity score studies because occasionally their results contradict those of randomized clinical trials and there is no reliable way to predict disagreements.}},
    author = {Kitsios, G. D. and Dahabreh, I. J. and Callahan, S. and Paulus, J. K. and Campagna, A. C. and Dargin, J. M.},
    citeulike-article-id = {13877164},
    citeulike-linkout-0 = {http://dx.doi.org/10.1097/CCM.0000000000001135},
    doi = {10.1097/CCM.0000000000001135},
    isbn = {1530-0293; 0090-3493},
    journal = {Critical Care Medicine},
    keywords = {exportrecords, observational-study---criticism, propensity-scores, source---cochrane-reviews},
    number = {9},
    pages = {1870--1879},
    posted-at = {2015-12-09 01:12:17},
    priority = {3},
    title = {{Can We Trust Observational Studies Using Propensity Scores in the Critical Care Literature? A Systematic Comparison With Randomized Clinical Trials}},
    url = {http://dx.doi.org/10.1097/CCM.0000000000001135},
    volume = {43},
    year = {2015}
}

@article{45286,
    abstract = {{PURPOSE: The generalisability of randomised controlled trials (RCTs) may be limited by restrictive entry criteria or by their experimental nature. Observational research can provide complementary findings but is prone to bias. Employing propensity score matching, to reduce such bias, we compared the real-life effect of cinacalcet use on all-cause mortality (ACM) with findings from the Evaluation of Cinacalcet Therapy to Lower Cardiovascular Events (EVOLVE) RCT in chronic haemodialysis patients. METHODS: Incident adult haemodialysis patients receiving cinacalcet, recruited in a prospective observational cohort from 2007-2009 (AROii; n = 10,488), were matched to non-exposed patients regardless of future exposure status. The effect of treatment crossover was investigated with inverse probability of censoring weighted and lag-censored analyses. EVOLVE ACM data were analysed largely as described for the primary composite endpoint. RESULTS: AROii patients receiving cinacalcet (n = 532) were matched to 1790 non-exposed patients. The treatment effect of cinacalcet on ACM in the main AROii analysis (hazard ratio 1.03 [95\% confidence interval (CI) 0.78-1.35]) was closer to the null than for the Intention to Treat (ITT) analysis of EVOLVE (0.94 [95\%CI 0.85-1.04]). Adjusting for non-persistence by 0- and 6-month lag-censoring and by inverse probability of censoring weight, the hazard ratios in AROii (0.76 [95\%CI 0.51-1.15], 0.84 [95\%CI 0.60-1.18] and 0.79 [95\%CI 0.56-1.11], respectively) were comparable with those of EVOLVE (0.82 [95\%CI 0.67-1.01], 0.83 [95\%CI 0.73-0.96] and 0.87 [95\%CI 0.71-1.06], respectively). CONCLUSIONS: Correcting for treatment crossover, we observed results in the 'real-life' setting of the AROii observational cohort that closely mirrored the results of the EVOLVE RCT. Persistence-corrected analyses revealed a trend towards reduced ACM in haemodialysis patients receiving cinacalcet therapy. Copyright {\copyright} 2015 John Wiley \& Sons, Ltd. Copyright {\copyright} 2015 John Wiley \& Sons, Ltd.}},
    author = {Gillespie, I. A. and Floege, J. and Gioni, I. and Dr\"{u}eke, T. B. and de Francisco, A. L. and Anker, S. D. and Kubo, Y. and Wheeler, D. C. and Froissart, M. and ARO Steering Committee Collaborators},
    citeulike-article-id = {13877122},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.3789},
    doi = {10.1002/pds.3789},
    isbn = {1099-1557; 1053-8569},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {comparative-effectiveness-research---methods, exportrecords, observational-study---methods, propensity-scores},
    number = {7},
    pages = {738--747},
    posted-at = {2015-12-09 01:12:15},
    priority = {3},
    title = {{Propensity score matching and persistence correction to reduce bias in comparative effectiveness: the effect of cinacalcet use on all-cause mortality}},
    url = {http://dx.doi.org/10.1002/pds.3789},
    volume = {24},
    year = {2015}
}

@article{45837,
    abstract = {{Observational studies using propensity-score methods have been increasing in the cardiovascular literature because randomized controlled trials are not always feasible or ethical. However, propensity-score methods can be confusing, and the general audience may not fully understand the importance of this technique. The objectives of this review are to describe (1) the fundamentals of propensity score methods, (2) the techniques to assess for propensity-score model adequacy, (3) the 4 major methods for using the propensity score (matching, stratification, covariate adjustment, and inverse probability of treatment weighting [IPTW]) using examples from previously published cardiovascular studies, and (4) the strengths and weaknesses of these 4 techniques. Our review suggests that matching or IPTW using the propensity score have shown to be most effective in reducing bias of the treatment effect.}},
    author = {Deb, S. and Austin, P. C. and Tu, J. V. and Ko, D. T. and Mazer, C. D. and Kiss, A. and Fremes, S. E.},
    citeulike-article-id = {13877098},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.cjca.2015.05.015},
    doi = {10.1016/j.cjca.2015.05.015},
    isbn = {1916-7075; 0828-282X},
    journal = {Canadian Journal of Cardiology},
    keywords = {exportrecords, observational-study---methods, propensity-scores},
    posted-at = {2015-12-09 01:12:15},
    priority = {3},
    title = {{A Review of Propensity-Score Methods and Their Use in Cardiovascular Research}},
    url = {http://dx.doi.org/10.1016/j.cjca.2015.05.015}
}

@article{30083,
    abstract = {{Causal inference with observational data frequently relies on the notion of the propensity score (PS) to adjust treatment comparisons for observed confounding factors. As decisions in the era of "big data" are increasingly reliant on large and complex collections of digital data, researchers are frequently confronted with decisions regarding which of a high-dimensional covariate set to include in the PS model in order to satisfy the assumptions necessary for estimating average causal effects. Typically, simple or ad-hoc methods are employed to arrive at a single PS model, without acknowledging the uncertainty associated with the model selection. We propose three Bayesian methods for PS variable selection and model averaging that 1) select relevant variables from a set of candidate variables to include in the PS model and 2) estimate causal treatment effects as weighted averages of estimates under different PS models. The associated weight for each PS model reflects the data-driven support for that model's ability to adjust for the necessary variables. We illustrate features of our proposed approaches with a simulation study, and ultimately use our methods to compare the effectiveness of surgical vs. nonsurgical treatment for brain tumors among 2,606 Medicare beneficiaries. Supplementary materials are available online.}},
    author = {Zigler, C. M. and Dominici, F.},
    citeulike-article-id = {13877022},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/01621459.2013.869498},
    doi = {10.1080/01621459.2013.869498},
    issn = {0162-1459},
    journal = {Journal of the American Statistical Association},
    keywords = {exportrecords, propensity-scores, statistics},
    number = {505},
    pages = {95--107},
    posted-at = {2015-12-09 01:12:13},
    priority = {3},
    title = {{Uncertainty in Propensity Score Estimation: Bayesian Methods for Variable Selection and Model-Averaged Causal Effects}},
    url = {http://dx.doi.org/10.1080/01621459.2013.869498},
    volume = {109},
    year = {2014}
}

@article{30191,
    abstract = {{PURPOSE: Differing healthcare access has implications for public health. In Ireland, eligibility for free public health care is means tested. Here, we examine the association between healthcare access and polypharmacy while accounting for underlying socio-economic and health status differences. METHODS: Self-reported regular medication use, history of diagnosed health conditions, disability, socio-demographics, and objective measures of depression and anxiety for adults aged 50-69 years (n = 5796) were ascertained from the population-representative Irish Longitudinal Study on Ageing. Objective measures of frailty, cognition, hypertension, and body mass index were also assessed for 4241 participants. The associations between free healthcare access and polypharmacy and use of 15 medication classes were estimated using multivariable modified Poisson regression, adjustment for the propensity score, and inverse probability of treatment weighting by the propensity score. RESULTS: Polypharmacy was reported by 22\% and 7\% of the 1932 and 3864 participants with and without public healthcare coverage. Public patients had a 21-38\% greater risk of polypharmacy depending on the method used to account for confounding. Results were less robust using propensity score weighting. There was evidence that classes of cardiovascular drugs, drugs for acid-related disorders, and analgesics were used more commonly in public patients. Associations were mostly unaffected after also accounting for objective health measures but were significantly attenuated after accounting for frequency of healthcare visits. CONCLUSIONS: Publically funded health care in Ireland leads to greater medication use in people aged 50-69 years. This may reflect over-prescribing to public patients or restricted use among those who pay out of pocket. Copyright {\copyright} 2014 John Wiley \& Sons, Ltd. Copyright {\copyright} 2014 John Wiley \& Sons, Ltd.}},
    author = {Richardson, K. and Kenny, R. A. and Bennett, K.},
    citeulike-article-id = {13876999},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.3590},
    doi = {10.1002/pds.3590},
    isbn = {1099-1557; 1053-8569},
    journal = {Pharmacoepidemiology and drug safety},
    keywords = {confounding, exportrecords, propensity-scores},
    posted-at = {2015-12-09 01:12:12},
    priority = {3},
    title = {{The effect of free health care on polypharmacy: a comparison of propensity score methods and multivariable regression to account for confounding}},
    url = {http://dx.doi.org/10.1002/pds.3590}
}

@article{28794,
    abstract = {{OBJECTIVE: We aimed to compare treatment effect estimates from NRSs with PS analysis and RCTs of surgery. BACKGROUND: Evaluating a surgical procedure in randomized controlled trials (RCTs) is challenging. Nonrandomized studies (NRSs) involving use of propensity score (PS) analysis to limit bias are of increasing interest. DESIGN: Meta-epidemiological study. METHODS: We systematically searched MEDLINE via PubMed for all prospective NRSs with PS analysis evaluating a surgical procedure. Related RCTs, addressing the same clinical questions, were systematically retrieved. Our primary outcome of interest was all-cause mortality. We also selected 1 subjective outcome. We calculated the summary odds ratios (OR) for each study design, the ratio of OR (ROR) between the designs and the summary ROR across clinical questions. An ROR < 1 indicated that the experimental intervention is more favorable in NRSs with PS analysis than RCTs. RESULTS: We retrieved 70 reports of NRSs with PS analysis and 94 related RCTs evaluating 31 clinical questions, of which 22 assessed all-cause mortality and 26 a subjective outcome. The combined ROR for all-cause mortality was 0.83 (95\% confidence interval: 0.65-1.04). For subjective outcomes, the combined ROR was 1.07 (0.87-1.33). CONCLUSIONS: There was no statistically significant difference in treatment effect between NRSs with PS analysis and RCTs. Prospective NRSs with suitable and careful PS analysis can be relied upon as evidence when RCTs are not possible.}},
    author = {Lonjon, G. and Boutron, I. and Trinquart, L. and Ahmad, N. and Aim, F. and Nizard, R. and Ravaud, P.},
    citeulike-article-id = {13876927},
    citeulike-linkout-0 = {http://dx.doi.org/10.1097/SLA.0000000000000256},
    doi = {10.1097/SLA.0000000000000256},
    isbn = {1528-1140; 0003-4932},
    journal = {Annals of Surgery},
    keywords = {effect-measures, exportrecords, propensity-scores},
    number = {1},
    pages = {18--25},
    posted-at = {2015-12-09 01:12:11},
    priority = {3},
    title = {{Comparison of treatment effect estimates from prospective nonrandomized studies with propensity score analysis and randomized controlled trials of surgical procedures}},
    url = {http://dx.doi.org/10.1097/SLA.0000000000000256},
    volume = {259},
    year = {2014}
}

@article{29210,
    abstract = {{PURPOSE: Researchers are often interested in estimating treatment effects in subgroups controlling for confounding based on a propensity score (PS) estimated in the overall study population. OBJECTIVE: To evaluate covariate balance and confounding control in sulfonylurea versus metformin initiators within subgroups defined by cardiovascular disease (CVD) history comparing an overall PS with subgroup-specific PSs implemented by 1:1 matching and stratification. METHODS: We analyzed younger patients from a US insurance claims database and older patients from 2 Medicare (Humana Medicare Advantage, fee-for-service Medicare Parts A, B, and D) datasets. Confounders and risk factors for acute myocardial infarction were included in an overall PS and subgroup PSs with and without CVD. Covariate balance was assessed using the average standardized absolute mean difference (ASAMD). RESULTS: Compared with crude estimates, ASAMD across covariates was improved 70\%-94\% for stratification for Medicare cohorts and 44\%-99\% for the younger cohort, with minimal differences between overall and subgroup-specific PSs. With matching, 75\%-99\% balance improvement was achieved regardless of cohort and PS, but with smaller sample size. Hazard ratios within each CVD subgroup differed minimally among PS and cohorts. CONCLUSIONS: Both overall PSs and CVD subgroup-specific PSs achieved good balance on measured covariates when assessing the relative association of diabetes monotherapy with nonfatal myocardial infarction. PS matching generally led to better balance than stratification, but with smaller sample size. Our study is limited insofar as crude differences were minimal, suggesting that the new user, active comparator design identified patients with some equipoise between treatments.}},
    author = {Girman, C. J. and Gokhale, M. and Kou, T. D. and Brodovicz, K. G. and Wyss, R. and St\"{u}rmer, T.},
    citeulike-article-id = {13876888},
    citeulike-linkout-0 = {http://dx.doi.org/10.1097/MLR.0000000000000064},
    doi = {10.1097/MLR.0000000000000064},
    isbn = {1537-1948; 0025-7079},
    journal = {Medical Care},
    keywords = {exportrecords, propensity-scores, subgroup-analysis},
    number = {3},
    pages = {280--287},
    posted-at = {2015-12-09 01:12:10},
    priority = {3},
    title = {{Assessing the Impact of Propensity Score Estimation and Implementation on Covariate Balance and Confounding Control Within and Across Important Subgroups in Comparative Effectiveness Research}},
    url = {http://dx.doi.org/10.1097/MLR.0000000000000064},
    volume = {52},
    year = {2014}
}

@article{29249,
    abstract = {{This paper examines the use of propensity score matching in economic analyses of observational data. Several excellent papers have previously reviewed practical aspects of propensity score estimation and other aspects of the propensity score literature. The purpose of this paper is to compare the conceptual foundation of propensity score models with alternative estimators of treatment effects. References are provided to empirical comparisons among methods that have appeared in the literature. These comparisons are available for a subset of the methods considered in this paper. However, in some cases, no pairwise comparisons of particular methods are yet available, and there are no examples of comparisons across all of the methods surveyed here. Irrespective of the availability of empirical comparisons, the goal of this paper is to provide some intuition about the relative merits of alternative estimators in health economic evaluations where nonlinearity, sample size, availability of pre/post data, heterogeneity, and missing variables can have important implications for choice of methodology. Also considered is the potential combination of propensity score matching with alternative methods such as differences-in-differences and decomposition methods that have not yet appeared in the empirical literature.}},
    author = {Crown, W. H.},
    citeulike-article-id = {13876857},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s40258-013-0075-4},
    doi = {10.1007/s40258-013-0075-4},
    isbn = {1179-1896; 1175-5652},
    journal = {Applied health economics and health policy},
    keywords = {economic-evaluations---methods, exportrecords, propensity-scores},
    number = {1},
    pages = {7--18},
    posted-at = {2015-12-09 01:12:09},
    priority = {3},
    title = {{Propensity-Score Matching in Economic Analyses: Comparison with Regression Models, Instrumental Variables, Residual Inclusion, Differences-in-Differences, and Decomposition Methods}},
    url = {http://dx.doi.org/10.1007/s40258-013-0075-4},
    volume = {12},
    year = {2014}
}

@article{29698,
    abstract = {{Propensity-score matching is increasingly being used to reduce the confounding that can occur in observational studies examining the effects of treatments or interventions on outcomes. We used Monte Carlo simulations to examine the following algorithms for forming matched pairs of treated and untreated subjects: optimal matching, greedy nearest neighbor matching without replacement, and greedy nearest neighbor matching without replacement within specified caliper widths. For each of the latter two algorithms, we examined four different sub-algorithms defined by the order in which treated subjects were selected for matching to an untreated subject: lowest to highest propensity score, highest to lowest propensity score, best match first, and random order. We also examined matching with replacement. We found that (i) nearest neighbor matching induced the same balance in baseline covariates as did optimal matching; (ii) when at least some of the covariates were continuous, caliper matching tended to induce balance on baseline covariates that was at least as good as the other algorithms; (iii) caliper matching tended to result in estimates of treatment effect with less bias compared with optimal and nearest neighbor matching; (iv) optimal and nearest neighbor matching resulted in estimates of treatment effect with negligibly less variability than did caliper matching; (v) caliper matching had amongst the best performance when assessed using mean squared error; (vi) the order in which treated subjects were selected for matching had at most a modest effect on estimation; and (vii) matching with replacement did not have superior performance compared with caliper matching without replacement.}},
    author = {Austin, P. C.},
    citeulike-article-id = {13876845},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6004},
    doi = {10.1002/sim.6004},
    isbn = {1097-0258; 0277-6715},
    journal = {Statistics in medicine},
    keywords = {exportrecords, propensity-scores},
    number = {6},
    pages = {1057--1069},
    posted-at = {2015-12-09 01:12:09},
    priority = {3},
    title = {{A comparison of 12 algorithms for matching on the propensity score}},
    url = {http://dx.doi.org/10.1002/sim.6004},
    volume = {33},
    year = {2014}
}

@article{29526,
    abstract = {{Observational studies are increasingly being used to estimate the effect of treatments, interventions and exposures on outcomes that can occur over time. Historically, the hazard ratio, which is a relative measure of effect, has been reported. However, medical decision making is best informed when both relative and absolute measures of effect are reported. When outcomes are time-to-event in nature, the effect of treatment can also be quantified as the change in mean or median survival time due to treatment and the absolute reduction in the probability of the occurrence of an event within a specified duration of follow-up. We describe how three different propensity score methods, propensity score matching, stratification on the propensity score and inverse probability of treatment weighting using the propensity score, can be used to estimate absolute measures of treatment effect on survival outcomes. These methods are all based on estimating marginal survival functions under treatment and lack of treatment. We then conducted an extensive series of Monte Carlo simulations to compare the relative performance of these methods for estimating the absolute effects of treatment on survival outcomes. We found that stratification on the propensity score resulted in the greatest bias. Caliper matching on the propensity score and a method based on earlier work by Cole and Hernan tended to have the best performance for estimating absolute effects of treatment on survival outcomes. When the prevalence of treatment was less extreme, then inverse probability of treatment weighting-based methods tended to perform better than matching-based methods.}},
    author = {Austin, P. C. and Schuster, T.},
    citeulike-article-id = {13876844},
    citeulike-linkout-0 = {http://dx.doi.org/10.1177/0962280213519716},
    doi = {10.1177/0962280213519716},
    isbn = {1477-0334; 0962-2802},
    journal = {Statistical Methods in Medical Research},
    keywords = {exportrecords, propensity-scores},
    posted-at = {2015-12-09 01:12:09},
    priority = {3},
    title = {{The performance of different propensity score methods for estimating absolute effects of treatments on survival outcomes: A simulation study}},
    url = {http://dx.doi.org/10.1177/0962280213519716}
}

@article{25513,
    abstract = {{Propensity score methods are increasingly being used to estimate causal treatment effects in observational studies. In medical and epidemiological studies, outcomes are frequently time-to-event in nature. Propensity-score methods are often applied incorrectly when estimating the effect of treatment on time-to-event outcomes. This article describes how two different propensity score methods (matching and inverse probability of treatment weighting) can be used to estimate the measures of effect that are frequently reported in randomized controlled trials: (i) marginal survival curves, which describe survival in the population if all subjects were treated or if all subjects were untreated; and (ii) marginal hazard ratios. The use of these propensity score methods allows one to replicate the measures of effect that are commonly reported in randomized controlled trials with time-to-event outcomes: both absolute and relative reductions in the probability of an event occurring can be determined. We also provide guidance on variable selection for the propensity score model, highlight methods for assessing the balance of baseline covariates between treated and untreated subjects, and describe the implementation of a sensitivity analysis to assess the effect of unmeasured confounding variables on the estimated treatment effect when outcomes are time-to-event in nature. The methods in the paper are illustrated by estimating the effect of discharge statin prescribing on the risk of death in a sample of patients hospitalized with acute myocardial infarction. In this tutorial article, we describe and illustrate all the steps necessary to conduct a comprehensive analysis of the effect of treatment on time-to-event outcomes. {\copyright} 2013 The authors. Statistics in Medicine published by John Wiley \& Sons, Ltd.}},
    author = {Austin, P. C.},
    citeulike-article-id = {13876813},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5984},
    doi = {10.1002/sim.5984},
    issn = {1097-0258},
    journal = {Statistics in Medicine},
    keywords = {effect-measures, exportrecords, propensity-scores, statistics},
    number = {7},
    pages = {1242--1258},
    posted-at = {2015-12-09 01:12:08},
    priority = {3},
    title = {{The use of propensity score methods with survival or time-to-event outcomes: reporting measures of effect similar to those used in randomized experiments}},
    url = {http://dx.doi.org/10.1002/sim.5984},
    volume = {33},
    year = {2014}
}

@article{24078,
    abstract = {{Missing values are a practical issue in the analysis of longitudinal data. Multiple imputation (MI) is a well-known likelihood-based method that has optimal properties in terms of efficiency and consistency if the imputation model is correctly specified. Doubly robust (DR) weighing-based methods protect against misspecification bias if one of the models, but not necessarily both, for the data or the mechanism leading to missing data is correct. We propose a new imputation method that captures the simplicity of MI and protection from the DR method. This method integrates MI and DR to protect against misspecification of the imputation model under a missing at random assumption. Our method avoids analytical complications of missing data particularly in multivariate settings, and is easy to implement in standard statistical packages. Moreover, the proposed method works very well with an intermittent pattern of missingness when other DR methods can not be used. Simulation experiments show that the proposed approach achieves improved performance when one of the models is correct. The method is applied to data from the fireworks disaster study, a randomized clinical trial comparing therapies in disaster-exposed children. We conclude that the new method increases the robustness of imputations.}},
    author = {Jolani, S. and Frank, L. E. and van Buuren, S.},
    citeulike-article-id = {13876803},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/bmsp.12021},
    doi = {10.1111/bmsp.12021},
    issn = {2044-8317},
    journal = {British Journal of Mathematical and Statistical Psychology},
    keywords = {data---missing, exportrecords, propensity-scores, statistics},
    number = {2},
    pages = {197--212},
    posted-at = {2015-12-09 01:12:08},
    priority = {3},
    title = {{Dual imputation model for incomplete longitudinal data}},
    url = {http://dx.doi.org/10.1111/bmsp.12021},
    volume = {67},
    year = {2014}
}

@article{23872,
    abstract = {{The propensity score plays a central role in a variety of causal inference settings. In particular, matching and weighting methods based on the estimated propensity score have become increasingly common in the analysis of observational data. Despite their popularity and theoretical appeal, the main practical difficulty of these methods is that the propensity score must be estimated. Researchers have found that slight misspecification of the propensity score model can result in substantial bias of estimated treatment effects. We introduce covariate balancing propensity score (CBPS) methodology, which models treatment assignment while optimizing the covariate balance. The CBPS exploits the dual characteristics of the propensity score as a covariate balancing score and the conditional probability of treatment assignment. The estimation of the CBPS is done within the generalized method-of-moments or empirical likelihood framework. We find that the CBPS dramatically improves the poor empirical performance of propensity score matching and weighting methods reported in the literature. We also show that the CBPS can be extended to other important settings, including the estimation of the generalized propensity score for non-binary treatments and the generalization of experimental estimates to a target population. Open source software is available for implementing the methods proposed.}},
    author = {Imai, K. and Ratkovic, M.},
    citeulike-article-id = {13876802},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/rssb.12027},
    doi = {10.1111/rssb.12027},
    issn = {1467-9868},
    journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
    keywords = {effect-size, exportrecords, propensity-scores, statistics},
    number = {1},
    pages = {243--263},
    posted-at = {2015-12-09 01:12:08},
    priority = {3},
    title = {{Covariate balancing propensity score}},
    url = {http://dx.doi.org/10.1111/rssb.12027},
    volume = {76},
    year = {2014}
}

@article{45684,
    abstract = {{Although randomization provides a gold-standard method of assessing causal relationships, it is not always possible to randomly allocate exposures. Where exposures are not randomized, estimating exposure effects is complicated by confounding. The traditional approach to dealing with confounding is to adjust for measured confounding variables within a regression model for the outcome variable. An alternative approach--propensity scoring--instead fits a regression model to the exposure variable. For a binary exposure, the propensity score is the probability of being exposed, given the measured confounders. These scores can be estimated from the data, for example by fitting a logistic regression model for the exposure including the confounders as explanatory variables and obtaining the estimated propensity scores from the predicted exposure probabilities from this model. These estimated propensity scores can then be used in various ways-matching, stratification, covariate-adjustment or inverse-probability weighting-to obtain estimates of the exposure effect. In this paper, we provide an introduction to propensity score methodology and review its use within respiratory health research. We illustrate propensity score methods by investigating the research question: 'Does personal smoking affect the risk of subsequent asthma?' using data taken from the Tasmanian Longitudinal Health Study.}},
    author = {Williamson, E. J. and Forbes, A.},
    citeulike-article-id = {13876662},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/resp.12312},
    doi = {10.1111/resp.12312},
    isbn = {1440-1843; 1323-7799},
    journal = {Respirology},
    keywords = {exportrecords, observational-study---methods, propensity-scores},
    number = {5},
    pages = {625--635},
    posted-at = {2015-12-09 01:12:05},
    priority = {3},
    title = {{Introduction to propensity scores}},
    url = {http://dx.doi.org/10.1111/resp.12312},
    volume = {19},
    year = {2014}
}

@article{43946,
    author = {Zhang, Z.},
    citeulike-article-id = {13876548},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2014.11.024},
    comment = {Comment on:

Kitsios GD. Propensity score studies are unlikely to underestimate treatment effects in critical care medicine: a critical reanalysis. J Clin Epidemiol. 2015 Apr;68(4):467-9. doi: 10.1016/j.jclinepi.2014.10.012. Epub 2014 Dec 4. PubMed PMID: 25555686.},
    doi = {10.1016/j.jclinepi.2014.11.024},
    isbn = {1878-5921; 0895-4356},
    journal = {Journal of Clinical Epidemiology},
    keywords = {exportrecords, observational-study---criticism, propensity-scores},
    number = {4},
    pages = {466--467},
    posted-at = {2015-12-09 01:12:03},
    priority = {3},
    title = {{Combining apples and oranges obtains common features of fruit}},
    url = {http://dx.doi.org/10.1016/j.jclinepi.2014.11.024},
    volume = {68},
    year = {2015}
}

@article{43947,
    author = {Kitsios, G. D.},
    citeulike-article-id = {13876470},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2014.10.012},
    comment = {Comment on:

Zhang Z, Ni H, Xu X. Observational studies using propensity score analysis underestimated the effect sizes in critical care medicine. J Clin Epidemiol. 2014 Aug;67(8):932-9. doi: 10.1016/j.jclinepi.2014.02.018. Epub 2014 Apr 26. PubMed PMID: 24774469.},
    doi = {10.1016/j.jclinepi.2014.10.012},
    isbn = {1878-5921; 0895-4356},
    journal = {Journal of Clinical Epidemiology},
    keywords = {effect-size, exportrecords, observational-study---criticism, propensity-scores},
    number = {4},
    pages = {467--469},
    posted-at = {2015-12-09 01:12:01},
    priority = {3},
    title = {{Propensity score studies are unlikely to underestimate treatment effects in critical care medicine: a critical reanalysis}},
    url = {http://dx.doi.org/10.1016/j.jclinepi.2014.10.012},
    volume = {68},
    year = {2015}
}

@article{32473,
    abstract = {{OBJECTIVES: To model the steps involved in preparing for and carrying out propensity score analyses by providing step-by-step guidance and Stata code applied to an empirical dataset. STUDY DESIGN: Guidance, Stata code, and empirical examples are given to illustrate (1) the process of choosing variables to include in the propensity score; (2) balance of propensity score across treatment and comparison groups; (3) balance of covariates across treatment and comparison groups within blocks of the propensity score; (4) choice of matching and weighting strategies; (5) balance of covariates after matching or weighting the sample; and (6) interpretation of treatment effect estimates. EMPIRICAL APPLICATION: We use data from the Palliative Care for Cancer Patients (PC4C) study, a multisite observational study of the effect of inpatient palliative care on patient health outcomes and health services use, to illustrate the development and use of a propensity score. CONCLUSIONS: Propensity scores are one useful tool for accounting for observed differences between treated and comparison groups. Careful testing of propensity scores is required before using them to estimate treatment effects. {\copyright} Health Research and Educational Trust.}},
    author = {Garrido, M. M. and Kelley, A. S. and Paris, J. and Roza, K. and Meier, D. E. and Morrison, R. S. and Aldridge, M. D.},
    citeulike-article-id = {13876111},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/1475-6773.12182},
    doi = {10.1111/1475-6773.12182},
    isbn = {1475-6773; 0017-9124},
    journal = {Health Services Research},
    keywords = {exportrecords, propensity-scores},
    number = {5},
    pages = {1701--1720},
    posted-at = {2015-12-09 01:11:54},
    priority = {3},
    title = {{Methods for Constructing and Assessing Propensity Scores}},
    url = {http://dx.doi.org/10.1111/1475-6773.12182},
    volume = {49},
    year = {2014}
}

@article{30067,
    abstract = {{The impact of evidence-based medicine and clinical epidemiology on clinical research has contributed to the development of Chinese medicine in modern times over the past two decades. Many concepts and methods of modern science and technology are emerging in Chinese medicine research, resulting in constant progress. Systematic reviews, randomized controlled trials and other advanced mathematic approaches and statistical analysis methods have brought reform to Chinese medicine. In this new era, Chinese medicine researchers have many opportunities and challenges. On the one hand, Chinese medicine researchers need to dedicate themselves to providing enough evidence to the world through rigorous studies, whilst on the other hand, they also need to keep up with the speed of modern medicine research. For example, recently, real world study, comparative effectiveness research, propensity score techniques and registry study have emerged. This article aims to inspire Chinese medicine researchers to explore new areas by introducing these new ideas and new techniques.}},
    author = {Liao, X. and Xie, Y. M.},
    citeulike-article-id = {13875853},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s11655-013-1662-9},
    doi = {10.1007/s11655-013-1662-9},
    issn = {1672-0415},
    journal = {Chinese journal of integrative medicine},
    keywords = {comparative-effectiveness-research---general, exportrecords, propensity-scores, registries---clinical-patient},
    posted-at = {2015-12-09 01:11:49},
    priority = {3},
    title = {{What can comparative effectiveness research, propensity score and registry study bring to Chinese medicine?}},
    url = {http://dx.doi.org/10.1007/s11655-013-1662-9}
}

@article{30449,
    abstract = {{In their recent Health Services Research article titled "Squeezing the Balloon: Propensity Scores and Unmeasured Covariate Balance," Brooks and Ohsfeldt (2013) addressed an important topic on the balancing property of the propensity score (PS) with respect to unmeasured covariates. They concluded that PS methods that balance measured covariates between treated and untreated subjects exacerbate imbalance in unmeasured covariates that are unrelated to measured covariates. Furthermore, they emphasized that for PS algorithms, an imbalance on unmeasured covariates between treatment and untreated subjects is a necessary condition to achieve balance on measured covariates between the groups. We argue that these conclusions are the results of their assumptions on the mechanism of treatment allocation. In addition, we discuss the underlying assumptions of PS methods, their advantages compared with multivariate regression methods, as well as the interpretation of the effect estimates from PS methods.}},
    author = {Ali, M. S. and Groenwold, R. H. and Klungel, O. H.},
    citeulike-article-id = {13875806},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/1475-6773.12152},
    comment = {Comment on:

Brooks JM, Ohsfeldt RL. Squeezing the balloon: propensity scores and unmeasured covariate balance. Health Serv Res. 2013 Aug;48(4):1487-507. doi: 10.1111/1475-6773.12020. Epub 2012 Dec 6. PubMed PMID: 23216471; PubMed Central PMCID: PMC3725536.},
    doi = {10.1111/1475-6773.12152},
    isbn = {1475-6773; 0017-9124},
    journal = {Health Services Research},
    keywords = {exportrecords, propensity-scores},
    number = {3},
    pages = {1074--1082},
    posted-at = {2015-12-09 01:11:48},
    priority = {3},
    title = {{Propensity score methods and unobserved covariate imbalance: comments on "squeezing the balloon"}},
    url = {http://dx.doi.org/10.1111/1475-6773.12152},
    volume = {49},
    year = {2014}
}

@article{27460,
    abstract = {{Propensity score (PS) methods have proliferated in recent years in observational studies in general and in observational comparative effectiveness research (CER) in particular. PS methods are an important set of tools for estimating treatment effects in observational studies, enabling adjustment for measured confounders in an easy-to-understand and transparent way. This article demonstrates how PS methods have been used to address specific CER questions from 2001 through to 2012 by identifying six impactful studies from this period. This article also discusses areas for improvement, including data infrastructure, and a unified set of guidelines in terms of PS implementation and reporting, which will boost confidence in evidence generated through observational CER using PS methods.}},
    author = {Borah, B. J. and Moriarty, J. P. and Crown, W. H. and Doshi, J. A.},
    citeulike-article-id = {13875697},
    citeulike-linkout-0 = {http://dx.doi.org/10.2217/cer.13.89},
    doi = {10.2217/cer.13.89},
    isbn = {2042-6313; 2042-6305},
    journal = {Journal of Comparative Effectiveness Research},
    keywords = {adverse-events---harms, comparative-effectiveness-research---methods, effect-size, exportrecords, propensity-scores},
    number = {1},
    pages = {63--78},
    posted-at = {2015-12-09 01:11:46},
    priority = {3},
    title = {{Applications of propensity score methods in observational comparative effectiveness and safety research: where have we come and where should we go?}},
    url = {http://dx.doi.org/10.2217/cer.13.89},
    volume = {3},
    year = {2014}
}

@article{45672,
    abstract = {{Propensity score methods are increasingly used in medical literature to estimate treatment effect using data from observational studies. Despite many papers on propensity score analysis, few have focused on the analysis of survival data. Even within the framework of the popular proportional hazard model, the choice among marginal, stratified or adjusted models remains unclear. A Monte Carlo simulation study was used to compare the performance of several survival models to estimate both marginal and conditional treatment effects. The impact of accounting or not for pairing when analysing propensity-score-matched survival data was assessed. In addition, the influence of unmeasured confounders was investigated. After matching on the propensity score, both marginal and conditional treatment effects could be reliably estimated. Ignoring the paired structure of the data led to an increased test size due to an overestimated variance of the treatment effect. Among the various survival models considered, stratified models systematically showed poorer performance. Omitting a covariate in the propensity score model led to a biased estimation of treatment effect, but replacement of the unmeasured confounder by a correlated one allowed a marked decrease in this bias. Our study showed that propensity scores applied to survival data can lead to unbiased estimation of both marginal and conditional treatment effect, when marginal and adjusted Cox models are used. In all cases, it is necessary to account for pairing when analysing propensity-score-matched data, using a robust estimator of the variance.}},
    author = {Gayat, E. and Resche-Rigon, M. and Mary, J. Y. and Porcher, R.},
    citeulike-article-id = {13875359},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pst.537},
    doi = {10.1002/pst.537},
    isbn = {1539-1612; 1539-1604},
    journal = {Pharmaceutical Statistics},
    keywords = {exportrecords, observational-study---methods, propensity-scores},
    number = {3},
    pages = {222--229},
    posted-at = {2015-12-09 01:10:54},
    priority = {3},
    title = {{Propensity score applied to survival data analysis through proportional hazards models: a Monte Carlo study}},
    url = {http://dx.doi.org/10.1002/pst.537},
    volume = {11},
    year = {2012}
}

@article{29757,
    abstract = {{The use of propensity scores to control for pretreatment imbalances on observed variables in non-randomized or observational studies examining the causal effects of treatments or interventions has become widespread over the past decade. For settings with two conditions of interest such as a treatment and a control, inverse probability of treatment weighted estimation with propensity scores estimated via boosted models has been shown in simulation studies to yield causal effect estimates with desirable properties. There are tools (e.g., the twang package in R) and guidance for implementing this method with two treatments. However, there is not such guidance for analyses of three or more treatments. The goals of this paper are twofold: (1) to provide step-by-step guidance for researchers who want to implement propensity score weighting for multiple treatments and (2) to propose the use of generalized boosted models (GBM) for estimation of the necessary propensity score weights. We define the causal quantities that may be of interest to studies of multiple treatments and derive weighted estimators of those quantities. We present a detailed plan for using GBM to estimate propensity scores and using those scores to estimate weights and causal effects. We also provide tools for assessing balance and overlap of pretreatment variables among treatment groups in the context of multiple treatments. A case study examining the effects of three treatment programs for adolescent substance abuse demonstrates the methods.}},
    author = {McCaffrey, D. F. and Griffin, B. A. and Almirall, D. and Slaughter, M. E. and Ramchand, R. and Burgette, L. F.},
    citeulike-article-id = {13875277},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5753},
    doi = {10.1002/sim.5753},
    isbn = {1097-0258; 0277-6715},
    journal = {Statistics in medicine},
    keywords = {exportrecords, propensity-scores},
    number = {19},
    pages = {3388--3414},
    posted-at = {2015-12-09 01:10:52},
    priority = {3},
    title = {{A tutorial on propensity score estimation for multiple treatments using generalized boosted models}},
    url = {http://dx.doi.org/10.1002/sim.5753},
    volume = {32},
    year = {2013}
}

@article{20946,
    abstract = {{Propensity score (Pscore) matching and inverse probability of treatment weighting (IPTW) can remove bias due to observed confounders, if the Pscore is correctly specified. Genetic Matching (GenMatch) matches on the Pscore and individual covariates using an automated search algorithm to balance covariates. This paper compares common ways of implementing Pscore matching and IPTW, with Genmatch for balancing time-constant baseline covariates}. The methods are considered when estimates of treatment effectiveness are required for patient subgroups, and the treatment allocation process differs by subgroup. We apply these methods in a prospective cohort study that estimates the effectiveness of Drotrecogin alfa activated, for subgroups of patients with severe sepsis. In a simulation study we compare the methods when the Pscore is correctly specified, and then misspecified by ignoring the subgroup-specific treatment allocation. The simulations also consider poor overlap in baseline covariates, and different sample sizes. In the case study, GenMatch reports better covariate balance than IPTW or Pscore matching. In the simulations with correctly specified Pscores, good overlap and reasonable sample sizes, all methods report minimal bias. When the Pscore is misspecified, GenMatch reports the least imbalance and bias. With small sample sizes, IPTW is the most efficient approach, but all methods report relatively high bias of treatment effects. This study shows that overall GenMatch achieves the best covariate balance for each subgroup, and is more robust to Pscore misspecification than common alternative Pscore approaches.},
    author = {Radice, R. and Ramsahai, R. and Grieve, R. and Kreif, N. and Sadique, Z. and Sekhon, J. S.},
    citeulike-article-id = {13875162},
    citeulike-linkout-0 = {http://dx.doi.org/10.1515/1557-4679.1382},
    doi = {10.1515/1557-4679.1382},
    isbn = {1557-4679;},
    journal = {International Journal of Biostatistics},
    keywords = {exportrecords, propensity-scores, subgroup-analysis},
    number = {1},
    pages = {25+},
    posted-at = {2015-12-09 01:10:49},
    priority = {3},
    title = {{Evaluating treatment effectiveness in patient subgroups: a comparison of propensity score methods with an automated matching approach}},
    url = {http://dx.doi.org/10.1515/1557-4679.1382},
    volume = {8},
    year = {2012}
}

@phdthesis{20823,
    abstract = {{Propensity score matching is a relatively new technique used in observational studies to approximate data that have been randomly assigned to treatment. This technique assimilates the values of several covariates into a single propensity score that is used as a matching variable to create similar groups. This dissertation comprises two separate but related studies. The first is a simulation wherein generated data are analyzed to determine if one of three propensity score matching techniques performs more effectively in reducing sample bias and if those methods more accurately detect a simulated effect size than does a traditional analysis of covariance (ANCOVA). (PsycINFO Database Record (c) 2013 APA, all rights reserved)}},
    author = {Phillips, S. M.},
    booktitle = {Dissertation Abstracts International},
    citeulike-article-id = {13875160},
    comment = {DAI 3507873},
    isbn = {0419-4217; 978-1-267-33363-6;},
    keywords = {exportrecords, propensity-scores},
    posted-at = {2015-12-09 01:10:49},
    priority = {3},
    school = {University of South Carolina},
    title = {{Propensity score matching techniques: Simulation and application in an educational research context}},
    year = {2012}
}

@article{20822,
    abstract = {{As a result of the use of random assignment to treatment, randomized experiments typically have high internal validity. However, units are very rarely randomly selected from a well-defined population of interest into an experiment; this results in low external validity. Under nonrandom sampling, this means that the estimate of the sample average treatment effect calculated in the experiment can be a biased estimate of the population average treatment effect. This article explores the use of the propensity score subclassification estimator as a means for improving generalizations from experiments. It first lays out the assumptions necessary for generalizations, then investigates the amount of bias reduction and average variance inflation that is likely when compared to a conventional estimator. It concludes with a discussion of issues that arise when the population of interest is not well represented by the experiment, and an example. (PsycINFO Database Record (c) 2013 APA, all rights reserved) (journal abstract)}},
    author = {Tipton, E.},
    citeulike-article-id = {13875159},
    citeulike-linkout-0 = {http://dx.doi.org/10.3102/1076998612441947},
    doi = {10.3102/1076998612441947},
    isbn = {1076-9986; 1935-1054},
    journal = {Journal of Educational and Behavioral Statistics},
    keywords = {exportrecords, propensity-scores},
    number = {3},
    pages = {239--266},
    posted-at = {2015-12-09 01:10:49},
    priority = {3},
    title = {{Improving generalizations from experiments using propensity score subclassification: Assumptions, properties, and contexts}},
    url = {http://dx.doi.org/10.3102/1076998612441947},
    volume = {38},
    year = {2013}
}

@article{23789,
    abstract = {{Cluster randomized trials (CRTs) are often prone to selection bias despite randomization. Using a simulation study, we investigated the use of propensity score (PS) based methods in estimating treatment effects in CRTs with selection bias when the outcome is quantitative. Of four PS-based methods (adjustment on PS, inverse weighting, stratification, and optimal full matching method), three successfully corrected the bias, as did an approach using classical multivariable regression. However, they showed poorer statistical efficiency than classical methods, with higher standard error for the treatment effect, and type I error much smaller than the 5\% nominal level. Copyright (c) 2013 John Wiley \& Sons, Ltd.}},
    author = {Leyrat, C. and Caille, A. and Donner, A. and Giraudeau, B.},
    citeulike-article-id = {13875115},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5795},
    doi = {10.1002/sim.5795},
    isbn = {1097-0258; 0277-6715},
    journal = {Statistics in Medicine},
    keywords = {bias---selection, controlled-trials---cluster, exportrecords, propensity-scores, statistics},
    number = {19},
    pages = {3357--3372},
    posted-at = {2015-12-09 01:10:48},
    priority = {3},
    title = {{Propensity scores used for analysis of cluster randomized trials with selection bias: a simulation study}},
    url = {http://dx.doi.org/10.1002/sim.5795},
    volume = {32},
    year = {2013}
}

@article{23788,
    abstract = {{Propensity score methods are being increasingly used as a less parametric alternative to traditional regression to balance observed differences across groups in both descriptive and causal comparisons. Data collected in many disciplines often have analytically relevant multilevel or clustered structure. The propensity score, however, was developed and has been used primarily with unstructured data. We present and compare several propensity-score-weighted estimators for clustered data, including marginal, cluster-weighted, and doubly robust estimators. Using both analytical derivations and Monte Carlo simulations, we illustrate bias arising when the usual assumptions of propensity score analysis do not hold for multilevel data. We show that exploiting the multilevel structure, either parametrically or nonparametrically, in at least one stage of the propensity score analysis can greatly reduce these biases. We applied these methods to a study of racial disparities in breast cancer screening among beneficiaries of Medicare health plans.}},
    author = {Li, F. and Zaslavsky, A. M. and Landrum, M. B.},
    citeulike-article-id = {13875114},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5786},
    doi = {10.1002/sim.5786},
    isbn = {1097-0258; 0277-6715},
    journal = {Statistics in Medicine},
    keywords = {bias---selection, exportrecords, propensity-scores, statistics},
    number = {19},
    pages = {3373--3387},
    posted-at = {2015-12-09 01:10:48},
    priority = {3},
    title = {{Propensity score weighting with multilevel data}},
    url = {http://dx.doi.org/10.1002/sim.5786},
    volume = {32},
    year = {2013}
}

@article{23474,
    abstract = {{BACKGROUND: Studying the effects of medications on endpoints in an observational setting is an important yet challenging problem due to confounding by indication. The purpose of this study is to describe methodology for estimating such effects while including prevalent medication users. These techniques are illustrated in models relating statin use to cardiovascular disease (CVD) in a large multi-ethnic cohort study. METHODS: The Multi-Ethnic Study of Atherosclerosis (MESA) includes 6814 participants aged 45-84 years free of CVD. Confounding by indication was mitigated using a two step approach: First, the untreated values of cholesterol were treated as missing data and the values imputed as a function of the observed treated value, dose and type of medication, and participant characteristics. Second, we construct a propensity-score modeling the probability of medication initiation as a function of measured covariates and estimated pre-treatment cholesterol value. The effect of statins on CVD endpoints were assessed using weighted Cox proportional hazard models using inverse probability weights based on the propensity score. RESULTS: Based on a meta-analysis of randomized controlled trials (RCT) statins are associated with a reduced risk of CVD (relative risk ratio = 0.73, 95\% CI: 0.70, 0.77). In an unweighted Cox model adjusting for traditional risk factors we observed little association of statins with CVD (hazard ratio (HR) = 0.97, 95\% CI: 0.60, 1.59). Using weights based on a propensity model for statins that did not include the estimated pre-treatment cholesterol we observed a slight protective association (HR = 0.92, 95\% CI: 0.54-1.57). Results were similar using a new-user design where prevalent users of statins are excluded (HR = 0.91, 95\% CI: 0.45-1.80). Using weights based on a propensity model with estimated pre-treatment cholesterol the effects of statins (HR = 0.74, 95\% CI: 0.38, 1.42) were consistent with the RCT literature. CONCLUSIONS: The imputation of pre-treated cholesterol levels for participants on medication at baseline in conjunction with a propensity score yielded estimates that were consistent with the RCT literature. These techniques could be useful in any example where inclusion of participants exposed at baseline in the analysis is desirable, and reasonable estimates of pre-exposure biomarker values can be estimated.}},
    author = {Jorgensen, N. W. and Sibley, C. T. and McClelland, R. L.},
    citeulike-article-id = {13875108},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/1471-2288-13-81},
    doi = {10.1186/1471-2288-13-81},
    issn = {1471-2288},
    journal = {BMC Medical Research Methodology},
    keywords = {confounding, exportrecords, propensity-scores},
    pages = {81+},
    posted-at = {2015-12-09 01:10:48},
    priority = {3},
    title = {{Using imputed pre-treatment cholesterol in a propensity score model to reduce confounding by indication: results from the multi-ethnic study of atherosclerosis}},
    url = {http://dx.doi.org/10.1186/1471-2288-13-81},
    volume = {13},
    year = {2013}
}

@article{23067,
    abstract = {{In a cluster randomized controlled trial (RCT), the number of randomized units is typically considerably smaller than in trials where the unit of randomization is the patient. If the number of randomized clusters is small, there is a reasonable chance of baseline imbalance between the experimental and control groups. This imbalance threatens the validity of inferences regarding post-treatment intervention effects unless an appropriate statistical adjustment is used. Here, we consider application of the propensity score adjustment for cluster RCTs. For the purpose of illustration, we apply the propensity adjustment to a cluster RCT that evaluated an intervention to reduce suicidal ideation and depression. This approach to adjusting imbalance had considerable bearing on the interpretation of results. A simulation study demonstrates that the propensity adjustment reduced well over 90\% of the bias seen in unadjusted models for the specifications examined. Copyright {\copyright} 2013 John Wiley \& Sons, Ltd.}},
    author = {Leon, A. C. and Demirtas, H. and Li, C. and Hedeker, D.},
    citeulike-article-id = {13875103},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pst.1580},
    doi = {10.1002/pst.1580},
    issn = {1539-1612},
    journal = {Pharmaceutical Statistics},
    keywords = {bias---general, bias---selection, controlled-trials---cluster, exportrecords, propensity-scores, statistics},
    posted-at = {2015-12-09 01:10:48},
    priority = {3},
    title = {{Subject-level matching for imbalance in cluster randomized trials with a small number of clusters}},
    url = {http://dx.doi.org/10.1002/pst.1580}
}

@article{20837,
    abstract = {{A two-step Bayesian propensity score approach is introduced that incorporates prior information in the propensity score equation and outcome equation without the problems associated with simultaneous Bayesian propensity score approaches. The corresponding variance estimators are also provided. The two-step Bayesian propensity score is provided for three methods of implementation: propensity score stratification, weighting, and optimal full matching. Three simulation studies and one case study are presented to elaborate the proposed two-step Bayesian propensity score approach. Results of the simulation studies reveal that greater precision in the propensity score equation yields better recovery of the frequentist-based treatment effect. A slight advantage is shown for the Bayesian approach in small samples. Results also reveal that greater precision around the wrong treatment effect can lead to seriously distorted results. However, greater precision around the correct treatment effect parameter yields quite good results, with slight improvement seen with greater precision in the propensity score equation. A comparison of coverage rates for the conventional frequentist approach and proposed Bayesian approach is also provided. The case study reveals that credible intervals are wider than frequentist confidence intervals when priors are non-informative. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Kaplan, D. and Chen, J.},
    citeulike-article-id = {13875097},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s11336-012-9262-8},
    comment = {Erratum in:

Kaplan, D., \& Chen, J. (2012). Erratum to: A two-step bayesian approach for propensity score analysis: Simulations and case study. Psychometrika, 77(3), 610. doi:http://dx.doi.org/10.1007/s11336-012-9271-7},
    doi = {10.1007/s11336-012-9262-8},
    isbn = {0033-3123; 1860-0980},
    journal = {Psychometrika},
    keywords = {exportrecords, propensity-scores},
    number = {3},
    pages = {581--609},
    posted-at = {2015-12-09 01:10:48},
    priority = {3},
    title = {{A two-step Bayesian approach for propensity score analysis: Simulations and case study.}},
    url = {http://dx.doi.org/10.1007/s11336-012-9262-8},
    volume = {77},
    year = {2012}
}

@article{20834,
    abstract = {{Because random assignment is not possible in observational studies, estimates of treatment effects might be biased due to selection on observable and unobservable variables. To strengthen causal inference in longitudinal observational studies of multiple treatments, we present 4 latent growth models for propensity score matched groups, and evaluate their performance with a Monte Carlo simulation study. We found that the 4 models performed similarly with respect to model fit, bias of parameter estimates, Type I error, and power to test the treatment effect. To demonstrate a multigroup latent growth model with dummy treatment indicators, we estimated the effect of students changing schools during elementary school years on their reading and mathematics achievement, using data from the Early Childhood Longitudinal Study Kindergarten Cohort. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Leite, W. L. and Sandbach, R. and Jin, R. and MacInnes, J. W. and Jackman, M. G.},
    citeulike-article-id = {13875096},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/10705511.2012.687666},
    doi = {10.1080/10705511.2012.687666},
    isbn = {1070-5511; 1532-8007},
    journal = {Structural Equation Modeling},
    keywords = {exportrecords, propensity-scores},
    number = {3},
    pages = {437--456},
    posted-at = {2015-12-09 01:10:48},
    priority = {3},
    title = {{An evaluation of latent growth models for propensity score matched groups}},
    url = {http://dx.doi.org/10.1080/10705511.2012.687666},
    volume = {19},
    year = {2012}
}

@article{20845,
    abstract = {{Propensity score matching and stratification enable researchers to make statistical adjustment for a large number of observed covariates in nonexperimental data. These methods have recently become popular in psychological research. Yet their applications to evaluations of multi-valued and multiple treatments are limited. The inverse-probability-of-treatment weighting method, though suitable for evaluating multi-valued and multiple treatments, often generates results that are not robust when only a portion of the population provides support for causal inference or when the functional form of the propensity score model is misspecified. The marginal mean weighting through stratification (MMW-S) method promises a viable nonparametric solution to these problems. By computing weights on the basis of stratified propensity scores, MMW-S adjustment equates the pretreatment composition of multiple treatment groups under the assumption that unmeasured covariates do not confound the treatment effects given the observed covariates. Analyzing data from a weighted sample, researchers can estimate a causal effect by computing the difference between the estimated average potential outcomes associated with alternative treatments within the analysis of variance framework. After providing an intuitive illustration of the theoretical rationale underlying the weighting method for causal inferences, the article demonstrates how to apply the MMW-S method to evaluations of treatments measured on a binary, ordinal, or nominal scale approximating a completely randomized experiment; to studies of multiple concurrent treatments approximating factorial randomized designs; and to moderated treatment effects approximating randomized block designs. The analytic procedure is illustrated with an evaluation of educational services for English language learners attending kindergarten in the United States. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Hong, G.},
    citeulike-article-id = {13875081},
    citeulike-linkout-0 = {http://dx.doi.org/10.1037/a0024918},
    doi = {10.1037/a0024918},
    isbn = {1082-989X; 1939-1463},
    journal = {Psychological Methods},
    keywords = {exportrecords, propensity-scores},
    number = {1},
    pages = {44--60},
    posted-at = {2015-12-09 01:10:47},
    priority = {3},
    title = {{Marginal mean weighting through stratification: A generalized method for evaluating multivalued and multiple treatments with nonexperimental data}},
    url = {http://dx.doi.org/10.1037/a0024918},
    volume = {17},
    year = {2012}
}

@article{20826,
    abstract = {{A primary goal of the paper is to provide an example of an evaluation design and analytic method that can be used to strengthen causal inference in nonexperimental prevention research. We used this method in a nonexperimental multisite study to evaluate short-term outcomes of a preventive intervention, and we accounted for effects of two types of selection bias: self-selection into the program and differential dropout. To provide context for our analytic approach, we present an overview of the counterfactual model (also known as Rubin's causal model or the potential outcomes model) and several methods derived from that model, including propensity score matching, the Heckman two-step approach, and full information maximum likelihood based on a bivariate probit model and its trivariate generalization. We provide an example using evaluation data from a community-based family intervention and a nonexperimental control group constructed from the Washington State biennial Healthy Youth Survey (HYS) risk behavior data (HYS n=68,846; intervention n=1,502). We identified significant effects of participant, program, and community attributes in self-selection into the program and program completion. Identification of specific selection effects is useful for developing recruitment and retention strategies, and failure to identify selection may lead to inaccurate estimation of outcomes and their public health impact. Counterfactual models allow us to evaluate interventions in uncontrolled settings and still maintain some confidence in the internal validity of our inferences; their application holds great promise for the field of prevention science as we scale up to community dissemination of preventive interventions. (PsycINFO Database Record (c) 2013 APA, all rights reserved) (journal abstract)}},
    author = {Hill, L. G. and Rosenman, R. and Tennekoon, V. and Mandal, B.},
    citeulike-article-id = {13875080},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s11121-012-0342-x},
    doi = {10.1007/s11121-012-0342-x},
    isbn = {1389-4986; 1573-6695},
    journal = {Prevention Science},
    keywords = {bias---selection, exportrecords, propensity-scores},
    posted-at = {2015-12-09 01:10:47},
    priority = {3},
    title = {{Selection effects and prevention program outcomes}},
    url = {http://dx.doi.org/10.1007/s11121-012-0342-x}
}

@article{25875,
    abstract = {{PURPOSE: The choice of propensity score (PS) implementation influences treatment effect estimates not only because different methods estimate different quantities, but also because different estimators respond in different ways to phenomena such as treatment effect heterogeneity and limited availability of potential matches. Using effectiveness data, we describe lessons learned from sensitivity analyses with matched and weighted estimates. METHODS: With subsample data (N = 1292) from Sequenced Treatment Alternatives to Relieve Depression, a 2001-2004 effectiveness trial of depression treatments, we implemented PS matching and weighting to estimate the treatment effect in the treated and conducted multiple sensitivity analyses. RESULTS: Matching and weighting both balanced covariates but yielded different samples and treatment effect estimates (matched RR 1.00, 95\% CI: 0.75-1.34; weighted RR 1.28, 95\% CI: 0.97-1.69). In sensitivity analyses, as increasing numbers of observations at both ends of the PS distribution were excluded from the weighted analysis, weighted estimates approached the matched estimate (weighted RR 1.04, 95\% CI 0.77-1.39 after excluding all observations below the 5th percentile of the treated and above the 95th percentile of the untreated). Treatment appeared to have benefits only in the highest and lowest PS strata. CONCLUSIONS: Matched and weighted estimates differed due to incomplete matching, sensitivity of weighted estimates to extreme observations, and possibly treatment effect heterogeneity. PS analysis requires identifying the population and treatment effect of interest, selecting an appropriate implementation method, and conducting and reporting sensitivity analyses. Weighted estimation especially should include sensitivity analyses relating to influential observations, such as those treated contrary to prediction. Copyright {\copyright} 2012 John Wiley \& Sons, Ltd.}},
    author = {Ellis, A. R. and Dusetzina, S. B. and Hansen, R. A. and Gaynes, B. N. and Farley, J. F. and St\"{u}rmer, T.},
    citeulike-article-id = {13875072},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.3396},
    doi = {10.1002/pds.3396},
    issn = {1053-8569},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {effect-size, exportrecords, propensity-scores},
    number = {2},
    pages = {138--144},
    posted-at = {2015-12-09 01:10:47},
    priority = {3},
    title = {{Investigating differences in treatment effect estimates between propensity score matching and weighting: A demonstration using STAR*D trial data}},
    url = {http://dx.doi.org/10.1002/pds.3396},
    volume = {22},
    year = {2013}
}

@article{22993,
    abstract = {{The use of propensity score methods to adjust for selection bias in observational studies has become increasingly popular in public health and medical research. A substantial portion of studies using propensity score adjustment treat the propensity score as a conventional regression predictor. Through a Monte Carlo simulation study, Austin and colleagues. investigated the bias associated with treatment effect estimation when the propensity score is used as a covariate in nonlinear regression models, such as logistic regression and Cox proportional hazards models. We show that the bias exists even in a linear regression model when the estimated propensity score is used and derive the explicit form of the bias. We also conduct an extensive simulation study to compare the performance of such covariate adjustment with propensity score stratification, propensity score matching, inverse probability of treatment weighted method, and nonparametric functional estimation using splines. The simulation scenarios are designed to reflect real data analysis practice. Instead of specifying a known parametric propensity score model, we generate the data by considering various degrees of overlap of the covariate distributions between treated and control groups. Propensity score matching excels when the treated group is contained within a larger control pool, while the model-based adjustment may have an edge when treated and control groups do not have too much overlap. Overall, adjusting for the propensity score through stratification or matching followed by regression or using splines, appears to be a good practical strategy. Copyright (c) 2013 John Wiley \& Sons, Ltd.}},
    author = {Hade, E. M. and Lu, B.},
    citeulike-article-id = {13875046},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5884},
    doi = {10.1002/sim.5884},
    isbn = {1097-0258; 0277-6715},
    journal = {Statistics in Medicine},
    keywords = {bias---selection, exportrecords, observational-study---criticism, propensity-scores},
    posted-at = {2015-12-09 01:10:47},
    priority = {3},
    title = {{Bias associated with using the estimated propensity score as a regression covariate}},
    url = {http://dx.doi.org/10.1002/sim.5884}
}

@article{20824,
    abstract = {{Propensity score estimation plays a fundamental role in propensity score matching for reducing group selection bias in observational data. To increase the accuracy of propensity score estimation, the author developed a bootstrap propensity score. The commonly used propensity score matching methods: nearest neighbor matching, caliper matching, and Mahalanobis metric matching, are used for evaluating the quality of bias reduction results using propensity scores estimated with or without the bootstrap. The study reveals that the matching results with bootstrap propensity score are better than or comparable to those of matching without bootstrap procedures. With regard to the merit of the bootstrap method in reducing sampling errors and, therefore, improving the accuracy of propensity score estimation, the results of this study imply a great potential to use the bootstrap method in estimating propensity scores. This study provides a preliminary framework for further research in this area. (PsycINFO Database Record (c) 2013 APA, all rights reserved) (journal abstract)}},
    author = {Bai, H.},
    citeulike-article-id = {13875009},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/00220973.2012.700497},
    doi = {10.1080/00220973.2012.700497},
    isbn = {0022-0973; 1940-0683},
    journal = {Journal of Experimental Education},
    keywords = {bias---selection, exportrecords, propensity-scores},
    number = {2},
    pages = {157--177},
    posted-at = {2015-12-09 01:10:46},
    priority = {3},
    title = {{A bootstrap procedure of propensity score estimation.}},
    url = {http://dx.doi.org/10.1080/00220973.2012.700497},
    volume = {81},
    year = {2013}
}

@article{20816,
    abstract = {{Propensity score methods are increasingly being used to reduce or minimize the effects of confounding when estimating the effects of treatments, exposures, or interventions when using observational or non-randomized data. Under the assumption of no unmeasured confounders, previous research has shown that propensity score methods allow for unbiased estimation of linear treatment effects (e.g., differences in means or proportions). However, in biomedical research, time-to-event outcomes occur frequently. There is a paucity of research into the performance of different propensity score methods for estimating the effect of treatment on time-to-event outcomes. Furthermore, propensity score methods allow for the estimation of marginal or population-average treatment effects. We conducted an extensive series of Monte Carlo simulations to examine the performance of propensity score matching (1:1 greedy nearest-neighbor matching within propensity score calipers), stratification on the propensity score, inverse probability of treatment weighting (IPTW) using the propensity score, and covariate adjustment using the propensity score to estimate marginal hazard ratios. We found that both propensity score matching and IPTW using the propensity score allow for the estimation of marginal hazard ratios with minimal bias. Of these two approaches, IPTW using the propensity score resulted in estimates with lower mean squared error when estimating the effect of treatment in the treated. Stratification on the propensity score and covariate adjustment using the propensity score result in biased estimation of both marginal and conditional hazard ratios. Applied researchers are encouraged to use propensity score matching and IPTW using the propensity score when estimating the relative effect of treatment on time-to-event outcomes. Copyright (c) 2012 John Wiley \& Sons, Ltd.}},
    author = {Austin, P. C.},
    citeulike-article-id = {13875008},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5705},
    doi = {10.1002/sim.5705},
    isbn = {1097-0258; 0277-6715},
    journal = {Statistics in Medicine},
    keywords = {bias---selection, exportrecords, propensity-scores},
    number = {16},
    pages = {2837--2849},
    posted-at = {2015-12-09 01:10:46},
    priority = {3},
    title = {{The performance of different propensity score methods for estimating marginal hazard ratios}},
    url = {http://dx.doi.org/10.1002/sim.5705},
    volume = {32},
    year = {2013}
}

@article{20449,
    abstract = {{Channeling occurs when a medication and its potential comparators are selectively prescribed based on differences in underlying patient characteristics. Drug safety advisories can provide new information regarding the relative safety or effectiveness of a drug product which might increase selective prescribing. In particular, when reported adverse effects vary among drugs within a therapeutic class, clinicians may channel patients toward or away from a drug based on the patient's underlying risk for an adverse outcome. If channeling is not identified and appropriately managed it might lead to confounding in observational comparative effectiveness studies. To demonstrate channeling among new users of second generation antipsychotics following a Food and Drug Administration safety advisory and to evaluate the impact of channeling on cardiovascular risk estimates over time. Florida Medicaid data from 2001-2006. Retrospective cohort of adults initiating second generation antipsychotics. We used propensity scores to match olanzapine initiators with other second generation antipsychotic initiators. To evaluate channeling away from olanzapine following an FDA safety advisory, we estimated calendar time-specific propensity scores. We compare the performance of these calendar time-specific propensity scores with conventionally-estimated propensity scores on estimates of cardiovascular risk. Increased channeling away from olanzapine was evident for some, but not all, cardiovascular risk factors and corresponded with the timing of the FDA advisory. Covariate balance was optimized within period and across all periods when using the calendar time-specific propensity score. Hazard ratio estimates for cardiovascular outcomes did not differ across models (Conventional PS: 0.97, 95\%CI: 0.81-3.18 versus calendar time-specific PS: 0.93, 95\%CI: 0.77-3.04). Changes in channeling over time was evident for several covariates but had limited impact on cardiovascular risk estimates, possibly due to unmeasured confounding. Although calendar time-specific propensity scores appear to improve covariate balance, the impact on comparative effectiveness results is limited in this setting.}},
    author = {Dusetzina, S. B. and Mack, C. D. and St\"{u}rmer, T.},
    citeulike-article-id = {13874810},
    citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pone.0063973},
    doi = {10.1371/journal.pone.0063973},
    issn = {1932-6203},
    journal = {PloS One},
    keywords = {adverse-events---harms, exportrecords, propensity-scores},
    number = {5},
    pages = {e63973+},
    posted-at = {2015-12-09 01:10:41},
    priority = {3},
    title = {{Propensity Score Estimation to Address Calendar Time-Specific Channeling in Comparative Effectiveness Research of Second Generation Antipsychotics}},
    url = {http://dx.doi.org/10.1371/journal.pone.0063973},
    volume = {8},
    year = {2013}
}

@proceedings{20657,
    abstract = {{The OCER literature that evaluates comparative effectiveness of alternative medical intervention using existing databases has seen explosive growth in the use of PSM in recent years. However, different PSM algorithms (e.g., one-to-one, one-to-many, radius matching etc.) yield different estimates of the treatment effect. Moreover, matching-induced attrition in the original sample may change the target population for which the average treatment effect (ATE) was intended. This paper, using a real-world example, proposes a range of ATEs that results from different PSM algorithm instead of a single ATE that is typically reported in the literature.}},
    author = {Borah, B. J. and Heien, H. C.},
    booktitle = {ISPOR 18th Annual International Meeting Research Abstracts},
    citeulike-article-id = {13874775},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jval.2013.03.030},
    doi = {10.1016/j.jval.2013.03.030},
    isbn = {1524-4733; 1098-3015},
    journal = {Value in Health},
    keywords = {exportrecords, propensity-scores},
    location = {New Orleans, LA},
    number = {3},
    pages = {A5+},
    posted-at = {2015-12-09 01:10:40},
    priority = {3},
    title = {{Reconciling Variations In Propensity Score Matching (PSM) Algorithms In Observational Comparative Effectiveness Research (OCER)}},
    url = {http://dx.doi.org/10.1016/j.jval.2013.03.030},
    volume = {16},
    year = {2013}
}

@techreport{20205,
    abstract = {{Objectives. This paper describes the use of two types of summary scores in the context of observational research in pharmaco-epidemiology: propensity scores and disease risk scores. Either of these approaches collapses multiple potentially confounding variables into a single score and offers advantages and disadvantages. The aim is to describe best practices for creating and applying these two types of scores. Conclusions. Settings that favor propensity scores tend to be those where there are more persons exposed to the treatment of interest than persons who have study outcomes. Another setting that favors propensity scores is when assessing a therapy's effects on multiple outcomes. Disease risk scores might be favored when assessing the effect of multiple exposures on a single outcome. Disease risk scores may also be preferable summary measures when the exposure is infrequent or consists of multiple levels and the outcome is common. Either method provides advantages for assessing treatment effect heterogeneity. A rationale for use of either summary method should be provided by the researchers who use these methods.}},
    author = {Arbogast, P. G. and Seeger, J. D. and DECIDE Methods Center Summary Variable Working Group},
    booktitle = {AHRQ Effective Health Care Program Research Report},
    citeulike-article-id = {13874763},
    comment = {Suggested citation:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm.},
    keywords = {disease-risk-scores, exportrecords, propensity-scores},
    location = {Rockville, MD},
    pages = {1--44},
    posted-at = {2015-12-09 01:10:40},
    priority = {3},
    publisher = {Agency for Healthcare Research and Quality},
    title = {{Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores}},
    volume = {AHRQ Publication No. 11(12)-EHC055-EF},
    year = {2012}
}

@article{24106,
    abstract = {{OBJECTIVE: Examining covariate balance is the prescribed method for determining the degree to which propensity score methods should be successful at reducing bias. This study assessed the performance of various balance measures, including a proposed balance measure based on the prognostic score (similar to a disease risk score), to determine which balance measures best correlate with bias in the treatment effect estimate. STUDY DESIGN AND SETTING: The correlations of multiple common balance measures with bias in the treatment effect estimate produced by weighting by the odds, subclassification on the propensity score, and full matching on the propensity score were calculated. Simulated data were used, based on realistic data settings. Settings included both continuous and binary covariates and continuous covariates only. RESULTS: The absolute standardized mean difference (ASMD) in prognostic scores, the mean ASMD (in covariates), and the mean t-statistic all had high correlations with bias in the effect estimate. Overall, prognostic scores displayed the highest correlations with bias of all the balance measures considered. Prognostic score measure performance was generally not affected by model misspecification, and the prognostic score measure performed well under a variety of scenarios. CONCLUSION: Researchers should consider using prognostic score-based balance measures for assessing the performance of propensity score methods for reducing bias in nonexperimental studies. Copyright {\copyright} 2013 Elsevier Inc. All rights reserved.}},
    author = {Stuart, E. A. and Lee, B. K. and Leacy, F. P.},
    citeulike-article-id = {13874717},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2013.01.013},
    doi = {10.1016/j.jclinepi.2013.01.013},
    isbn = {1878-5921; 0895-4356},
    journal = {Journal of Clinical Epidemiology},
    keywords = {comparative-effectiveness-research---methods, confounding, disease-risk-scores, exportrecords, propensity-scores, statistics},
    number = {8 Suppl},
    pages = {S84--S90.e1},
    posted-at = {2015-12-09 01:10:39},
    priority = {3},
    title = {{Prognostic score-based balance measures can be a useful diagnostic for propensity score methods in comparative effectiveness research}},
    url = {http://dx.doi.org/10.1016/j.jclinepi.2013.01.013},
    volume = {66},
    year = {2013}
}

@article{18722,
    abstract = {{Decision makers require cost-effectiveness estimates for patient subgroups. In nonrandomized studies, propensity score (PS) matching and inverse probability of treatment weighting (IPTW) can address overt selection bias, but only if they balance observed covariates between treatment groups. Genetic matching (GM) matches on the PS and individual covariates using an automated search algorithm to directly balance baseline covariates. This article compares these methods for estimating subgroup effects in cost-effectiveness analyses (CEA). The motivating case study is a CEA of a pharmaceutical intervention, drotrecogin alfa (DrotAA), for patient subgroups with severe sepsis (n = 2726). Here, GM reported better covariate balance than PS matching and IPTW. For the subgroup at a high level of baseline risk, the probability that DrotAA was cost-effective ranged from 30\% (IPTW) to 90\% (PS matching and GM), at a threshold of pound20 000 per quality-adjusted life-year. We then compared the methods in a simulation study, in which initially the PS was correctly specified and then misspecified, for example, by ignoring the subgroup-specific treatment assignment. Relative performance was assessed as bias and root mean squared error (RMSE) in the estimated incremental net benefits. When the PS was correctly specified and inverse probability weights were stable, each method performed well; IPTW reported the lowest RMSE. When the subgroup-specific treatment assignment was ignored, PS matching and IPTW reported covariate imbalance and bias; GM reported better balance, less bias, and more precise estimates. We conclude that if the PS is correctly specified and the weights for IPTW are stable, each method can provide unbiased cost-effectiveness estimates. However, unlike IPTW and PS matching, GM is relatively robust to PS misspecification.}},
    author = {Kreif, N. and Grieve, R. and Radice, R. and Sadique, Z. and Ramsahai, R. and Sekhon, J. S.},
    citeulike-article-id = {13874647},
    citeulike-linkout-0 = {http://dx.doi.org/10.1177/0272989X12448929},
    doi = {10.1177/0272989X12448929},
    isbn = {1552-681X; 0272-989X},
    journal = {Medical Decision Making},
    keywords = {economic-evaluations---methods, exportrecords, propensity-scores, subgroup-analysis},
    number = {6},
    pages = {750--763},
    posted-at = {2015-12-09 01:10:37},
    priority = {3},
    title = {{Methods for estimating subgroup effects in cost-effectiveness analyses that use observational data}},
    url = {http://dx.doi.org/10.1177/0272989X12448929},
    volume = {32},
    year = {2012}
}

@article{18327,
    abstract = {{In cost-effectiveness analyses (CEA) that use randomized controlled trials (RCTs), covariates of prognostic importance may be imbalanced and warrant adjustment. In CEA that use non-randomized studies (NRS), the selection on observables assumption must hold for regression and matching methods to be unbiased. Even in restricted circumstances when this assumption is plausible, a key concern is how to adjust for imbalances in observed confounders. If the propensity score is misspecified, the covariates in the matched sample will be imbalanced, which can lead to conditional bias. To address covariate imbalance in CEA based on RCTs and NRS, this paper considers Genetic Matching. This matching method uses a search algorithm to directly maximize covariate balance. We compare Genetic and propensity score matching in Monte Carlo simulations and two case studies, CEA of pulmonary artery catheterization, based on an RCT and an NRS. The simulations show that Genetic Matching reduces the conditional bias and root mean squared error compared with propensity score matching. Genetic Matching achieves better covariate balance than the unadjusted analyses of the RCT data. In the NRS, Genetic Matching improves on the balance obtained from propensity score matching and gives substantively different estimates of incremental cost-effectiveness. We conclude that Genetic Matching can improve balance on measured covariates in CEA that use RCTs and NRS, but with NRS, this will be insufficient to reduce bias; the selection on observables assumption must also hold.}},
    author = {Sekhon, J. S. and Grieve, R. D.},
    citeulike-article-id = {13874536},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/hec.1748},
    doi = {10.1002/hec.1748},
    isbn = {1099-1050 1057-9230},
    journal = {Health Economics},
    keywords = {bias---general, economic-evaluations---methods, exportrecords, propensity-scores},
    number = {6},
    pages = {695--714},
    posted-at = {2015-12-09 01:10:35},
    priority = {3},
    title = {{A matching method for improving covariate balance in cost-effectiveness analyses}},
    url = {http://dx.doi.org/10.1002/hec.1748},
    volume = {21},
    year = {2012}
}

@article{17390,
    abstract = {{PURPOSE: Under Medicare Part D, patient characteristics influence plan choice, which in turn influences Part D coverage gap entry. We compared predefined propensity score (PS) and high-dimensional propensity score (hdPS) approaches to address such "confounding by health system use" in assessing whether coverage gap entry is associated with cardiovascular events or death. METHODS: We followed 243,079 Medicare patients aged 65+ years with linked prescription, medical, and plan-specific data in 2005-2007. Patients reached the coverage gap and were followed until an event or year's end. Exposed patients were responsible for drug costs in the gap; unexposed patients (patients with non-Part D drug insurance and Part D patients receiving a low-income subsidy) received financial assistance. Exposed patients were 1:1 PS-matched or hdPS-matched to unexposed patients. The PS model included 52 predefined covariates; the hdPS model added 400 empirically identified covariates. Hazard ratios for death and any of five cardiovascular outcomes were compared. In sensitivity analyses, we explored residual confounding using only low-income subsidy patients in the unexposed group. RESULTS: In unadjusted analyses, exposed patients had no greater hazard of death (HR = 1.00; 95\%CI, 0.84-1.20) or other outcomes. PS-matched (HR = 1.29; 0.99-1.66) and hdPS-matched (HR = 1.11; 0.86-1.42) analyses showed elevated but non-significant hazards of death. In sensitivity analyses, the PS analysis showed a protective effect (HR = 0.78; 0.61-0.98), whereas the hdPS analysis (HR = 1.06; 0.82-1.37) confirmed the main hdPS findings. CONCLUSION: Although the PS-matched analysis suggested elevated but non-significant hazards of death among patients with no financial assistance during the gap, the hdPS analysis produced lower estimates that were stable across sensitivity analyses. Copyright {\copyright} 2012 John Wiley \& Sons, Ltd.}},
    author = {Polinski, J. M. and Schneeweiss, S. and Glynn, R. J. and Lii, J. and Rassen, J. A.},
    citeulike-article-id = {13874483},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.3250},
    doi = {10.1002/pds.3250},
    isbn = {1099-1557; 1053-8569},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {exportrecords, propensity-scores},
    number = {Suppl 2},
    pages = {90--98},
    posted-at = {2015-12-09 01:10:33},
    priority = {3},
    title = {{Confronting "confounding by health system use" in Medicare Part D: comparative effectiveness of propensity score approaches to confounding adjustment}},
    url = {http://dx.doi.org/10.1002/pds.3250},
    volume = {21},
    year = {2012}
}

@article{17388,
    abstract = {{BACKGROUND: Among the large number of cohort studies that employ propensity score matching, most match patients 1:1. Increasing the matching ratio is thought to improve precision but may come with a trade-off with respect to bias. OBJECTIVE: To evaluate several methods of propensity score matching in cohort studies through simulation and empirical analyses. METHODS: We simulated cohorts of 20,000 patients with exposure prevalence of 10\%-50\%. We simulated five dichotomous and five continuous confounders. We estimated propensity scores and matched using digit-based greedy ("greedy"), pairwise nearest neighbor within a caliper ("nearest neighbor"), and a nearest neighbor approach that sought to balance the scores of the comparison patient above and below that of the treated patient ("balanced nearest neighbor"). We matched at both fixed and variable matching ratios and also evaluated sequential and parallel schemes for the order of formation of 1:n match groups. We then applied this same approach to two cohorts of patients drawn from administrative claims data. RESULTS: Increasing the match ratio beyond 1:1 generally resulted in somewhat higher bias. It also resulted in lower variance with variable ratio matching but higher variance with fixed. The parallel approach generally resulted in higher mean squared error but lower bias than the sequential approach. Variable ratio, parallel, balanced nearest neighbor matching generally yielded the lowest bias and mean squared error. CONCLUSIONS: 1:n matching can be used to increase precision in cohort studies. We recommend a variable ratio, parallel, balanced 1:n, nearest neighbor approach that increases precision over 1:1 matching at a small cost in bias. Copyright {\copyright} 2012 John Wiley \& Sons, Ltd.}},
    author = {Rassen, J. A. and Shelat, A. A. and Myers, J. and Glynn, R. J. and Rothman, K. J. and Schneeweiss, S.},
    citeulike-article-id = {13874482},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.3263},
    doi = {10.1002/pds.3263},
    isbn = {1099-1557 1053-8569},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {exportrecords, propensity-scores},
    number = {Suppl 2},
    pages = {69--80},
    posted-at = {2015-12-09 01:10:33},
    priority = {3},
    title = {{One-to-many propensity score matching in cohort studies}},
    url = {http://dx.doi.org/10.1002/pds.3263},
    volume = {21},
    year = {2012}
}

@article{16867,
    abstract = {{Longitudinal observational studies provide rich opportunities to examine treatment effectiveness during the course of a chronic illness. However, there are threats to the validity of observational inferences. For instance, clinician judgment and self-selection play key roles in treatment assignment. To account for this, an adjustment such as the propensity score can be used if certain assumptions are fulfilled. Here, we consider a problem that could surface in a longitudinal observational study and has been largely overlooked. It can occur when subjects have a varying number of distinct periods of therapeutic intervention. We evaluate the implications of baseline variables in the propensity model being associated with the number of post baseline observations per subject and refer to it as 'covariate-dependent representation'. An observational study of antidepressant treatment effectiveness serves as a motivating example. The analyses examine the first 20 years of follow-up data from the National Institute of Mental Health Collaborative Depression Study, a longitudinal, observational study. A simulation study evaluates the consequences of covariate-dependent representation in longitudinal observational studies of treatment effectiveness under a range of data specifications.The simulations found that estimates were adversely affected by underrepresentation when there was lower ICC among repeated doses and among repeated outcomes. Copyright (c) 2012 John Wiley \& Sons, Ltd.}},
    author = {Leon, A. C. and Hedeker, D. and Li, C. and Demirtas, H.},
    citeulike-article-id = {13874474},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5332},
    doi = {10.1002/sim.5332},
    isbn = {1097-0258 ; 0277-6715},
    journal = {Statistics in Medicine},
    keywords = {bias---selection, exportrecords, observational-study---criticism, propensity-scores},
    number = {20},
    pages = {2262--2274},
    posted-at = {2015-12-09 01:10:33},
    priority = {3},
    title = {{Performance of a propensity score adjustment in longitudinal studies with covariate-dependent representation}},
    url = {http://dx.doi.org/10.1002/sim.5332},
    volume = {31},
    year = {2012}
}

@article{17391,
    abstract = {{BACKGROUND: Usefulness of propensity scores and regression models to balance potential confounders at treatment initiation may be limited for newly introduced therapies with evolving use patterns. OBJECTIVES: To consider settings in which the disease risk score has theoretical advantages as a balancing score in comparative effectiveness research because of stability of disease risk and the availability of ample historical data on outcomes in people treated before introduction of the new therapy. METHODS: We review the indications for and balancing properties of disease risk scores in the setting of evolving therapies and discuss alternative approaches for estimation. We illustrate development of a disease risk score in the context of the introduction of atorvastatin and the use of high-dose statin therapy beginning in 1997, based on data from 5668 older survivors of myocardial infarction who filled a statin prescription within 30 days after discharge from 1995 until 2004. Theoretical considerations suggested development of a disease risk score among nonusers of atorvastatin and high-dose statins during the period 1995-1997. RESULTS: Observed risk of events increased from 11\% to 35\% across quintiles of the disease risk score, which had a C-statistic of 0.71. The score allowed control of many potential confounders even during early follow-up with few study endpoints. CONCLUSIONS: Balancing on a disease risk score offers an attractive alternative to a propensity score in some settings such as newly marketed drugs and provides an important axis for evaluation of potential effect modification. Joint consideration of propensity and disease risk scores may be valuable. Copyright {\copyright} 2012 John Wiley \& Sons, Ltd.}},
    author = {Glynn, R. J. and Gagne, J. J. and Schneeweiss, S.},
    citeulike-article-id = {13874470},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.3231},
    doi = {10.1002/pds.3231},
    isbn = {1099-1557 ; 1053-8569 ;},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {disease-risk-scores, exportrecords, propensity-scores},
    number = {Suppl 2},
    pages = {138--147},
    posted-at = {2015-12-09 01:10:33},
    priority = {3},
    title = {{Role of disease risk scores in comparative effectiveness research with emerging therapies}},
    url = {http://dx.doi.org/10.1002/pds.3231},
    volume = {21},
    year = {2012}
}

@article{17389,
    abstract = {{PURPOSE: To examine the performance of propensity score-based methods for estimating relative risks when exposed and comparison subjects are selected from different data sources. METHODS: We conducted Monte Carlo simulations to assess the performance of propensity score methods under various scenarios in which exposed and comparison subjects were selected from different data sources for a comparative effectiveness study of a medical device. RESULTS: The use of propensity score methods in our simulated data scenarios often yielded estimates of relative risk that were close to the true effect, unless the comparison group differed from the exposed group systematically on a factor associated with the outcome. This situation caused severe bias regardless of which method was used but could be overcome if the exposed group could be restricted similarly to the comparison group. Mean square error of relative risk estimates was lowest for similarly restricted study groups and when the comparison group could be considered a random sample of the source population that generated the exposed group. CONCLUSIONS: When exposed and comparison groups originated from different data sources, all propensity score methods yielded relatively unbiased and consistent estimates of relative risk in most situations reflected in our simulation study.}},
    author = {Hammill, B. G. and Curtis, L. H. and Setoguchi, S.},
    citeulike-article-id = {13874469},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.3251},
    doi = {10.1002/pds.3251},
    isbn = {1099-1557 ; 1053-8569 ;},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {exportrecords, propensity-scores},
    number = {Suppl 2},
    pages = {81--9},
    posted-at = {2015-12-09 01:10:33},
    priority = {3},
    title = {{Performance of propensity score methods when comparison groups originate from different data sources}},
    url = {http://dx.doi.org/10.1002/pds.3251},
    volume = {21},
    year = {2012}
}

@article{16851,
    abstract = {{The propensity score method is widely used in clinical studies to estimate the effect of a treatment with two levels on patient's outcomes. However, due to the complexity of many diseases, an effective treatment often involves multiple components. For example, in the practice of Traditional Chinese Medicine (TCM), an effective treatment may include multiple components, e.g. Chinese herbs, acupuncture, and massage therapy. In clinical trials involving TCM, patients could be randomly assigned to either the treatment or control group, but they or their doctors may make different choices about which treatment component to use. As a result, treatment components are not randomly assigned. Rosenbaum and Rubin proposed the propensity score method for binary treatments, and Imbens extended their work to multiple treatments. These authors defined the generalized propensity score as the conditional probability of receiving a particular level of the treatment given the pre-treatment variables. In the present work, we adopted this approach and developed a statistical methodology based on the generalized propensity score in order to estimate treatment effects in the case of multiple treatments. Two methods were discussed and compared: propensity score regression adjustment and propensity score weighting. We used these methods to assess the relative effectiveness of individual treatments in the multiple-treatment IMPACT clinical trial. The results reveal that both methods perform well when the sample size is moderate or large. Copyright (c) 2011 John Wiley \& Sons, Ltd.}},
    author = {Feng, P. and Zhou, X. H. and Zou, Q. M. and Fan, M. Y. and Li, X. S.},
    citeulike-article-id = {13874464},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4168},
    doi = {10.1002/sim.4168},
    isbn = {1097-0258 ; 0277-6715 ;},
    journal = {Statistics in Medicine},
    keywords = {complex-multicomponent-interventions, exportrecords, propensity-scores},
    number = {7},
    pages = {681--697},
    posted-at = {2015-12-09 01:10:33},
    priority = {3},
    title = {{Generalized propensity score for estimating the average treatment effect of multiple treatments}},
    url = {http://dx.doi.org/10.1002/sim.4168},
    volume = {31},
    year = {2012}
}

@article{15704,
    abstract = {{The regression discontinuity (RD) design is considered to be the closest to a randomized trial that can be applied in non-experimental settings. The design relies on a cut-off point on a continuous baseline variable to assign individuals to treatment. The individuals just to the right and left of the cut-off are assumed to be exchangeable - as in a randomized trial. Any observed discontinuity in the relationship between the assignment variable and outcome is therefore considered evidence of a treatment effect. In this paper, we describe key advances in the RD design over the past decade and illustrate their implementation using data from a health management intervention. We then introduce the propensity score-based weighting technique as a complement to the RD design to correct for imbalances in baseline characteristics between treated and non-treated groups that may bias RD results. We find that the weighting strategy outperforms standard regression covariate adjustment in the present data. One clear advantage of the weighting technique over regression covariate adjustment is that we can directly inspect the degree to which balance was achieved. Because of its relative simplicity and tremendous utility, the RD design (either alone or combined with propensity score weighting adjustment) should be considered as an alternative approach to evaluate health management program effectiveness when using observational data.}},
    author = {Linden, A. and Adams, J. L.},
    citeulike-article-id = {13874443},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.1365-2753.2011.01768.x},
    doi = {10.1111/j.1365-2753.2011.01768.x},
    isbn = {1365-2753; 1356-1294},
    journal = {Journal of Evaluation in Clinical Practice},
    keywords = {exportrecords, propensity-scores, statistics},
    number = {2},
    pages = {317--325},
    posted-at = {2015-12-09 01:10:33},
    priority = {3},
    title = {{Combining the regression discontinuity design and propensity score-based weighting to improve causal inference in program evaluation}},
    url = {http://dx.doi.org/10.1111/j.1365-2753.2011.01768.x},
    volume = {18},
    year = {2012}
}

@article{23798,
    abstract = {{Propensity score models are increasingly used in observational comparative effectiveness studies to reduce confounding by covariates that are associated with both a study outcome and treatment choice. Any such potentially confounding covariate will bias estimation of the effect of treatment on the outcome, unless the distribution of that covariate is well-balanced between treatment and control groups. Constructing a subsample of treated and control subjects who are matched on estimated propensity scores is a means of achieving such balance for covariates that are included in the propensity score model. If, during study design, investigators assemble a comprehensive inventory of known and suspected potentially confounding covariates, examination of how well this inventory is covered by the chosen dataset yields an assessment of the extent of bias reduction that is possible by matching on estimated propensity scores. These considerations are explored by examining the designs of three recently published comparative effectiveness studies.}},
    author = {Robinson, J. W.},
    citeulike-article-id = {13874276},
    citeulike-linkout-0 = {http://dx.doi.org/10.2217/cer.12.4},
    doi = {10.2217/cer.12.4},
    issn = {2042-6305},
    journal = {Journal of Comparative Effectiveness Research},
    keywords = {exportrecords, propensity-scores},
    number = {2},
    pages = {129--135},
    posted-at = {2015-12-09 01:10:29},
    priority = {3},
    title = {{Propensity score models in observational comparative effectiveness studies: cornerstone of design or statistical afterthought?}},
    url = {http://dx.doi.org/10.2217/cer.12.4},
    volume = {1},
    year = {2012}
}

@article{20828,
    abstract = {{A latent variable modeling approach that permits estimation of propensity scores in observational studies containing fallible independent variables is outlined, with subsequent examination of treatment effect. When at least one covariate is measured with error, it is indicated that the conventional propensity score need not possess the desirable property of bias adjustment with respect to possible prior group differences. For this setting, a modified propensity score is discussed that is based on true scores on fallible covariates and perfectly measured covariates, if available. This modified score can be recommended to use for average treatment effect evaluation in circumstances where selection into groups occurs on corresponding underlying latent dimensions measured with error. The proposed propensity score procedure is illustrated with an example. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Raykov, T.},
    citeulike-article-id = {13874275},
    citeulike-linkout-0 = {http://dx.doi.org/10.1177/0013164412440999},
    doi = {10.1177/0013164412440999},
    isbn = {U13  - No},
    journal = {Educational and Psychological Measurement},
    keywords = {exportrecords, propensity-scores},
    number = {5},
    pages = {715--733},
    posted-at = {2015-12-09 01:10:29},
    priority = {3},
    title = {{Propensity score analysis with fallible covariates: A note on a latent variable modeling approach}},
    url = {http://dx.doi.org/10.1177/0013164412440999},
    volume = {72},
    year = {2012}
}

@article{26000,
    abstract = {{[First paragraph] Propensity score based methods are used increasingly to evaluate the effectiveness of treatments when evidence from randomised trials is not available. However, users need to be aware of their strengths and limitations}},
    author = {Freemantle, N. and Marston, L. and Walters, K. and Wood, J. and Reynolds, M. R. and Petersen, I.},
    citeulike-article-id = {13873889},
    citeulike-linkout-0 = {http://dx.doi.org/10.1136/bmj.f6409},
    doi = {10.1136/bmj.f6409},
    isbn = {1756-1833; 0959-535X},
    journal = {BMJ},
    keywords = {confounding, effect-size, exportrecords, observational-study---criticism, propensity-scores},
    pages = {f6409+},
    posted-at = {2015-12-09 01:10:21},
    priority = {3},
    title = {{Making inferences on treatment effects from real world data: propensity scores, confounding by indication, and other perils for the unwary in observational research}},
    url = {http://dx.doi.org/10.1136/bmj.f6409},
    volume = {347},
    year = {2013}
}

@article{23847,
    abstract = {{OBJECTIVE: To provide a tutorial for using propensity score methods with complex survey data. DATA SOURCES: Simulated data and the 2008 Medical Expenditure Panel Survey. STUDY DESIGN: Using simulation, we compared the following methods for estimating the treatment effect: a na\"{i}ve estimate (ignoring both survey weights and propensity scores), survey weighting, propensity score methods (nearest neighbor matching, weighting, and subclassification), and propensity score methods in combination with survey weighting. Methods are compared in terms of bias and 95 percent confidence interval coverage. In Example 2, we used these methods to estimate the effect on health care spending of having a generalist versus a specialist as a usual source of care. PRINCIPAL FINDINGS: In general, combining a propensity score method and survey weighting is necessary to achieve unbiased treatment effect estimates that are generalizable to the original survey target population. CONCLUSIONS: Propensity score methods are an essential tool for addressing confounding in observational studies. Ignoring survey weights may lead to results that are not generalizable to the survey target population. This paper clarifies the appropriate inferences for different propensity score methods and suggests guidelines for selecting an appropriate propensity score method based on a researcher's goal. {\copyright} Health Research and Educational Trust.}},
    author = {Dugoff, E. H. and Schuler, M. and Stuart, E. A.},
    citeulike-article-id = {13873872},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/1475-6773.12090},
    doi = {10.1111/1475-6773.12090},
    isbn = {1475-6773; 0017-9124},
    journal = {Health Services Research},
    keywords = {bias---selection, exportrecords, propensity-scores},
    posted-at = {2015-12-09 01:10:20},
    priority = {3},
    title = {{Generalizing Observational Study Results: Applying Propensity Score Methods to Complex Surveys}},
    url = {http://dx.doi.org/10.1111/1475-6773.12090}
}

@article{23180,
    abstract = {{Objectives: The aim of this work is to examine the promise that propensity scores can yield accurate effect estimates in nonrandomized experiments, review research on the realities of the conditions needed to meet this promise, and caution against irrational exuberance about their capacity to meet this promise. Methods: A review of selected experimental work that illustrates both the promise and realities of propensity score analysis. Results: Propensity score analysis of nonrandomized experiments can yield the same results as randomized experiments. Those estimates depend on meeting the strong ignorability assumption that the available covariates well describe selection processes and on use of comparison groups that are from the same location with very similar focal characteristics. When those assumptions are not met, propensity scores may not yield accurate estimates. Conclusions: The use of propensity score analysis has proliferated exponentially, especially in the last decade, but careful attention to its assumptions seems to be very rare in practice. Researchers and policymakers who rely on these extensive propensity score applications may be using evidence of largely unknown validity. All stakeholders should devote far more empirical attention to justifying that each study has met these assumptions. {\copyright} 2012 Springer Science+Business Media Dordrecht.}},
    author = {Shadish, W. R.},
    citeulike-article-id = {13873832},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s11292-012-9166-8},
    doi = {10.1007/s11292-012-9166-8},
    isbn = {1573-3750; 1572-8315},
    journal = {Journal of Experimental Criminology},
    keywords = {exportrecords, observational-study---methods, propensity-scores},
    number = {2},
    pages = {129--144},
    posted-at = {2015-12-09 01:10:19},
    priority = {3},
    title = {{Propensity score analysis: Promise, reality and irrational exuberance}},
    url = {http://dx.doi.org/10.1007/s11292-012-9166-8},
    volume = {9},
    year = {2013}
}

@article{20842,
    abstract = {{Comments on an article Comparative effectiveness of revascularization strategies by W. S. Weintraub et al. (2012). Weintraub et al. presented the results of the American College of Cardiology Foundation (ACCF) and the Society of Thoracic Surgeons (STS) Database Collaboration on the Comparative Effectiveness of Revascularization Strategies (ASCERT) study, a nonrandomized comparison of patients who underwent percutaneous coronary intervention (PCI) or coronary artery bypass grafting (CABG) for the treatment of two-vessel or three vessel coronary artery disease. Strengths of their data are the breadth and number of patients included, that is, more than 180,000 from the combined ACCF and STS databases. Their eport is the most comprehensive sample to date of revascularization outcomes in U.S. patients 65 years of age or older. Although no difference was evident at 1 year, the adjusted all-cause mortality at 4 years was lower by 4.4 percentage points with CABG than with PCI. The validity of these findings rests largely on a determination of whether adequate control for confounding was possible. Even with the findings adjusted for propensity score, Weintraub et al. stated their conclusions cautiously and they acknowledged the possibility of residual confounding. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Mauri, L.},
    citeulike-article-id = {13873809},
    citeulike-linkout-0 = {http://dx.doi.org/10.1056/NEJMe1202866},
    comment = {Comment on:

Comparative effectiveness of revascularization strategies.Weintraub WS, Grau-Sepulveda MV, Weiss JM, O'Brien SM, Peterson ED, Kolm P, Zhang Z, Klein LW, Shaw RE, McKay C, et al. N Engl J Med. 2012 Apr 19; 366(16):1467-76. Epub 2012 Mar 27.},
    doi = {10.1056/NEJMe1202866},
    isbn = {0028-4793; 1533-4406},
    journal = {New England Journal of Medicine},
    keywords = {bias---selection, data---administrative-billing, exportrecords, propensity-scores},
    number = {16},
    pages = {1538--1540},
    posted-at = {2015-12-09 01:10:19},
    priority = {3},
    title = {{Why we still need randomized trials to compare effectiveness.}},
    url = {http://dx.doi.org/10.1056/NEJMe1202866},
    volume = {366},
    year = {2012}
}

@article{20827,
    abstract = {{Despite the fact that randomization is the gold standard for estimating causal relationships, many questions in prevention science are often left to be answered through nonexperimental studies because randomization is either infeasible or unethical. While methods such as propensity score matching can adjust for observed confounding, unobserved confounding is the Achilles heel of most nonexperimental studies. This paper describes and illustrates seven sensitivity analysis techniques that assess the sensitivity of study results to an unobserved confounder. These methods were categorized into two groups to reflect differences in their conceptualization of sensitivity analysis, as well as their targets of interest. As a motivating example, we examine the sensitivity of the association between maternal suicide and offspring's risk for suicide attempt hospitalization. While inferences differed slightly depending on the type of sensitivity analysis conducted, overall, the association between maternal suicide and offspring's hospitalization for suicide attempt was found to be relatively robust to an unobserved confounder. The ease of implementation and the insight these analyses provide underscores sensitivity analysis techniques as an important tool for nonexperimental studies. The implementation of sensitivity analysis can help increase confidence in results from nonexperimental studies and better inform prevention researchers and policy makers regarding potential intervention targets. (PsycINFO Database Record (c) 2013 APA, all rights reserved) (journal abstract)}},
    author = {Liu, W. and Kuramoto, S. J. and Stuart, E. A.},
    citeulike-article-id = {13873808},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s11121-012-0339-5},
    doi = {10.1007/s11121-012-0339-5},
    isbn = {1389-4986; 1573-6695},
    journal = {Prevention Science},
    keywords = {exportrecords, propensity-scores, sensitivity-analysis},
    posted-at = {2015-12-09 01:10:19},
    priority = {3},
    title = {{An introduction to sensitivity analysis for unobserved confounding in nonexperimental prevention research}},
    url = {http://dx.doi.org/10.1007/s11121-012-0339-5}
}

@article{20169,
    abstract = {{In the evaluation of medical products, including drugs, biological products, and medical devices, comparative observational studies could play an important role when properly conducted randomized, well-controlled clinical trials are infeasible due to ethical or practical reasons. However, various biases could be introduced at every stage and into every aspect of the observational study, and consequently the interpretation of the resulting statistical inference would be of concern. While there do exist statistical techniques for addressing some of the challenging issues, often based on propensity score methodology, these statistical tools probably have not been as widely employed in prospectively designing observational studies as they should be. There are also times when they are implemented in an unscientific manner, such as performing propensity score model selection for a dataset involving outcome data in the same dataset, so that the integrity of observational study design and the interpretability of outcome analysis results could be compromised. In this paper, regulatory considerations on prospective study design using propensity scores are shared and illustrated with hypothetical examples.}},
    author = {Yue, L. Q.},
    citeulike-article-id = {13873774},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/10543406.2012.715111},
    doi = {10.1080/10543406.2012.715111},
    isbn = {1520-5711; 1054-3406},
    journal = {Journal of Biopharmaceutical Statistics},
    keywords = {bias---selection, exportrecords, observational-study---criticism, propensity-scores, regulatory-agencies},
    number = {6},
    pages = {1272--1279},
    posted-at = {2015-12-09 01:10:18},
    priority = {3},
    title = {{Regulatory considerations in the design of comparative observational studies using propensity scores}},
    url = {http://dx.doi.org/10.1080/10543406.2012.715111},
    volume = {22},
    year = {2012}
}

@article{20267,
    abstract = {{Propensity scores have been proposed as a method of equating groups at baseline, which is a problem, especially in studies that do not use randomization. This article discusses some difficulties with the technique that may jeopardize the findings if users (and readers) are not aware of these problems.}},
    author = {Streiner, D. L. and Norman, G. R.},
    citeulike-article-id = {13873767},
    citeulike-linkout-0 = {http://dx.doi.org/10.1378/chest.12-1920},
    doi = {10.1378/chest.12-1920},
    isbn = {1931-3543; 0012-3692},
    journal = {Chest},
    keywords = {exportrecords, propensity-scores},
    number = {6},
    pages = {1380--1382},
    posted-at = {2015-12-09 01:10:18},
    priority = {3},
    title = {{The pros and cons of propensity scores}},
    url = {http://dx.doi.org/10.1378/chest.12-1920},
    volume = {142},
    year = {2012}
}

@article{18813,
    author = {Collins, G. S. and Le Manach, Y.},
    citeulike-article-id = {13873422},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/eurheartj/ehs186},
    comment = {Comment on:

Do observational studies using propensity score methods agree with randomized trials? A systematic comparison of studies on acute coronary syndromes.Dahabreh IJ, Sheldrick RC, Paulus JK, Chung M, Varvarigou V, Jafri H, Rassen JA, Trikalinos TA, Kitsios GD. Eur Heart J. 2012 Aug; 33(15):1893-901. Epub 2012 Jun 17.},
    doi = {10.1093/eurheartj/ehs186},
    isbn = {1522-9645; 0195-668X},
    journal = {European Heart Journal},
    keywords = {appraising-quality, exportrecords, propensity-scores, randomized-vs-non-randomized-study-designs, reporting},
    number = {15},
    pages = {1867--1869},
    posted-at = {2015-12-09 01:10:11},
    priority = {3},
    title = {{Comparing treatment effects between propensity scores and randomized controlled trials: improving conduct and reporting}},
    url = {http://dx.doi.org/10.1093/eurheartj/ehs186},
    volume = {33},
    year = {2012}
}

@article{18361,
    abstract = {{Instrumental variable (IV) and risk adjustment (RA) estimators, including propensity score adjustments, are both used to alleviate confounding problems in nonexperimental studies on treatment effects, but it is not clear how estimates based on these 2 approaches compare. Methodological considerations have shown that IV and RA estimators yield estimates of distinct types of causal treatment effects regardless of confounding problems. Many investigators have neglected these distinctions. In this paper, the authors use 3 schematic models to explain visually the relations between IV and RA estimates of intended treatment effects as demonstrated in the methodological studies. When treatment effects are homogeneous across a study population or when treatment effects are heterogeneous across the study population but treatment decisions are unrelated to the treatment effects, RA and IV estimates should be equivalent when the respective assumptions are met. In contrast, when treatment effects are heterogeneous and treatment decisions are related to the treatment effects, RA estimates of treatment effect can asymptotically differ from IV estimates, but both are correct even when the respective assumptions are met. Appropriate interpretations of IV or RA estimates can be facilitated by developing conceptual models related to treatment choice and treatment effect heterogeneity prior to analyses.}},
    author = {Fang, G. and Brooks, J. M. and Chrischilles, E. A.},
    citeulike-article-id = {13873371},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/aje/kwr283},
    doi = {10.1093/aje/kwr283},
    isbn = {1476-6256 0002-9262},
    journal = {American Journal of Epidemiology},
    keywords = {decision-making, exportrecords, heterogeneity---statistical, instrumental-variables, propensity-scores},
    number = {1},
    pages = {60--65},
    posted-at = {2015-12-09 01:10:10},
    priority = {3},
    title = {{Apples and Oranges? Interpretations of Risk Adjustment and Instrumental Variable Estimates of Intended Treatment Effects Using Observational Data}},
    url = {http://dx.doi.org/10.1093/aje/kwr283},
    volume = {175},
    year = {2012}
}

@article{18501,
    abstract = {{Aims Randomized controlled trials (RCTs) are the gold standard for assessing the efficacy of therapeutic interventions because randomization protects from biases inherent in observational studies. Propensity score (PS) methods, proposed as a potential solution to confounding of the treatment-outcome association, are widely used in observational studies of therapeutic interventions for acute coronary syndromes (ACS). We aimed to systematically assess agreement between observational studies using PS methods and RCTs on therapeutic interventions for ACS. Methods and results We searched for observational studies of interventions for ACS that used PS methods to estimate treatment effects on short- or long-term mortality. Using a standardized algorithm, we matched observational studies to RCTs based on patients' characteristics, interventions, and outcomes ('topics'), and we compared estimates of treatment effect between the two designs. When multiple observational studies or RCTs were identified for the same topic, we performed a meta-analysis and used the summary relative risk for comparisons. We matched 21 observational studies investigating 17 distinct clinical topics to 63 RCTs (median = 3 RCTs per observational study) for short-term (7 topics) and long-term (10 topics) mortality. Estimates from PS analyses differed statistically significantly from randomized evidence in two instances; however, observational studies reported more extreme beneficial treatment effects compared with RCTs in 13 of 17 instances (P = 0.049). Sensitivity analyses limited to large RCTs, and using alternative meta-analysis models yielded similar results. Conclusion For the treatment of ACS, observational studies using PS methods produce treatment effect estimates that are of more extreme magnitude compared with those from RCTs, although the differences are rarely statistically significant.}},
    author = {Dahabreh, I. J. and Sheldrick, R. C. and Paulus, J. K. and Chung, M. and Varvarigou, V. and Jafri, H. and Rassen, J. A. and Trikalinos, T. A. and Kitsios, G. D.},
    citeulike-article-id = {13873361},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/eurheartj/ehs114},
    doi = {10.1093/eurheartj/ehs114},
    isbn = {1522-9645 0195-668X},
    journal = {European Heart Journal},
    keywords = {exportrecords, propensity-scores, randomized-vs-non-randomized-study-designs},
    number = {15},
    pages = {1893--1901},
    posted-at = {2015-12-09 01:10:10},
    priority = {3},
    title = {{Do observational studies using propensity score methods agree with randomized trials? A systematic comparison of studies on acute coronary syndromes}},
    url = {http://dx.doi.org/10.1093/eurheartj/ehs114},
    volume = {33},
    year = {2012}
}

@article{18586,
    author = {Brunelli, S. M. and Rassen, J. A.},
    citeulike-article-id = {13873353},
    citeulike-linkout-0 = {http://dx.doi.org/10.1053/j.ajkd.2012.08.030},
    doi = {10.1053/j.ajkd.2012.08.030},
    isbn = {1523-6838; 0272-6386},
    journal = {American Journal of Kidney Diseases},
    keywords = {comparative-effectiveness-research---methods, disease-risk-scores, exportrecords, instrumental-variables, observational-study---criticism, propensity-scores, statistics},
    number = {1},
    pages = {13--17},
    posted-at = {2015-12-09 01:10:10},
    priority = {3},
    title = {{Emerging Analytical Techniques for Comparative Effectiveness Research}},
    url = {http://dx.doi.org/10.1053/j.ajkd.2012.08.030},
    volume = {61},
    year = {2013}
}

@article{17549,
    author = {Concato, J.},
    citeulike-article-id = {13873333},
    citeulike-linkout-0 = {http://dx.doi.org/10.1001/jama.2012.482},
    comment = {Comment on:

Intensity-modulated radiation therapy, proton therapy, or conformal radiation therapy and morbidity and disease control in localized prostate cancer. Sheets NC, Goldin GH, Meyer AM, Wu Y, Chang Y, Sturmer T, Holmes JA, Reeve BB, Godley PA, Carpenter WR, et al. JAMA2012 Apr 18; 307(15):1611-20.

Long-term survival following partial vs radical nephrectomy among older patients with early-stage kidney cancer. Tan HJ, Norton EC, Ye Z, Hafez KS, Gore JL, Miller DC. JAMA 2012 Apr 18; 307(15):1629-35.

Carboplatin and paclitaxel with vs without bevacizumab in older patients with advanced non-small cell lung cancer. Zhu J, Sharma DB, Gray SW, Chen AB, Weeks JC, Schrag D.JAMA. 2012 Apr 18; 307(15):1593-601.

Association between helicopter vs ground emergency medical services and survival for adults with major trauma. Galvagno SM Jr, Haut ER, Zafar SN, Millin MG, Efron DT, Koenig GJ Jr, Baker SP, Bowman SM, Pronovost PJ, Haider AH. JAMA 2012 Apr 18; 307(15):1602-10.

Comparison of long-term survival after open vs endovascular repair of intact abdominal aortic aneurysm among Medicare beneficiaries. Jackson RS, Chang DC, Freischlag JA. JAMA 2012 Apr 18; 307(15):1621-8.},
    doi = {10.1001/jama.2012.482},
    isbn = {1538-3598; 0098-7484},
    journal = {JAMA},
    keywords = {comparative-effectiveness-research---usability-of-results, evidence-based-practice---criticism, exportrecords, instrumental-variables, propensity-scores, randomized-vs-non-randomized-study-designs},
    number = {15},
    pages = {1641--1643},
    posted-at = {2015-12-09 01:10:09},
    priority = {3},
    title = {{Is it time for medicine-based evidence?}},
    url = {http://dx.doi.org/10.1001/jama.2012.482},
    volume = {307},
    year = {2012}
}

@article{17452,
    author = {Walsh, M. C. and Trentham-Dietz, A. and Newcomb, P. A. and Gangnon, R. and Palta, M.},
    citeulike-article-id = {13873330},
    citeulike-linkout-0 = {http://dx.doi.org/10.1097/EDE.0b013e3182628365},
    comment = {Comment on:

Cell phone use and crash risk: evidence for positive bias.Young RA. Epidemiology. 2012 Jan; 23(1):116-8.},
    doi = {10.1097/EDE.0b013e3182628365},
    isbn = {1531-5487; 1044-3983;},
    journal = {Epidemiology},
    keywords = {bias---selection, exportrecords, observational-study---criticism, propensity-scores},
    number = {5},
    pages = {772--773},
    posted-at = {2015-12-09 01:10:09},
    priority = {3},
    title = {{Using Propensity Scores to Reduce Case-control Selection Bias}},
    url = {http://dx.doi.org/10.1097/EDE.0b013e3182628365},
    volume = {23},
    year = {2012}
}

@book{24215,
    abstract = {{[From the Publisher's Website] Due to recent theoretical findings and advances in statistical computing, there has been a rapid development of techniques and applications in the area of missing data analysis. Statistical Methods for Handling Incomplete Data covers the most up-to-date statistical theories and computational methods for analyzing incomplete data. Suitable for graduate students and researchers in statistics, the book presents thorough treatments of: Statistical theories of likelihood-based inference with missing data Computational techniques and theories on imputation Methods involving propensity score weighting, nonignorable missing data, longitudinal missing data, survey sampling, and statistical matching Assuming prior experience with statistical theory and linear models, the text uses the frequentist framework with less emphasis on Bayesian methods and nonparametric methods. It includes many examples to help readers understand the methodologies. Some of the research ideas introduced can be developed further for specific applications. TABLE OF CONTENTS: Introduction Likelihood-Based Approach Introduction Observed Likelihood Mean Score Approach Observed Information Computation Introduction Factoring Likelihood Approach EM Algorithm Monte Carlo Computation Monte Carlo EM Data Augmentation Imputation Introduction Basic Theory for Imputation Variance Estimation after Imputation Replication Variance Estimation Multiple Imputation Fractional Imputation Propensity Scoring Approach Introduction Regression Weighting Method Propensity Score Method Optimal Estimation Doubly Robust Method Empirical Likelihood Method Nonparametric Method Nonignorable Missing Data Nonresponse Instrument Conditional Likelihood Approach Generalized Method of Moments (GMM) Approach Pseudo Likelihood Approach Exponential Tilting (ET) Model Latent Variable Approach Callbacks Capture–Recapture (CR) Experiment Longitudinal and Clustered Data Ignorable Missing Data Nonignorable Monotone Missing Data Past-Value-Dependent Missing Data Random-Effect-Dependent Missing Data Application to Survey Sampling Introduction Calibration Estimation Propensity Score Weighting Method Fractional Imputation Fractional Hot Deck Imputation Imputation for Two-Phase Sampling Synthetic Imputation Statistical Matching Introduction Instrumental Variable Approach Measurement Error Models Causal Inference}},
    author = {Kim, J. K. and Shao, J.},
    citeulike-article-id = {13873102},
    isbn = {9781439849637; 1439849633; 1439849641; 9781439849644; 9781482205077; 1482205076; 1482205092; 9781482205091},
    keywords = {data---missing, exportrecords, propensity-scores},
    location = {Boca Raton, FL},
    pages = {223p.+},
    posted-at = {2015-12-09 01:10:05},
    priority = {3},
    publisher = {Chapman and Hall/CRC},
    title = {{Statistical methods for handling incomplete data}},
    year = {2013}
}

@article{16109,
    abstract = {{Summary Randomized trials remain the most accepted design for estimating the effects of interventions, but they do not necessarily answer a question of primary interest: will the programme be effective in a target population in which it may be implemented? In other words, are the results generalizable? There has been very little statistical research on how to assess the generalizability, or 'external validity', of randomized trials. We propose the use of propensity-score-based metrics to quantify the similarity of the participants in a randomized trial and a target population. In this setting the propensity score model predicts participation in the randomized trial, given a set of covariates. The resulting propensity scores are used first to quantify the difference between the trial participants and the target population, and then to match, subclassify or weight the control group outcomes to the population, assessing how well the propensity-score-adjusted outcomes track the outcomes that are actually observed in the population. These metrics can serve as a first step in assessing the generalizability of results from randomized trials to target populations. The paper lays out these ideas, discusses the assumptions underlying the approach and illustrates the metrics by using data on the evaluation of a schoolwide prevention programme called 'Positive behavioral interventions and supports'.}},
    author = {Stuart, E. A. and Cole, S. R. and Bradshaw, C. P. and Leaf, P. J.},
    citeulike-article-id = {13873017},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.1467-985X.2010.00673.x},
    doi = {10.1111/j.1467-985X.2010.00673.x},
    isbn = {0964-1998; 1467-985X},
    journal = {Journal of the Royal Statistical Society. Series A: Statistics in Society},
    keywords = {applicability, exportrecords, propensity-scores},
    number = {2},
    pages = {369--386},
    posted-at = {2015-12-09 01:09:19},
    priority = {3},
    title = {{The use of propensity scores to assess the generalizability of results from randomized trials}},
    url = {http://dx.doi.org/10.1111/j.1467-985X.2010.00673.x},
    volume = {174},
    year = {2011}
}

@article{16926,
    author = {Cotton, C. A. and Cuerden, M. S. and Cook, R. J.},
    citeulike-article-id = {13873001},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.1537-2995.2011.03324.x},
    doi = {10.1111/j.1537-2995.2011.03324.x},
    isbn = {1537-2995 ; 0041-1132},
    journal = {Transfusion},
    keywords = {exportrecords, propensity-scores},
    number = {12},
    pages = {2536--2539},
    posted-at = {2015-12-09 01:09:19},
    priority = {3},
    title = {{Causal inference in nonrandomized studies via propensity score methods}},
    url = {http://dx.doi.org/10.1111/j.1537-2995.2011.03324.x},
    volume = {51},
    year = {2011}
}

@article{17381,
    abstract = {{Mandated post-marketing drug safety studies require vast databases pooled from multiple administrative data sources which can contain private and proprietary information. We sought to create a method to conduct pooled analyses while keeping information private and allowing for full confounder adjustment.We propose a method based on propensity score (PS) techniques. A set of propensity scores are computed in each data-contributing center and a PS-adjusted analysis is then carried out on a pooled basis. The method is demonstrated in a study of the potentially negative effects of concurrent initiation of clopidogrel and proton pump inhibitors (PPIs) in four cohorts of patients assembled from North American claims data sources. Clinical outcomes were myocardial infarction (MI) hospitalization and hospitalization for revascularization procedure. Success of the method was indicated by equivalent performance of our PS-based method and traditional confounder adjustment. We also implemented and evaluated high-dimensional propensity scores and meta-analytic techniques.On both a pooled and individual cohort basis, we saw substantially similar point estimates and confidence intervals for studies adjusted by covariates and from privacy-maintaining propensity scores. The pooled, adjusted OR for MI hospitalization was 1.20 (95\% confidence interval 1.03, 1.41) with individual variable adjustment and 1.16 (1.00, 1.36) with PS adjustment. The revascularization OR estimates differed by<\'{a}1\%. Meta-analysis and pooling yielded substantially similar results.We observed little difference in point estimates when we employed standard techniques or the proposed privacy-maintaining pooling method. We would recommend the technique in instances where multi-center studies require both privacy and multivariate adjustment. Copyright {\copyright} 2010 John Wiley \& Sons, Ltd.}},
    author = {Rassen, J. A. and Avorn, J. and Schneeweiss, S.},
    citeulike-article-id = {13872941},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.1867},
    doi = {10.1002/pds.1867},
    isbn = {1053-8569; 1099-1557},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {adverse-events---harms, data---administrative-billing, data---individual-participant, exportrecords, propensity-scores, quantitative-synthesis---individual-participant-meta-analysis},
    number = {8},
    pages = {848--857},
    posted-at = {2015-12-09 01:09:18},
    priority = {3},
    title = {{Multivariate-adjusted pharmacoepidemiologic analyses of confidential information pooled from multiple health care utilization databases}},
    url = {http://dx.doi.org/10.1002/pds.1867},
    volume = {19},
    year = {2010}
}

@article{31284,
    abstract = {{I use diagrams to illustrate the sources of potential selection bias in observational studies of comparative effectiveness. I adapt these diagrams for three hypothetical scenarios that clarify the strengths and weaknesses of two prominent methods used to account for potential selection bias: propensity scores and instrumental variables. After reviewing the fundamentals of how to apply each method, including new developments that make implementation easier, I refer to some recent studies that illustrate how choice of method can affect estimates. I conclude by emphasizing that many studies with apparently rich sources of data are nevertheless unlikely to produce unbiased estimates and that conceptual modeling can help identify these problems in advance. {\copyright} Springer Science+Business Media, LLC 2009.}},
    author = {Pizer, S. D.},
    citeulike-article-id = {13872813},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s10742-009-0045-3},
    doi = {10.1007/s10742-009-0045-3},
    issn = {1387-3741},
    journal = {Health Services and Outcomes Research Methodology},
    keywords = {bias---selection, comparative-effectiveness-research---methods, exportrecords, instrumental-variables, propensity-scores},
    number = {1},
    pages = {54--68},
    posted-at = {2015-12-09 01:09:14},
    priority = {3},
    title = {{An intuitive review of methods for observational studies of comparative effectiveness}},
    url = {http://dx.doi.org/10.1007/s10742-009-0045-3},
    volume = {9},
    year = {2009}
}

@phdthesis{20853,
    abstract = {{This study uses a multi-level multivariate propensity score matching approach to examine the synthetic cohort design (SCD) in estimating the schooling effect on mathematics proficiency of the focal cohort 2 (8th graders). Collecting 7th and 8th graders at the same time point, the SCD is sufficient in estimating the schooling effect under the historical equivalency of groups (HEoG) assumption. A structural equation modeling (SEM) framework is used to define the HEoG assumption. It has shown that HEoG assures that the use of SCD results in an unbiased estimate of schooling effect without randomized data. The post-hoc group matching is used to achieve the HEoG assumption in order to produce an estimate of schooling effect that is unbiased in SCD. Three matching approaches, level-1 matching, level-2 matching, and dual matching, are evaluated using simulated data generated based on USA participants of the Second International Mathematics Study (SIMS-USA, IEA, 1977). Two-level latent variable models based on situations that violated the HEoG assumption are created in order to examine the ability of matching to reduce the simulated selection biases to improve the accuracy of the schooling effect estimate in SCD. The three simulated situations involve hierarchically structured data, surrogate covariates with measurement errors, and omitted covariates. Results suggest the following: (1) To reduce initial bias and assure the HEoG assumption, three different matching approaches should be conducted on the covariates according to where the initial bias occurs: on level-1 covariates, on level-2 covariates, and on both level-1 and level-2 covariates; (2) When reliability is low (e.g., .25), latent variable matching does not help improve group comparability, but using observed surrogate variables to match can reduce bias by more than 50 percent. When reliability is high (e.g., greater than .75), latent variable matching reduces bias as much as matching on observed surrogate variables does; (3) When level-2 initial bias is large, increasing level-2 R2 does help to improve level-2 matching. The bias reduction of either individual or dual propensity score matching is not sensitive to the increase of R 2. The dual propensity score matching is more robust to the magnitude of initial selection bias, achieving a large bias reduction rate when the initial bias is small. Either level-1 matching or level-2 matching achieves lower bias reduction rate when the initial bias is small. This dissertation study provides a theoretical basis for future research to examine the effectiveness of propensity score matching in reducing the selection bias of SCD for casual inference and program evaluation. Practical considerations and suggestions for future research on hierarchically structured data in program evaluation are discussed. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Wang, Q.},
    citeulike-article-id = {13872734},
    isbn = {978-1-124-34850-6;},
    keywords = {exportrecords, propensity-scores},
    location = {East Lansing, MI},
    pages = {1--180},
    posted-at = {2015-12-09 01:09:13},
    priority = {3},
    school = {Michigan State University},
    title = {{Matching for bias reduction in treatment effect estimation of hierarchically structured synthetic cohort design data}},
    year = {2010}
}

@phdthesis{20881,
    abstract = {{We present three examples of public health research problems for which causal inference methods are better suited than commonly used traditional analytical methods. We expand and generalize our causal inference approaches in systematic ways to provide insight into their potential use beyond these specific motivating examples. First is adjusting for confounding in observational studies. Although there is a growing trend to use propensity score analyses to confirm results from traditional adjustment methods, there has been little systematic comparison of propensity score and traditional regression adjustment methods, particularly when the majority of confounders are dichotomous variables. This leaves open the question of how to interpret potentially conflicting results from the two methods. We simulate comparison groups with higher and lower frequencies of confounders, and compare the performance of traditional and propensity score methods in terms of estimated treatment effect. Next, we examine the performance of Frangakis and Rubin's (2002) principle stratification method for estimating treatment effects when outcome measures are 'truncated' by death. In our example from the ProTECT study [Wright et al., 2007] of traumatic brain injury patients, we have the added complication of missing mortality status due to loss to follow-up. We are not aware of any other research that examines the performance of principle stratification analyses when the post-randomization variable upon which stratification is based is missing among some observations. We examine the sensitivity of causal effect estimates to assumptions about the structure of the principle strata themselves versus possible patterns of missingness, and show that, for our example, the former are more influential. Last, there have been recent efforts to define a prognostic score for stroke and traumatic brain injury patients, to enable tailoring of definitions of 'favorable' outcomes based on a patient's predicted outcome. We propose a new application of Hansen's (2006, 2008) prognostic scoring methods to this problem, and compare our prognostic score results to those generated by prognostic models from the existing literature. We also conduct a formal power analysis comparing analyses using outcomes based on a patient's prognosis versus traditional outcome measures. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Price, M.},
    citeulike-article-id = {13872723},
    isbn = {978-1-109-23045-1;},
    keywords = {bias---selection, exportrecords, propensity-scores},
    location = {Atlanta, GA},
    pages = {1--166},
    posted-at = {2015-12-09 01:09:13},
    priority = {3},
    school = {Emory University},
    title = {{Issues in causal inference and applications to public health}},
    year = {2009}
}

@phdthesis{20867,
    abstract = {{Propensity score matching is a widely used tool for estimating treatment effects in observational studies. Little work however has been conducted applying propensity score methods to data that are clustered and ideally analyzed using multi-level models. This dissertation focuses on estimation strategies for the propensity score in multi-site nonrandomized designs, exploring several multi-level formulations. The different formulations reflect different assumptions about the selection process being modeled by the propensity score. Models with only random intercepts as well as a varying number of random slopes were considered. The absence of random slopes relating confounding covariates and treatment assignment was analytically shown to imply that information from cluster-specific covariates would not be needed to produce an unbiased estimate of the treatment effect conditional on the propensity score. A large simulation study explored the performance of the different models with a special focus on model behavior under misspecification. Data were generated according to several possible selection models and were analyzed using different multi-level propensity score models. The factors examined were sample size, strength of confounding, and the number and magnitude of variance of the random slopes in the population selection model. In each of the 1,000 replications per condition prima facie treatment effects and various measures of bias were calculated. In conditions with weak confounding all models performed equally well in terms of bias reduction, however the performance across models differed as strength of confounding increased. A single level model commonly used in the behavioral sciences that ignored clustering showed more bias after conditioning when compared to any of the multi-level models. The multi-level models with both random intercepts and slopes performed slightly, but consistently better than the random intercept only models. Adding random slopes that are allowed to vary across clusters can be seen as being conceptually similar to overfitting a model with additional predictors. Results indicated that the recommendation of overfitting propensity score models extends to the multi-level models considered in this study, but careful attention is needed in the modeling process to avoid problems of non-convergence in the estimation procedure. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Thoemmes, F. J.},
    citeulike-article-id = {13872721},
    isbn = {U13  - sent},
    keywords = {exportrecords, propensity-scores},
    location = {Tempe, AZ},
    pages = {1--201},
    posted-at = {2015-12-09 01:09:12},
    priority = {3},
    school = {Arizona State University},
    title = {{The use of propensity scores with clustered data: A simulation study}},
    year = {2009}
}

@article{20865,
    abstract = {{Reviews the book, Propensity Score Analysis: Statistical Methods and Applications by S. Guo and M. W. Fraser (see record 2010-00734-000). It is the first comprehensive book that discusses and compares different propensity score (PS) techniques from theoretical and practical points of view. Overall, the book is partitioned into nine chapters. One of the book's strengths is its focus on the application of PS to real data. The authors demonstrate the practical implementation of all the methods introduced by using Stata and several real datasets. They explain the syntax of corresponding Stata procedures and show its practical implementation and interpretation. They also provide guidelines to help researchers avoiding common pitfalls when analyzing observational studies. A further strength is the book's coverage of alternatives to PS methods-general matching methods and Heckman's selection model. However, the broad coverage was obtained at the expense of a more thorough presentation of PS methods. In presenting a variety of different PS-related methods, the authors put more emphasis on technical aspects than corresponding design and data related aspects like the analogy of PS analyses to randomized experiments. This textbook gives a good introduction to PS matching techniques and some alternative approaches for estimating causal treatment effects. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Steiner, P. M.},
    citeulike-article-id = {13872720},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s11336-010-9170-8},
    doi = {10.1007/s11336-010-9170-8},
    isbn = {0033-3123; 1860-0980},
    journal = {Psychometrika},
    keywords = {exportrecords, propensity-scores},
    number = {4},
    pages = {775--777},
    posted-at = {2015-12-09 01:09:12},
    priority = {3},
    title = {{Review of Propensity score analysis: Statistical methods and applications}},
    url = {http://dx.doi.org/10.1007/s11336-010-9170-8},
    volume = {75},
    year = {2010}
}

@article{20857,
    abstract = {{The use of propensity scores in psychological and educational research has been steadily increasing in the last 2 to 3 years. However, there are some common misconceptions about the use of different estimation techniques and conditioning choices in the context of propensity score analysis. In addition, reporting practices for propensity score analyses often lack important details that allow other researchers to confidently judge the appropriateness of reported analyses and potentially to replicate published findings. In this article we conduct a systematic literature review of a large number of published articles in major areas of social science that used propensity scores up until the fall of 2009. We identify common errors in estimation, conditioning, and reporting of propensity score analyses and suggest possible solutions. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Thoemmes, F. J. and Kim, E. S.},
    citeulike-article-id = {13872719},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/00273171.2011.540475},
    doi = {10.1080/00273171.2011.540475},
    isbn = {0027-3171; 1532-7906},
    journal = {Multivariate Behavioral Research},
    keywords = {exportrecords, propensity-scores},
    number = {1},
    pages = {90--118},
    posted-at = {2015-12-09 01:09:12},
    priority = {3},
    title = {{A systematic review of propensity score methods in the social sciences}},
    url = {http://dx.doi.org/10.1080/00273171.2011.540475},
    volume = {46},
    year = {2011}
}

@article{20838,
    abstract = {{In this article we propose several modeling choices to extend propensity score analysis to clustered data. We describe different possible model specifications for estimation of the propensity score: single-level model, fixed effects model, and two random effects models. We also consider both conditioning within clusters and conditioning across clusters. We examine the underlying assumptions of these modeling choices and the type of randomized experiment approximated by each approach. Using a simulation study, we compare the relative performance of these modeling and conditioning choices in reducing bias due to confounding variables at both the person and cluster levels. An applied example based on a study by Hughes, Chen, Thoemmes, and Kwok (2010) is provided in which the effect of retention in Grade 1 on passing an achievement test in Grade 3 is evaluated. We find that models that consider the clustered nature of the data both in estimation of the propensity score and conditioning on the propensity score performed best in our simulation study; however, other modeling choices also performed well. The applied example illustrates practical limitations of these models when cluster sizes are small. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Thoemmes, F. J. and West, S. G.},
    citeulike-article-id = {13872718},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/00273171.2011.569395},
    doi = {10.1080/00273171.2011.569395},
    isbn = {0027-3171; 1532-7906},
    journal = {Multivariate Behavioral Research},
    keywords = {exportrecords, propensity-scores},
    number = {3},
    pages = {514--543},
    posted-at = {2015-12-09 01:09:12},
    priority = {3},
    title = {{The use of propensity scores for nonrandomized designs with clustered data}},
    url = {http://dx.doi.org/10.1080/00273171.2011.569395},
    volume = {46},
    year = {2011}
}

@article{20830,
    abstract = {{The effect of unreliability of measurement on propensity score (PS) adjusted treatment effects has not been previously studied. The authors report on a study simulating different degrees of unreliability in the multiple covariates that were used to estimate the PS. The simulation uses the same data as two prior studies. Shadish, Clark, and Steiner showed that a PS formed from many covariates demonstrably reduced selection bias, while Steiner, Cook, Shadish, and Clark identified the subsets of covariates from the larger set that were most effective for bias reduction. Adding different degrees of random error to these covariates in a simulation, the authors demonstrate that unreliability of measurement can degrade the ability of PSs to reduce bias. Specifically, increases in reliability only promote bias reduction, if the covariates are effective in reducing bias to begin with. Increasing or decreasing the reliability of covariates that do not effectively reduce selection bias makes no difference at all. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Steiner, P. M. and Cook, T. D. and Shadish, W. R.},
    citeulike-article-id = {13872717},
    citeulike-linkout-0 = {http://dx.doi.org/10.3102/1076998610375835},
    doi = {10.3102/1076998610375835},
    isbn = {1076-9986; 1935-1054},
    journal = {Journal of Educational and Behavioral Statistics},
    keywords = {exportrecords, propensity-scores},
    number = {2},
    pages = {213--236},
    posted-at = {2015-12-09 01:09:12},
    priority = {3},
    title = {{On the importance of reliable covariate measurement in selection bias adjustments using propensity scores}},
    url = {http://dx.doi.org/10.3102/1076998610375835},
    volume = {36},
    year = {2011}
}

@article{20877,
    abstract = {{McCandless, Gustafson and Austin (2009) describe a Bayesian approach to regression adjustment for the propensity score to reduce confounding. A unique property of the method is that the treatment and outcome models are combined via Bayes theorem. However, this estimation procedure can be problematic if the outcome model is misspecified. We observe feedback that can bias propensity score estimates. Building on new innovation in Bayesian computation, we propose a technique for cutting feedback in a Bayesian propensity analysis. We use the posterior distribution of the propensity scores as an input in the regression model for the outcome. The method is approximately Bayesian in the sense that it does not use the full likelihood for estimation. Nonetheless, it severs feedback between the treatment and outcome giving propensity score estimates that are free from bias but modeled with uncertainty. We illustrate the method in a matched cohort study investigating the effect of statins on primary stroke prevention. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {McCandless, L. C. and Douglas, I. J. and Evans, S. J. and Smeeth, L.},
    citeulike-article-id = {13872710},
    citeulike-linkout-0 = {http://dx.doi.org/10.2202/1557-4679.1205},
    doi = {10.2202/1557-4679.1205},
    isbn = {1557-4679;},
    journal = {International Journal of Biostatistics},
    keywords = {exportrecords, propensity-scores},
    number = {2},
    pages = {Article 16+},
    posted-at = {2015-12-09 01:09:12},
    priority = {3},
    title = {{Cutting feedback in Bayesian regression adjustment for the propensity score}},
    url = {http://dx.doi.org/10.2202/1557-4679.1205},
    volume = {6},
    year = {2010}
}

@article{20861,
    abstract = {{Propensity score methods are an increasingly popular technique for causal inference. To estimate propensity scores, we must model the distribution of the treatment indicator given a vector of covariates. Much work has been done in the case where the covariates are fully observed. Unfortunately, many large scale and complex surveys, such as longitudinal surveys, suffer from missing covariate values. In this paper, we compare three different approaches and their underlying assumptions of handling missing background data in the estimation and use of propensity scores: a complete case analysis, a pattern-mixture model based approach developed by Rosenbaum and Rubin (J Am Stat Assoc79:516-524, 1984), and a multiple imputation approach. We apply these methods to assess the impact of childbearing events on individuals' well being in Indonesia, using a sample of women from the Indonesia Family Life Survey. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Mattei, A.},
    citeulike-article-id = {13872709},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s10260-007-0086-0},
    doi = {10.1007/s10260-007-0086-0},
    isbn = {1618-2510; 1613-981X},
    journal = {Statistical Methods and Applications},
    keywords = {data---missing, exportrecords, propensity-scores},
    number = {2},
    pages = {257--273},
    posted-at = {2015-12-09 01:09:12},
    priority = {3},
    title = {{Estimating and using propensity score in presence of missing background data: An application to assess the impact of childbearing on wellbeing}},
    url = {http://dx.doi.org/10.1007/s10260-007-0086-0},
    volume = {18},
    year = {2009}
}

@article{20895,
    abstract = {{Objectives: This study reports on the concept and method of linear propensity scores used to obtain a comparison group from the National Longitudinal Survey of Children and Youth to assess the effects of a longitudinal, structured arts program for Canadian youth (aged 9 to 15 years) from low-income, multicultural communities. Method: This study compares 183 children in a community arts project to 183 children from a national longitudinal survey using propensity score matching. The variables included baseline scores of child-rated conduct problems, indirect aggression, emotional problems, self-esteem, and prosocial behavior and child gender, person most knowledgeable (PMK) education, PMK marital status, household income, and family functioning. Results: Mean score comparison showed that the groups were very similar on all covariates. Conclusions: Propensity score matching offers an alternative to true randomization that is cost-effective and convenient, particularly important for social work research in community-based organizations with a limited budget. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {John, L. and Wright, R. and Duku, E. K. and Willms, J. D.},
    citeulike-article-id = {13872699},
    citeulike-linkout-0 = {http://dx.doi.org/10.1177/1049731507303958},
    doi = {10.1177/1049731507303958},
    isbn = {U13  - sent},
    journal = {Research on Social Work Practice},
    keywords = {exportrecords, propensity-scores},
    number = {1},
    pages = {20--26},
    posted-at = {2015-12-09 01:09:12},
    priority = {3},
    title = {{The use of propensity scores as a matching strategy}},
    url = {http://dx.doi.org/10.1177/1049731507303958},
    volume = {18},
    year = {2008}
}

@phdthesis{20887,
    abstract = {{Composite outcomes defined by logical (Boolean) operations on mixed original outcomes arise often in biomedical research. For example, hypertension is often defined as a systolic blood pressure greater than or equal to 140 mmHg, a diastolic blood pressure greater than or equal to 90 mmHg, or the use of antihypertensive medication. When there are no missing values in the original outcomes, the estimation of the proportion of successes from a composite outcome is straightforward; however, when there are missing values in the original outcomes, the estimation is less clear and common estimators can be biased, even if the missingness is completely at random. Motivated from the study of hypertension, we propose estimators of prevalence, methods of joint regression modeling of continuous and binary outcomes, and conduct fully Bayesian longitudinal analyses of these outcomes. This dissertation comprises three distinct papers. In the first paper, the logically defined outcome (composite outcome) is defined and four estimators of the prevalence are proposed and compared. The maximum likelihood estimator, using all available data, is shown to be consistent and efficient while the naive estimator is arbitrarily biased. In the second paper, we jointly model two continuous outcomes and one binary outcome using shared random effects (intercept) models with a probit model for the binary outcome and propose the use of the propensity score as a way to balance confounding variables in order to obtain the proportion of successes of the composite outcome associated with covariates. In the third paper, Bayesian joint modeling of longitudinal continuous and binary outcomes is proposed to analyze a novel hypertension data set and Markov chain Monte Carlo algorithms are used to sample from the posterior distributions of parameters. The proposed statistical methods for composite outcomes and their components in this dissertation perform reasonably well and can be used in many epidemiologic studies and clinical trials with continuous and binary outcomes. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Li, X.},
    citeulike-article-id = {13872698},
    keywords = {exportrecords, propensity-scores},
    location = {Baltimore, MD},
    pages = {1--120},
    posted-at = {2015-12-09 01:09:12},
    priority = {3},
    school = {Johns Hopkins University},
    title = {{Modeling composite outcomes and jointly modeling their components}},
    year = {2008}
}

@article{20874,
    abstract = {{When the randomized controlled trial is unfeasible, program evaluators attempt to emulate the randomization process in observational studies by creating a control group that is essentially equivalent to the treatment group on known characteristics and trust that the remaining unknown characteristics are inconsequential and will not bias the results. In recent years, adjustment procedures based on the propensity score, such as matching and subclassification, have become increasingly popular. A new technique that has particular appeal for evaluating health management programs uses the propensity score to create a weight based on the subject's inverse probability of receiving treatment. This weighting mechanism removes imbalances of pre-intervention characteristics between treated and non-treated individuals, and is then used within a regression framework to provide unbiased estimates of treatment effects. This paper presents a non-technical introduction of this technique by illustrating its implementation with data from a recent study estimating the impact of a motivational interviewing-based health coaching on patient activation measure scores in a chronically ill group of individuals. Because of its relative simplicity and tremendous utility, propensity-score weighting adjustment should be considered as an alternative procedure for use with observational data to evaluate health management program effectiveness. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Linden, A. and Adams, J. L.},
    citeulike-article-id = {13872697},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.1365-2753.2009.01219.x},
    doi = {10.1111/j.1365-2753.2009.01219.x},
    isbn = {1356-1294; 1365-2753},
    journal = {Journal of Evaluation in Clinical Practice},
    keywords = {exportrecords, propensity-scores},
    number = {1},
    pages = {175--179},
    posted-at = {2015-12-09 01:09:12},
    priority = {3},
    title = {{Using propensity score-based weighting in the evaluation of health management programme effectiveness.}},
    url = {http://dx.doi.org/10.1111/j.1365-2753.2009.01219.x},
    volume = {16},
    year = {2010}
}

@phdthesis{20868,
    abstract = {{Recent calls for accountability have focused on scientifically based research that isolates causal mechanisms to inform both the policies and practices of education. A major challenge in aligning educational research with such standards has been to develop methods that can address the interdependency and multilevel structure of teaching and learning and approximate randomized experiments using observational data. In this dissertation, I carried out three studies that centered on improving causal inferences drawn from observational studies in common educational settings. In the first study, I developed several models for estimating multilevel propensity scores (PSs) and examined their effectiveness for causal inference. The results suggested consistent gains from multilevel PSs that allow differential influence of the group on its individuals. The results further suggested that covariate selection in multilevel PSs can play a large role, both relative to model type and in an absolute sense. The second study then developed a method to construct PSs in an effective and efficient manner using two pivotal relationships. The method made use of each covariate's relationship with the treatment and commonly available outcome proxies (e.g. pretest measures) to construct PSs that minimizes the mean-square error (MSE) of the treatment effect estimator. The results of the study suggested that an effective and efficient approach to constructing the PS might be to include those covariates whose relationship with the outcome is at least half the magnitude of the respective relationship with the treatment. In the final study, I develop an index that assesses the sensitivity of inferences in binomial regression models by extending the impact threshold of a confounding variable framework (Frank, 2000). Each of these methods is then applied to observational data to demonstrate how these methods can advance the quality and robustness of causal inferences in educational research. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Kelcey, B. M.},
    citeulike-article-id = {13872696},
    isbn = {978-1-109-43655-6;},
    keywords = {exportrecords, propensity-scores, sensitivity-analysis},
    location = {Ann Arbor, MI},
    pages = {1--301},
    posted-at = {2015-12-09 01:09:12},
    priority = {3},
    school = {University of Michigan},
    title = {{Improving and assessing propensity score based causal inferences in multilevel and nonlinear settings}},
    year = {2009}
}

@phdthesis{20858,
    abstract = {{When researchers are unable to randomly assign students to treatment conditions, selection bias is introduced into the estimates of treatment effects. Random assignment to treatment conditions, which has historically been the scientific benchmark for causal inference, is often impossible or unethical to implement in educational systems. For example, researchers cannot deny services to those who stand to gain from participation in an academic program. Additionally, students select into a particular treatment group through processes that are impossible to control, such as those that result in a child dropping-out of high school or attending a resource-starved school. Propensity score methods provide valuable tools for removing the selection bias from quasi-experimental research designs and observational studies through modeling the treatment assignment mechanism. The utility of propensity scores has been validated for the purposes of removing selection bias when the observations are assumed to be independent; however, the ability of propensity scores to remove selection bias in a multilevel context, in which group membership plays a role in the treatment assignment, is relatively unknown. A central purpose of the current study was to begin filling in the gaps in knowledge regarding the performance of propensity scores for removing selection bias, as defined by covariate balance, in multilevel settings using a Monte Carlo simulation study. The performance of propensity scores was also examined using a large-scale national dataset. Results from this study provide support for the conclusion that multilevel characteristics of a sample have a bearing upon the performance of propensity scores to balance covariates between treatment and control groups. Findings suggest that propensity score estimation models should take into account the cluster-level effects when working with multilevel data; however, the numbers of treatment and control group individuals within each cluster must be sufficient to allow estimation of those effects. Propensity scores that take into account the cluster-level effects can have the added benefit of balancing covariates within each cluster and across the sample as a whole. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Lingle, J. A.},
    citeulike-article-id = {13872695},
    isbn = {978-1-124-04820-8;},
    keywords = {bias---selection, data---administrative-billing, exportrecords, propensity-scores},
    location = {Atlanta, GA},
    pages = {1--264},
    posted-at = {2015-12-09 01:09:12},
    priority = {3},
    school = {Georgia State University},
    title = {{Evaluating the performance of propensity scores to address selection bias in a multilevel context: A Monte Carlo simulation study and application using a national dataset}},
    year = {2009}
}

@article{20893,
    abstract = {{A central theme of research on human development and psychopathology is whether a therapeutic intervention or a turning-point event, such as a family break-up, alters the trajectory of the behavior under study. This article describes and applies a method for using observational longitudinal data to make more transparent causal inferences about the impact of such events on developmental trajectories. The method combines 2 distinct lines of research: work on the use of finite mixture modeling to analyze developmental trajectories and work on propensity score matching. The propensity scores are used to balance observed covariates and the trajectory groups are used to control pretreatment measures of response. The trajectory groups also aid in characterizing classes of subjects for which no good matches are available. The approach is demonstrated with an analysis of the impact of gang membership on violent delinquency based on data from a large longitudinal study conducted in Montreal, Canada. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Haviland, A. and Nagin, D. S. and Rosenbaum, P. R. and Tremblay, R. E.},
    citeulike-article-id = {13872687},
    citeulike-linkout-0 = {http://dx.doi.org/10.1037/0012-1649.44.2.422},
    doi = {10.1037/0012-1649.44.2.422},
    isbn = {0012-1649; 1939-0599},
    journal = {Developmental Psychology},
    keywords = {exportrecords, modeling, propensity-scores},
    number = {2},
    pages = {422--436},
    posted-at = {2015-12-09 01:09:12},
    priority = {3},
    title = {{Combining group-based trajectory modeling and propensity score matching for causal inferences in nonexperimental longitudinal data}},
    url = {http://dx.doi.org/10.1037/0012-1649.44.2.422},
    volume = {44},
    year = {2008}
}

@article{20870,
    abstract = {{There is considerable interest in using propensity score (PS) statistical techniques to address questions of causal inference in psychological research. Many PS techniques exist, yet few guidelines are available to aid applied researchers in their understanding, use, and evaluation. In this study, the authors give an overview of available techniques for PS estimation and PS application. They also provide a way to help compare PS techniques, using the resulting measured covariate balance as the criterion for selecting between techniques. The empirical example for this study involves the potential causal relationship linking early-onset cannabis problems and subsequent negative mental health outcomes and uses data from a prospective cohort study. PS techniques are described and evaluated on the basis of their ability to balance the distributions of measured potentially confounding covariates for individuals with and without early-onset cannabis problems. This article identifies the PS techniques that yield good statistical balance of the chosen measured covariates within the context of this particular research question and cohort. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Harder, V. S. and Stuart, E. A. and Anthony, J. C.},
    citeulike-article-id = {13872686},
    citeulike-linkout-0 = {http://dx.doi.org/10.1037/a0019623},
    doi = {10.1037/a0019623},
    isbn = {1082-989X; 1939-1463},
    journal = {Psychological Methods},
    keywords = {exportrecords, propensity-scores},
    number = {3},
    pages = {234--249},
    posted-at = {2015-12-09 01:09:12},
    priority = {3},
    title = {{Propensity score techniques and the assessment of measured covariate balance to test causal associations in psychological research}},
    url = {http://dx.doi.org/10.1037/a0019623},
    volume = {15},
    year = {2010}
}

@article{20839,
    abstract = {{This article explores some of the challenges that arise when trying to implement propensity score strategies to answer a causal question using data with a large number of covariates. We discuss choices in propensity score estimation strategies, matching and weighting implementation strategies, balance diagnostics, and final analysis models. We demonstrate the wide range of estimates that can result from different combinations of these choices. Finally, an alternative estimation strategy is presented that may have benefits in terms of simplicity and reliability. These issues are explored in the context of an empirical example that uses data from the Early Childhood Longitudinal Study, Kindergarten Cohort to investigate the potential effect of grade retention after the 1st-grade year on subsequent cognitive outcomes. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Hill, J. and Weiss, C. and Zhai, F.},
    citeulike-article-id = {13872685},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/00273171.2011.570161},
    doi = {10.1080/00273171.2011.570161},
    isbn = {0027-3171; 1532-7906},
    journal = {Multivariate Behavioral Research},
    keywords = {exportrecords, propensity-scores},
    number = {3},
    pages = {477--513},
    posted-at = {2015-12-09 01:09:12},
    priority = {3},
    title = {{Challenges with propensity score strategies in a high-dimensional setting and a potential alternative}},
    url = {http://dx.doi.org/10.1080/00273171.2011.570161},
    volume = {46},
    year = {2011}
}

@article{20878,
    abstract = {{In observational studies for causal effects, treatments are assigned to experimental units without the benefits of randomization. As a result, there is the potential for bias in the estimation of the treatment effect. Two methods for estimating the causal effect consistently are Inverse Probability of Treatment Weighting (IPTW) and the Propensity Score (PS). We demonstrate that in many simple cases, the PS method routinely produces estimators with lower Mean-Square Error (MSE). In the longitudinal setting, estimation of the causal effect of a time-dependent exposure in the presence of time-dependent covariates that are themselves affected by previous treatment also requires adjustment approaches. We describe an alternative approach to the classical binary treatment propensity score termed the Generalized Propensity Score (GPS). Previously, the GPS has mainly been applied in a single interval setting; we use an extension of the GPS approach to the longitudinal setting. We compare the strengths and weaknesses of IPTW and GPS for causal inference in three simulation studies and two real data sets. Again, in simulation, the GPS appears to produce estimators with lower MSE. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Ertefaie, A. and Stephens, D. A.},
    citeulike-article-id = {13872673},
    citeulike-linkout-0 = {http://dx.doi.org/10.2202/1557-4679.1198},
    doi = {10.2202/1557-4679.1198},
    issn = {1557-4679},
    journal = {International Journal of Biostatistics},
    keywords = {bias---selection, exportrecords, propensity-scores},
    number = {2},
    pages = {Article 14+},
    posted-at = {2015-12-09 01:09:11},
    priority = {3},
    title = {{Comparing approaches to causal inference for longitudinal data: Inverse probability weighting versus propensity scores.}},
    url = {http://dx.doi.org/10.2202/1557-4679.1198},
    volume = {6},
    year = {2010}
}

@article{20862,
    abstract = {{Introduction: Despite efforts to control for confounding variables using stringent sampling plans, selection bias typically exists in observational studies, resulting in unbalanced comparison groups. Ignoring selection bias can result in unreliable or misleading estimates of the causal effect. Methods: Generalized boosted models were used to estimate propensity scores from 42 confounding variables for a sample of 361 neonates. Using emergent neonatal attention and orientation skills as an example developmental outcome, we examined the impact of tobacco exposure with and without accounting for selection bias. Weight at birth, an outcome related to tobacco exposure, also was used to examine the functionality of the propensity score approach. Results: Without inclusion of propensity scores, tobacco-exposed neonates did not differ from their nonexposed peers in attention skills over the first month or in weight at birth. When the propensity score was included as a covariate, exposed infants had marginally lower attention and a slower linear change rate at 4 weeks, with greater quadratic deceleration over the first month. Similarly, exposure-related differences in birth weight emerged when propensity scores were included as a covariate. Conclusions: The propensity score method captured the selection bias intrinsic to this observational study of prenatal tobacco exposure. Selection bias obscured the deleterious impact of tobacco exposure on the development of neonatal attention. The illustrated analytic strategy offers an example to better characterize the impact of prenatal tobacco exposure on important developmental outcomes by directly modeling and statistically accounting for the selection bias from the sampling process. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Fang, H. and Johnson, C. and Chevalier, N. and Stopp, C. and Wiebe, S. and Wakschlag, L. S. and Espy, K. A.},
    citeulike-article-id = {13872672},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/ntr/ntq170},
    doi = {10.1093/ntr/ntq170},
    isbn = {1462-2203; 1469-994X},
    journal = {Nicotine \& Tobacco Research},
    keywords = {exportrecords, propensity-scores},
    number = {12},
    pages = {1211--1219},
    posted-at = {2015-12-09 01:09:11},
    priority = {3},
    title = {{Using propensity score modeling to minimize the influence of confounding risks related to prenatal tobacco exposure.}},
    url = {http://dx.doi.org/10.1093/ntr/ntq170},
    volume = {12},
    year = {2010}
}

@article{20855,
    abstract = {{Educational researchers frequently study the impact of treatments or interventions on educational outcomes. However, when observational or quasiexperimental data are used for such investigations, selection bias can adversely impact researchers' abilities to make causal inferences about treatment effects. One way to deal with selection bias is to use propensity score methods. The authors introduce educational researchers to the general principles underlying propensity score methods, describe 2 practical applications of these methods, and discuss their limitations. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Graham, S. E. and Kurlaender, M.},
    citeulike-article-id = {13872671},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/00220671.2010.486082},
    doi = {10.1080/00220671.2010.486082},
    isbn = {0022-0671; 1940-0675},
    journal = {Journal of Educational Research},
    keywords = {bias---selection, exportrecords, propensity-scores},
    number = {5},
    pages = {340--353},
    posted-at = {2015-12-09 01:09:11},
    priority = {3},
    title = {{Using propensity scores in educational research: General principles and practical applications}},
    url = {http://dx.doi.org/10.1080/00220671.2010.486082},
    volume = {104},
    year = {2011}
}

@phdthesis{20846,
    abstract = {{This research investigated a causal estimate of the impact of zero tolerance policy adoption on individual students' cognitive outcomes by modeling multilevel propensity score estimates within a potential outcomes framework. This estimate was obtained using a large, nationally representative non-experimental sample. Proponents of zero tolerance policy assert that the mandatory expulsion of students for listed offenses leads to a learning environment that supports cognitive growth for the remaining students. Results indicated that zero tolerance policies do not have the desired positive effect on not-at-risk students' cognitive outcomes. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Eckardt, P. A.},
    citeulike-article-id = {13872670},
    isbn = {978-1-124-28943-4;},
    keywords = {exportrecords, propensity-scores},
    location = {New York, NY},
    pages = {1--168},
    posted-at = {2015-12-09 01:09:11},
    priority = {3},
    school = {City University of New York},
    title = {{The application of propensity score estimates in hierarchical linear models for causal inference}},
    year = {2010}
}

@article{20831,
    abstract = {{This methodological brief introduces the readers to the propensity score matching method, which can be used for enhancing the validity of causal inferences in research situations involving nonexperimental design or observational research, or in situations where the benefits of an experimental design are not fully realized because of reasons beyond the researcher's control (e.g., attrition of participants). This brief discusses the rationale of propensity score matching, the major implementation steps and considerations, and illustrates the procedures with a data example. Some limitations and implementation challenges are also discussed. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Fan, X. and Nowell, D. L.},
    citeulike-article-id = {13872669},
    citeulike-linkout-0 = {http://dx.doi.org/10.1177/0016986210390635},
    doi = {10.1177/0016986210390635},
    isbn = {0016-9862; 1934-9041},
    journal = {Gifted Child Quarterly},
    keywords = {bias---selection, exportrecords, propensity-scores},
    number = {1},
    pages = {74--79},
    posted-at = {2015-12-09 01:09:11},
    priority = {3},
    title = {{Using propensity score matching in educational research}},
    url = {http://dx.doi.org/10.1177/0016986210390635},
    volume = {55},
    year = {2011}
}

@article{23697,
    abstract = {{Propensity scores are widely used in cohort studies to improve performance of regression models when considering large numbers of covariates. Another type of summary score, the disease risk score (DRS), which estimates disease probability conditional on nonexposure, has also been suggested. However, little is known about how it compares with propensity scores. Monte Carlo simulations were conducted comparing regression models using the DRS and the propensity score with models that directly adjust for all of the individual covariates. The DRS was calculated in 2 ways: from the unexposed population and from the full cohort. Compared with traditional multivariable outcome regression models, all 3 summary scores had comparable performance for moderate correlation between exposure and covariates and, for strong correlation, the full-cohort DRS and propensity score had comparable performance. When traditional methods had model misspecification, propensity scores and the full-cohort DRS had superior performance. All 4 models were affected by the number of events per covariate, with propensity scores and traditional multivariable outcome regression least affected. These data suggest that, for cohort studies for which covariates are not highly correlated with exposure, the DRS, particularly that calculated from the full cohort, is a useful tool.}},
    author = {Arbogast, P. G. and Ray, W. A.},
    citeulike-article-id = {13872662},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/aje/kwr143},
    doi = {10.1093/aje/kwr143},
    isbn = {1476-6256; 0002-9262},
    journal = {American Journal of Epidemiology},
    keywords = {disease-risk-scores, exportrecords, propensity-scores},
    number = {5},
    pages = {613--620},
    posted-at = {2015-12-09 01:09:11},
    priority = {3},
    title = {{Performance of disease risk scores, propensity scores, and traditional multivariable outcome regression in the presence of multiple confounders}},
    url = {http://dx.doi.org/10.1093/aje/kwr143},
    volume = {174},
    year = {2011}
}

@article{20892,
    abstract = {{This article presents propensity score matching as a method to implement randomized conditions to analyze service effects using nonexperimental data. Most social work research is challenged to implement randomized clinical trials, whereas administrative and survey data are often available and can provide valuable information about services received under naturalistic conditions. This article discusses the assumptions of this method and the analytic steps involved; and it presents three examples of the approach, demonstrating that it is possible to approximate the conditions of a randomized controlled trial, and when selection bias is reduced, investigators can have more confidence in their findings. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Barth, R. P. and Guo, S. and McCrae, J. S.},
    citeulike-article-id = {13872650},
    citeulike-linkout-0 = {http://dx.doi.org/10.1177/1049731507307791},
    doi = {10.1177/1049731507307791},
    isbn = {U13  - sent},
    journal = {Research on Social Work Practice},
    keywords = {exportrecords, propensity-scores},
    number = {3},
    pages = {212--222},
    posted-at = {2015-12-09 01:09:11},
    priority = {3},
    title = {{Propensity score matching strategies for evaluating the success of child and family service programs}},
    url = {http://dx.doi.org/10.1177/1049731507307791},
    volume = {18},
    year = {2008}
}

@article{20856,
    abstract = {{As can be seen from the recent Special Issue of MBR on propensity score analysis (PSA) methods, the use of PSA has gained increasing popularity for estimating causal effects in observational studies. However, PSA use with multilevel or clustered data has been limited, and to date there seems to have been no development of specialized graphics for such data. This paper introduces the multilevelPSA (http://multilevelPSA.r-forge.r-project.org) package for R that provides cluster-based functions for estimating propensity scores as well as graphics to exhibit results for multilevel data. This work extends to the multilevel case the framework for visualizing propensity score analysis introduced by Helmreich and Pruzek (2009). International data from the Programme for International Student Assessment (Organization for Economic Co-operation and Development, 2009) are comprehensively examined to compare private with public schools on reading, mathematics, and science outcomes after adjusting for covariate differences in the multilevel context. Particularly for analyses of large data sets, focusing on statistical significance is limiting. As can readily be seen, overall results favor "private" over "public" schools, at least for end of secondary school math achievement. But the graphics provide a more nuanced understanding of the nature and magnitude of adjusted differences for countries. Furthermore, the graphics are readily interpreted by a nontechnical audience. Broadly speaking, it is seen that modern graphics can enhance and extend conventional numerical summaries by focusing on details of what data have to say for multilevel comparisons of many countries based on propensity score methods. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Bryer, J. M. and Pruzek, R. M.},
    citeulike-article-id = {13872649},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/00273171.2011.636693},
    doi = {10.1080/00273171.2011.636693},
    isbn = {0027-3171; 1532-7906},
    journal = {Multivariate Behavioral Research},
    keywords = {exportrecords, propensity-scores},
    number = {6},
    pages = {1010--1011},
    posted-at = {2015-12-09 01:09:11},
    priority = {3},
    title = {{Abstract: An international comparison of private and public schools using multilevel propensity score methods and graphics}},
    url = {http://dx.doi.org/10.1080/00273171.2011.636693},
    volume = {46},
    year = {2011}
}

@phdthesis{20850,
    abstract = {{Previous research implementing stratification on the propensity score has generally relied on using five strata, based on prior theoretical groundwork and minimal empirical evidence as to the suitability of quintiles to adequately reduce bias in all cases and across all sample sizes. This study investigates bias reduction across varying number of strata and sample sizes via a large-scale simulation to determine the adequacy of quintiles for bias reduction under all conditions. Sample sizes ranged from 100 to 50,000 and strata from 3 to 20. Both the percentage of bias reduction and the standardized selection bias were examined. The results show that while the particular covariates in the simulation met certain criteria with five strata that greater bias reduction could be achieved by increasing the number of strata, especially with larger sample sizes. Simulation code written in R is included. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Akers, A.},
    booktitle = {Dissertation Abstracts International},
    citeulike-article-id = {13872648},
    isbn = {0419-4209; 978-1-124-15381-0;},
    keywords = {bias---selection, exportrecords, propensity-scores},
    location = {Denton, TX},
    posted-at = {2015-12-09 01:09:11},
    priority = {3},
    school = {University of North Texas},
    title = {{Determination of the optimal number of strata for bias reduction in propensity score matching}},
    year = {2010}
}

@article{20847,
    abstract = {{The central role of the propensity score analysis (PSA) in observational studies is for causal inference; as such, PSA is often used for making causal claims in research articles. However, there are still some issues for researchers to consider when making claims of causality using PSA results. This summary first briefly reviews PSA, followed by discussions of its effectiveness and limitations. Finally, a guideline of how to address these concerns is also provided for researchers to make appropriate causal claims using PSA results in their research articles. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Bai, H.},
    citeulike-article-id = {13872647},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s10648-011-9164-9},
    doi = {10.1007/s10648-011-9164-9},
    isbn = {1040-726X; 1573-336X},
    journal = {Educational Psychology Review},
    keywords = {exportrecords, propensity-scores},
    number = {2},
    pages = {273--278},
    posted-at = {2015-12-09 01:09:11},
    priority = {3},
    title = {{Using propensity score analysis for making causal claims in research articles}},
    url = {http://dx.doi.org/10.1007/s10648-011-9164-9},
    volume = {23},
    year = {2011}
}

@article{20792,
    abstract = {{Community engagement is central to strategies to promote health and well-being and reduce health inequalities in many countries, particularly interventions which focus on improving health in disadvantaged populations. Despite the widespread use of community engagement approaches, however, there have been relatively few attempts to review the evidence on the impact that participation has on the lives of individuals involved. Drawing on a wider review of evidence carried out on behalf of the National Institute for Health and Clinical Excellence (NICE), this article reports on a rapid review of evidence of the effectiveness of initiatives which seek to engage communities in action to address the wider social determinants of health, to explore individuals' subjective experiences of engagement. The rapid review process was guided by NICE's public health methods manual, adapted to suit the diversity of the evidence. A total of 22 studies were identified containing empirical data on subjective experiences of community engagement for individuals. The findings of the rapid review suggest that the majority of 'engaged' individuals perceived benefits for their physical and psychological health, self-confidence, self-esteem, sense of personal empowerment and social relationships. Set against these positive outcomes, however, the evidence suggests that there are unintended negative consequences of community engagement for some individuals, which may pose a risk to well-being. These consequences included exhaustion and stress, as involvement drained participants' energy levels as well as time and financial resources. The physical demands of engagement were reported as particularly onerous by individuals with disabilities. Consultation fatigue and disappointment were negative consequences for some participants who had experienced successive waves of engagement initiatives. For some individuals, engagement may involve a process of negotiation between gains and losses. This complexity needs to be more widely recognised among those who seek to engage communities. 2010 Blackwell Publishing Ltd.}},
    author = {Attree, P. and French, B. and Milton, B. and Povall, S. and Whitehead, M. and Popay, J.},
    citeulike-article-id = {13872645},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.1365-2524.2010.00976.x},
    doi = {10.1111/j.1365-2524.2010.00976.x},
    isbn = {0966-0410; 1365-2524},
    journal = {Health \& Social Care in the Community},
    keywords = {exportrecords, propensity-scores, stakeholder-engagement, systematic-reviews---limited-time-rapid},
    number = {3},
    pages = {250--260},
    posted-at = {2015-12-09 01:09:11},
    priority = {3},
    title = {{The experience of community engagement for individuals: a rapid review of evidence}},
    url = {http://dx.doi.org/10.1111/j.1365-2524.2010.00976.x},
    volume = {19},
    year = {2011}
}

@article{24809,
    abstract = {{Standardized means, commonly used in observational studies in epidemiology to adjust for potential confounders, are equal to inverse probability weighted means with inverse weights equal to the empirical propensity scores. More refined standardization corresponds with empirical propensity scores computed under more flexible models. Unnecessary standardization induces efficiency loss. However, according to the theory of inverse probability weighted estimation, propensity scores estimated under more flexible models induce improvement in the precision of inverse probability weighted means. This apparent contradiction is clarified by explicitly stating the assumptions under which the improvement in precision is attained.}},
    author = {Rotnitzky, A. and Li, L. and Li, X.},
    citeulike-article-id = {13872631},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/biomet/asq049},
    doi = {10.1093/biomet/asq049},
    issn = {0006-3444},
    journal = {Biometrika},
    keywords = {bias---over-adjustment, exportrecords, propensity-scores},
    number = {4},
    pages = {997--1001},
    posted-at = {2015-12-09 01:09:11},
    priority = {3},
    title = {{A note on overadjustment in inverse probability weighted estimation}},
    url = {http://dx.doi.org/10.1093/biomet/asq049},
    volume = {97},
    year = {2010}
}

@article{25523,
    abstract = {{In randomized controlled trials (RCTs), treatment assignment is unconfounded with baseline covariates, allowing outcomes to be directly compared between treatment arms. When outcomes are binary, the effect of treatment can be summarized using relative risks, absolute risk reductions and the number needed to treat (NNT). When outcomes are time-to-event in nature, the effect of treatment on the absolute reduction of the risk of an event occurring within a specified duration of follow-up and the associated NNT can be estimated. In observational studies of the effect of treatments on health outcomes, treatment is frequently confounded with baseline covariates. Regression adjustment is commonly used to estimate the adjusted effect of treatment on outcomes. We highlight several limitations of measures of treatment effect that are directly obtained from regression models. We illustrate how both regression-based approaches and propensity-score based approaches allow one to estimate the same measures of treatment effect as those that are commonly reported in RCTs. The CONSORT statement recommends that both relative and absolute measures of treatment effects be reported for RCTs with dichotomous outcomes. The methods described in this paper will allow for similar reporting in observational studies.}},
    author = {Austin, P. C. and Laupacis, A.},
    citeulike-article-id = {13872591},
    citeulike-linkout-0 = {http://dx.doi.org/10.2202/1557-4679.1285},
    doi = {10.2202/1557-4679.1285},
    issn = {1557-4679},
    journal = {International Journal of Biostatistics},
    keywords = {effect-measures, exportrecords, observational-study---methods, propensity-scores},
    number = {1},
    pages = {6+},
    posted-at = {2015-12-09 01:09:10},
    priority = {3},
    title = {{A tutorial on methods to estimating clinically and policy-meaningful measures of treatment effects in prospective observational studies: a review}},
    url = {http://dx.doi.org/10.2202/1557-4679.1285},
    volume = {7},
    year = {2011}
}

@article{18169,
    abstract = {{The applied literature on propensity scores has often cited the c-statistic as a measure of the ability of the propensity score to control confounding. However, a high c-statistic in the propensity model is neither necessary nor sufficient for control of confounding. Moreover, use of the c-statistic as a guide in constructing propensity scores may result in less overlap in propensity scores between treated and untreated subjects; this may require the analyst to restrict populations for inference. Such restrictions may reduce precision of estimates and change the population to which the estimate applies. Variable selection based on prior subject matter knowledge, empirical observation, and sensitivity analysis is preferable and avoids many of these problems.}},
    author = {Westreich, D. and Cole, S. R. and Funk, M. J. and Brookhart, M. A. and St\"{u}rmer, T.},
    citeulike-article-id = {13872487},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.2074},
    doi = {10.1002/pds.2074},
    isbn = {1053-8569; 1099-1557},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {exportrecords, propensity-scores, statistics},
    number = {3},
    pages = {317--320},
    posted-at = {2015-12-09 01:09:07},
    priority = {3},
    title = {{The role of the c-statistic in variable selection for propensity score models}},
    url = {http://dx.doi.org/10.1002/pds.2074},
    volume = {20},
    year = {2011}
}

@article{18134,
    abstract = {{PURPOSE: To investigate whether propensity score (ps) methods could reasonably be applied to estimate the treatment effect on mortality, based on a comparatively small sample of patients with severe cutaneous adverse reactions (SCAR) and who come from different countries where physicians prefer different treatment schemes. METHODS: Ps methods were applied to cope with confounding due to non-randomized treatment assignment for the analysis of the treatment data obtained in the case-control study EuroSCAR. For the study's purpose, the analysis focused on the comparison of the treatments: corticosteroids (STER) and supportive care only (SUPP). RESULTS: 206 French and German patients were treated either with SUPP or STER. Imbalances between treatment groups as well as between the countries were recognized. Concerning the balance between the treatment groups no ps model for the full cohort was satisfying. In addition, the inclusion of a variable for patient's country led to a separation of the patients by country. Thus, we developed ps models for each country separately and estimated the treatment effects (France: odds ratio (OR) 0.52, 95\% confidence interval (CI) 0.09-3.10, Germany: OR 0.23, CI 0.06-0.92, Overall: OR 0.33 CI 0.11-1.04). CONCLUSIONS: The application of the ps methods was successful and provided valuable information. We could confirm the findings of the original analysis which was based on standard logistic regression, especially concerning the necessity of a country-specific analysis. The observed country differences in the estimated treatment effects were less pronounced and thus seemed to be more reasonable than those of the past analysis.}},
    author = {Sekula, P. and Caputo, A. and Dunant, A. and Roujeau, J. C. and Mockenhaupt, M. and Sidoroff, A. and Schumacher, M.},
    citeulike-article-id = {13872448},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.1863},
    doi = {10.1002/pds.1863},
    isbn = {1053-8569 1099-1557},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {exportrecords, propensity-scores},
    number = {1},
    pages = {10--8},
    posted-at = {2015-12-09 01:09:07},
    priority = {3},
    title = {{An application of propensity score methods to estimate the treatment effect of corticosteroids in patients with severe cutaneous adverse reactions}},
    url = {http://dx.doi.org/10.1002/pds.1863},
    volume = {19},
    year = {2010}
}

@article{18068,
    abstract = {{Propensity scores have been used widely as a bias reduction method to estimate the treatment effect in nonrandomized studies. Since many covariates are generally included in the model for estimating the propensity scores, the proportion of subjects with at least one missing covariate could be large. While many methods have been proposed for propensity score-based estimation in the presence of missing covariates, little has been published comparing the performance of these methods. In this article we propose a novel method called multiple imputation missingness pattern (MIMP) and compare it with the naive estimator (ignoring propensity score) and three commonly used methods of handling missing covariates in propensity score-based estimation (separate estimation of propensity scores within each pattern of missing data, multiple imputation and discarding missing data) under different mechanisms of missing data and degree of correlation among covariates. Simulation shows that all adjusted estimators are much less biased than the naive estimator. Under certain conditions MIMP provides benefits (smaller bias and mean-squared error) compared with existing alternatives. Copyright {\copyright} 2009 John Wiley \& Sons, Ltd.}},
    author = {Qu, Y. and Lipkovich, I.},
    citeulike-article-id = {13872401},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.3549},
    doi = {10.1002/sim.3549},
    issn = {1097-0258},
    journal = {Statistics in Medicine},
    keywords = {data---missing, exportrecords, propensity-scores},
    number = {9},
    pages = {1402--1414},
    posted-at = {2015-12-09 01:09:06},
    priority = {3},
    title = {{Propensity score estimation with missing values using a multiple imputation missingness pattern (MIMP) approach}},
    url = {http://dx.doi.org/10.1002/sim.3549},
    volume = {28},
    year = {2009}
}

@article{18212,
    abstract = {{In a longitudinal study of dose-response, it is often necessary to adjust for confounding or non-compliance, which may otherwise compromise the estimation of the true effect of a treatment. Using an approach based on the generalised propensity score (GPS) - a generalisation of the classical, binary treatment propensity score - it is possible to construct a balancing score that provides an estimation procedure for the true (unconfounded) direct effect of dose on response. Previously, the GPS has been applied only in a single interval setting; in this article, we extend the GPS methodology to the longitudinal setting to estimate the direct effect of a continuous dose on a longitudinal response. The methodology is applied to two simulated examples, and a real longitudinal dose-response investigation, the Monitored Occlusion Treatment of Amblyopia Study (MOTAS). In the treatment of childhood amblyopia, a common ophthalmological condition, occlusion therapy (patching) was for many decades the standard medical treatment, despite the fact that its efficacy was not quantified. MOTAS was revolutionary, as it was the first study to obtain precise measurements of the amount of occlusion each study participant received over the course of the study.}},
    author = {Moodie, E. E. M. and Stephens, D. A.},
    citeulike-article-id = {13872376},
    citeulike-linkout-0 = {http://dx.doi.org/10.1177/0962280209340213},
    doi = {10.1177/0962280209340213},
    issn = {0962-2802},
    journal = {Statistical Methods in Medical Research},
    keywords = {exportrecords, propensity-scores, statistics},
    number = {2},
    pages = {149--166},
    posted-at = {2015-12-09 01:09:05},
    priority = {3},
    title = {{Estimation of dose-response functions for longitudinal data using the generalised propensity score}},
    url = {http://dx.doi.org/10.1177/0962280209340213},
    volume = {21},
    year = {2010}
}

@article{18160,
    abstract = {{In many observational studies, analysts estimate causal effects using propensity scores, e.g. by matching, sub-classifying, or inverse probability weighting based on the scores. Estimation of propensity scores is complicated when some values of the covariates are missing. Analysts can use multiple imputation to create completed data sets from which propensity scores can be estimated. We propose a general location mixture model for imputations that assumes that the control units are a latent mixture of (i) units whose covariates are drawn from the same distributions as the treated units' covariates and (ii) units whose covariates are drawn from different distributions. This formulation reduces the influence of control units outside the treated units' region of the covariate space on the estimation of parameters in the imputation model, which can result in more plausible imputations. In turn, this can result in more reliable estimates of propensity scores and better balance in the true covariate distributions when matching or sub-classifying. We illustrate the benefits of the latent class modeling approach with simulations and with an observational study of the effect of breast feeding on children's cognitive abilities. Copyright (c) 2010 John Wiley \& Sons, Ltd.}},
    author = {Mitra, R. and Reiter, J. P.},
    citeulike-article-id = {13872370},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4124},
    doi = {10.1002/sim.4124},
    isbn = {1097-0258; 0277-6715},
    journal = {Statistics in Medicine},
    keywords = {data---missing, exportrecords, propensity-scores, statistics},
    number = {6},
    pages = {627--641},
    posted-at = {2015-12-09 01:09:05},
    priority = {3},
    title = {{Estimating propensity scores with missing covariate data using general location mixture models}},
    url = {http://dx.doi.org/10.1002/sim.4124},
    volume = {30},
    year = {2011}
}

@article{18013,
    abstract = {{In the analysis of observational data, stratifying patients on the estimated propensity scores reduces confounding from measured variables. Confidence intervals for the treatment effect are typically calculated without acknowledging uncertainty in the estimated propensity scores, and intuitively this may yield inferences, which are falsely precise. In this paper, we describe a Bayesian method that models the propensity score as a latent variable. We consider observational studies with a dichotomous treatment, dichotomous outcome, and measured confounders where the log odds ratio is the measure of effect. Markov chain Monte Carlo is used for posterior simulation. We study the impact of modelling uncertainty in the propensity scores in a case study investigating the effect of statin therapy on mortality in Ontario patients discharged from hospital following acute myocardial infarction. Our analysis reveals that the Bayesian credible interval for the treatment effect is 10 per cent wider compared with a conventional propensity score analysis. Using simulations, we show that when the association between treatment and confounders is weak, then this increases uncertainty in the estimated propensity scores. Bayesian interval estimates for the treatment effect are longer on average, though there is little improvement in coverage probability. A novel feature of the proposed method is that it fits models for the treatment and outcome simultaneously rather than one at a time. The method uses the outcome variable to inform the fit of the propensity model. We explore the performance of the estimated propensity scores using cross-validation. Copyright (c) 2008 John Wiley \& Sons, Ltd.}},
    author = {McCandless, L. C. and Gustafson, P. and Austin, P. C.},
    citeulike-article-id = {13872355},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.3460},
    doi = {10.1002/sim.3460},
    issn = {0277-6715},
    journal = {Statistics in Medicine},
    keywords = {exportrecords, observational-study---general, propensity-scores, statistics},
    number = {1},
    pages = {94--112},
    posted-at = {2015-12-09 01:09:05},
    priority = {3},
    title = {{Bayesian propensity score analysis for observational data}},
    url = {http://dx.doi.org/10.1002/sim.3460},
    volume = {28},
    year = {2009}
}

@article{18333,
    abstract = {{The authors developed a sensitivity analysis method to address the issue of uncontrolled confounding in observational studies. In this method, the authors use a 1-dimensional function of the propensity score, which they refer to as the sensitivity function (SF), to quantify the hidden bias due to unmeasured confounders. The propensity score is defined as the conditional probability of being treated given the measured covariates. Then the authors construct SF-corrected inverse-probability-weighted estimators to draw inference on the causal treatment effect. This approach allows analysts to conduct a comprehensive sensitivity analysis in a straightforward manner by varying sensitivity assumptions on both the functional form and the coefficients in the 1-dimensional SF. Furthermore, 1-dimensional continuous functions can be well approximated by low-order polynomial structures (e.g., linear, quadratic). Therefore, even if the imposed SF is practically certain to be incorrect, one can still hope to obtain valuable information on treatment effects by conducting a comprehensive sensitivity analysis using polynomial SFs with varying orders and coefficients. The authors demonstrate the new method by implementing it in an asthma study which evaluates the effect of clinician prescription patterns regarding inhaled corticosteroids for children with persistent asthma on selected clinical outcomes.}},
    author = {Li, L. and Shen, C. and Wu, A. C. and Li, X.},
    citeulike-article-id = {13872339},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/aje/kwr096},
    doi = {10.1093/aje/kwr096},
    isbn = {1476-6256; 0002-9262},
    journal = {American Journal of Epidemiology},
    keywords = {bias---selection, exportrecords, propensity-scores, sensitivity-analysis},
    number = {3},
    pages = {345--353},
    posted-at = {2015-12-09 01:09:04},
    priority = {3},
    title = {{Propensity Score-based Sensitivity Analysis Method for Uncontrolled Confounding}},
    url = {http://dx.doi.org/10.1093/aje/kwr096},
    volume = {174},
    year = {2011}
}

@article{18213,
    abstract = {{The authors review experimental and nonexperimental causal inference methods, focusing on assumptions for the validity of instrumental variables and propensity score (PS) methods. They provide guidance in four areas for the analysis and reporting of PS methods in medical research and selectively evaluate mainstream medical journal articles from 2000 to 2005 in the four areas, namely, examination of balance, overlapping support description, use of estimated PS for evaluation of treatment effect, and sensitivity analyses. In spite of the many pitfalls, when appropriately evaluated and applied, PS methods can be powerful tools in assessing average treatment effects in observational studies. Appropriate PS applications can create experimental conditions using observational data when randomized controlled trials are not feasible and, thus, lead researchers to an efficient estimator of the average treatment effect.}},
    author = {Luo, Z. and Gardiner, J. C. and Bradley, C. J.},
    citeulike-article-id = {13872325},
    citeulike-linkout-0 = {http://dx.doi.org/10.1177/1077558710361486},
    doi = {10.1177/1077558710361486},
    isbn = {1077-5587; 1552-6801},
    journal = {Medical Care Research and Review},
    keywords = {exportrecords, propensity-scores},
    number = {5},
    pages = {528--554},
    posted-at = {2015-12-09 01:09:04},
    priority = {3},
    title = {{Applying propensity score methods in medical research: pitfalls and prospects}},
    url = {http://dx.doi.org/10.1177/1077558710361486},
    volume = {67},
    year = {2010}
}

@article{18347,
    abstract = {{Doubly robust estimation combines a form of outcome regression with a model for the exposure (i.e., the propensity score) to estimate the causal effect of an exposure on an outcome. When used individually to estimate a causal effect, both outcome regression and propensity score methods are unbiased only if the statistical model is correctly specified. The doubly robust estimator combines these 2 approaches such that only 1 of the 2 models need be correctly specified to obtain an unbiased effect estimator. In this introduction to doubly robust estimators, the authors present a conceptual overview of doubly robust estimation, a simple worked example, results from a simulation study examining performance of estimated and bootstrapped standard errors, and a discussion of the potential advantages and limitations of this method. The supplementary material for this paper, which is posted on the Journal's Web site (http://aje.oupjournals.org/), includes a demonstration of the doubly robust property (Web Appendix 1) and a description of a SAS macro (SAS Institute, Inc., Cary, North Carolina) for doubly robust estimation, available for download at http://www.unc.edu/ approximately mfunk/dr/.}},
    author = {Funk, M. J. and Westreich, D. and Wiesen, C. and St\"{u}rmer, T. and Brookhart, M. A. and Davidian, M.},
    citeulike-article-id = {13872296},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/aje/kwq439},
    doi = {10.1093/aje/kwq439},
    isbn = {1476-6256; 0002-9262},
    journal = {American Journal of Epidemiology},
    keywords = {exportrecords, propensity-scores, statistics},
    number = {7},
    pages = {761--767},
    posted-at = {2015-12-09 01:09:03},
    priority = {3},
    title = {{Doubly robust estimation of causal effects}},
    url = {http://dx.doi.org/10.1093/aje/kwq439},
    volume = {173},
    year = {2011}
}

@article{18291,
    abstract = {{The assessment of treatment effects from observational studies may be biased with patients not randomly allocated to the experimental or control group. One way to overcome this conceptual shortcoming in the design of such studies is the use of propensity scores to adjust for differences of the characteristics between patients treated with experimental and control interventions. The propensity score is defined as the probability that a patient received the experimental intervention conditional on pre-treatment characteristics at baseline. Here, we review how propensity scores are estimated and how they can help in adjusting the treatment effect for baseline imbalances. We further discuss how to evaluate adequate overlap of baseline characteristics between patient groups, provide guidelines for variable selection and model building in modelling the propensity score, and review different methods of propensity score adjustments. We conclude that propensity analyses may help in evaluating the comparability of patients in observational studies, and may account for more potential confounding factors than conventional covariate adjustment approaches. However, bias due to unmeasured confounding cannot be corrected for.}},
    author = {Heinze, G. and J\"{u}ni, P.},
    citeulike-article-id = {13872293},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/eurheartj/ehr031},
    doi = {10.1093/eurheartj/ehr031},
    isbn = {1522-9645; 0195-668X},
    journal = {European Heart Journal},
    keywords = {bias---selection, exportrecords, propensity-scores},
    number = {14},
    pages = {1704--1708},
    posted-at = {2015-12-09 01:09:03},
    priority = {3},
    title = {{An overview of the objectives of and the approaches to propensity score analyses}},
    url = {http://dx.doi.org/10.1093/eurheartj/ehr031},
    volume = {32},
    year = {2011}
}

@article{16886,
    abstract = {{Propensity score methods are widely used to estimate treatment or exposure effects in observational studies. In studies with binary response the effect can be described as an odds ratio, and the Mantel-Haenszel estimator is traditionally used for stratified data. Although propensity score methods are designed for marginal treatment effects, it has been shown that the Mantel-Haenszel estimator stratified for propensity score is a questionable estimator for the marginal odds ratio, which describes the change in odds of response if everybody versus nobody were treated.We studied recently proposed alternative estimators for the marginal odds ratio, one stratified for propensity score, the other derived from logistic regression. Additionally, we adapted the methodology of the logistic regression based estimator for the derivation of a marginal odds ratio estimator to covariate adjustment by the propensity score. We also derived corresponding variance estimators using the Delta-method.The estimators were illustrated and compared to the inverse probability weighted estimator and the stratified Mantel-Haenszel estimator in a study dealing with respiratory tract infections in children in Germany. Furthermore, simulation studies that were carried out to investigate relative bias, variance and coverage probability showed reasonable performance of marginal odds ratio estimators if response rates or regression based approaches were used. Their variances were accurately estimated. In contrast, the stratified Mantel-Haenszel estimator was substantially biased in some situations due to problems of non-collapsibility and thus it is generally inappropriate for a reliable estimation of the marginal odds ratio.}},
    author = {Stampf, S. and Graf, E. and Schmoor, C. and Schumacher, M.},
    citeulike-article-id = {13872195},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.3811},
    doi = {10.1002/sim.3811},
    isbn = {1097-0258 0277-6715},
    journal = {Statistics in Medicine},
    keywords = {exportrecords, propensity-scores},
    number = {8-Jul},
    pages = {760--9},
    posted-at = {2015-12-09 01:09:01},
    priority = {3},
    title = {{Estimators and confidence intervals for the marginal odds ratio using logistic regression and propensity score stratification}},
    url = {http://dx.doi.org/10.1002/sim.3811},
    volume = {29},
    year = {2010}
}

@article{16493,
    abstract = {{BACKGROUND: The erythropoiesis-stimulating agents (ESAs) epoetin alfa (EA) and darbepoetin alfa (DA) have comparable efficacy in treating chemotherapy-induced anaemia (CIA). Therapy choice depends on many factors, including cost. Previous estimates of ESA cost differences have been derived from claims data. These data lack clinical variables, such as baseline haemoglobin (Hb) level, which are likely to influence choice of ESA, dosing and costs. We estimated cost differences between DA and EA in patients with cancer receiving chemotherapy, using a propensity-score matched analysis of baseline patient characteristics with and without Hb values to assess the effect of this clinical variable on ESA cost estimates. METHODS: Data were extracted from electronic medical records in two US databases between January 2004 and December 2006. The study sample included 6743 patients receiving chemotherapy, with one or more visits during the study period, who received an ESA during a chemotherapy episode. Episodes of chemotherapy care were constructed using a 90-day gap in administration to identify the start and end. Patients receiving both DA and EA during their initial chemotherapy episode or with missing data were excluded, representing 42\% of patients with CIA receiving an ESA. Drug costs were calculated from the cumulative dose multiplied by 106\% of the average sales price (ASP) for DA or EA. Two propensity-score matches were conducted: first using variables available in administrative billing claims systems, then adding the baseline Hb test result. Regression-adjusted cost differences were estimated with and without baseline Hb, using generalized linear models. RESULTS: Using baseline Hb levels resulted in a better match of the baseline characteristics for the EA and DA treatment groups than the original sample or the matched sample without Hb variables. Mean ESA costs (year 2007 values) for the original sample were \$US4171 for EA and \$US3811 for DA (mean difference \$US360; p < 0.001, standard error [SE] \$US99). With propensity-score matching without Hb variables, mean estimated costs were \$US3836 for EA and \$US3599 for DA (mean difference \$US237; p = 0.053, SE \$US123). With propensity-score match including Hb variables, mean costs were \$US3965 for EA and \$US3536 for DA (mean difference \$US429; p = 0.001, SE \$US125). Cost differences in sensitivity analyses ranged between \$US102 (p = 0.201) and \$US261 (p = 0.003). CONCLUSIONS: Addition of baseline Hb level as a variable in propensity score and ESA cost models affects ESA treatment cost estimates in patients with cancer receiving chemotherapy. Cost comparisons based on observational data should use analytical methods that account for differences in clinical variables between treatment groups.}},
    author = {Polsky, D. and Eremina, D. and Hess, G. and Hill, J. and Hulnick, S. and Roumm, A. and Whyte, J. L. and Kallich, J.},
    citeulike-article-id = {13872124},
    citeulike-linkout-0 = {http://dx.doi.org/10.2165/11313860-000000000-00000},
    doi = {10.2165/11313860-000000000-00000},
    isbn = {1170-7690 1179-2027},
    journal = {PharmacoEconomics},
    keywords = {exportrecords, propensity-scores},
    number = {9},
    pages = {755--65},
    posted-at = {2015-12-09 01:09:00},
    priority = {3},
    title = {{The Importance of Clinical Variables in Comparative Analyses Using Propensity-Score Matching: The Case of ESA Costs for the Treatment of Chemotherapy-Induced Anaemia}},
    url = {http://dx.doi.org/10.2165/11313860-000000000-00000},
    volume = {27},
    year = {2009}
}

@article{16812,
    abstract = {{Machine learning techniques such as classification and regression trees (CART) have been suggested as promising alternatives to logistic regression for the estimation of propensity scores. The authors examined the performance of various CART-based propensity score models using simulated data. Hypothetical studies of varying sample sizes (n=500, 1000, 2000) with a binary exposure, continuous outcome, and 10 covariates were simulated under seven scenarios differing by degree of non-linear and non-additive associations between covariates and the exposure. Propensity score weights were estimated using logistic regression (all main effects), CART, pruned CART, and the ensemble methods of bagged CART, random forests, and boosted CART. Performance metrics included covariate balance, standard error, per cent absolute bias, and 95 per cent confidence interval (CI) coverage. All methods displayed generally acceptable performance under conditions of either non-linearity or non-additivity alone. However, under conditions of both moderate non-additivity and moderate non-linearity, logistic regression had subpar performance, whereas ensemble methods provided substantially better bias reduction and more consistent 95 per cent CI coverage. The results suggest that ensemble methods, especially boosted CART, may be useful for propensity score weighting. Copyright {\copyright} 2009 John Wiley \& Sons, Ltd.}},
    author = {Lee, B. K. and Lessler, J. and Stuart, E. A.},
    citeulike-article-id = {13872097},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.3782},
    doi = {10.1002/sim.3782},
    isbn = {1097-0258;},
    journal = {Statistics in Medicine},
    keywords = {exportrecords, propensity-scores},
    number = {3},
    pages = {337--346},
    posted-at = {2015-12-09 01:08:59},
    priority = {3},
    title = {{Improving propensity score weighting using machine learning}},
    url = {http://dx.doi.org/10.1002/sim.3782},
    volume = {29},
    year = {2010}
}

@article{16806,
    abstract = {{We examine the practicality of propensity score methods for estimating causal treatment effects conditional on intermediate posttreatment outcomes (principal effects) in the context of randomized experiments. In particular, we focus on the sensitivity of principal causal effect estimates to violation of principal ignorability, which is the primary assumption that underlies the use of propensity score methods to estimate principal effects. Under principal ignorability (PI), principal strata membership is conditionally independent of the potential outcome under control given the pre-treatment covariates; i.e. there are no differences in the potential outcomes under control across principal strata given the observed pretreatment covariates. Under this assumption, principal scores modeling principal strata membership can be estimated based solely on the observed covariates and used to predict strata membership and estimate principal effects. While this assumption underlies the use of propensity scores in this setting, sensitivity to violations of it has not been studied rigorously. In this paper, we explicitly define PI using the outcome model (although we do not actually use this outcome model in estimating principal scores) and systematically examine how deviations from the assumption affect estimates, including how the strength of association between principal stratum membership and covariates modifies the performance. We find that when PI is violated, very strong covariate predictors of stratum membership are needed to yield accurate estimates of principal effects. Copyright {\copyright} 2009 John Wiley \& Sons, Ltd.}},
    author = {Jo, B. and Stuart, E. A.},
    citeulike-article-id = {13872096},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.3669},
    doi = {10.1002/sim.3669},
    isbn = {1097-0258;},
    journal = {Statistics in Medicine},
    keywords = {exportrecords, propensity-scores},
    number = {23},
    pages = {2857--2875},
    posted-at = {2015-12-09 01:08:59},
    priority = {3},
    title = {{On the use of propensity scores in principal causal effect estimation}},
    url = {http://dx.doi.org/10.1002/sim.3669},
    volume = {28},
    year = {2009}
}

@article{17403,
    abstract = {{BACKGROUND: Randomized controlled trials are considered the best scientific proof of effectiveness. There is increasing concern, though, about their feasibility in psychotherapy research. We discuss a quasi-experimental study design for situations in which a randomized controlled trial is not feasible. Here, as an alternative strategy, the propensity score (PS) method is used to correct for selection bias. METHODS: We used data from a Dutch research project, SCEPTRE (Study on Cost-Effectiveness of Personality Disorder Treatment). The sample consisted of 749 psychotherapy patients with personality pathology. We tested whether the PS method was useful and applicable. We examined differences between 2 treatment groups (short vs. long treatment duration) in pretreatment characteristics before and after PS correction. This revealed the impact of the PS on outcome differences. RESULTS: The PS offered statistical control over observed pretreatment differences between patients in a non-randomized study. CONCLUSIONS: When a randomized controlled trial is not possible, this quasi-experimental design using the PS could be a feasible alternative. Its advantages and limitations are discussed. Implemented carefully, this method is promising for future effectiveness research. 2008 S. Karger AG, Basel.}},
    author = {Bartak, A. and Spreeuwenberg, M. D. and Andrea, H. and Busschbach, J. J. and Croon, M. A. and Verheul, R. and Emmelkamp, P. M. and Stijnen, T.},
    citeulike-article-id = {13872024},
    citeulike-linkout-0 = {http://dx.doi.org/10.1159/000162298},
    doi = {10.1159/000162298},
    isbn = {1423-0348 ; 0033-3190;},
    journal = {Psychotherapy and Psychosomatics},
    keywords = {exportrecords, propensity-scores},
    number = {1},
    pages = {26--34},
    posted-at = {2015-12-09 01:08:58},
    priority = {3},
    title = {{The use of propensity score methods in psychotherapy research. A practical application}},
    url = {http://dx.doi.org/10.1159/000162298},
    volume = {78},
    year = {2009}
}

@article{17377,
    abstract = {{Propensity-score matching is increasingly being used to reduce the impact of treatment-selection bias when estimating causal treatment effects using observational data. Matching on the propensity score creates sets of treated and untreated subjects who have a similar distribution of baseline covariates. Propensity-score matching frequently relies upon calipers, such that matched treated and untreated subjects must have propensity scores that lie within a specified caliper distance of each other. We define the lsquomarginally matchedrsquo subject as a subject who would be matched using the specified caliper width, but who would not have been matched had calipers with a narrower width been employed. Using patients hospitalized with an acute myocardial infarction (or heart attack) and with exposure to a statin prescription at discharge, we demonstrate that the inclusion of marginally matched subjects can have both a quantitative and qualitative impact upon the estimated treatment effect. Furthermore, marginally matched treated subjects can differ from marginally matched untreated subjects to a substantially greater degree than the differences between non-marginally matched treated and untreated subjects in the propensity-score matched sample. The concept of the marginally matched subject can be used as a sensitivity analysis to examine the impact of the matching method on the estimates of treatment effectiveness. Copyright {\copyright} 2009 John Wiley \& Sons, Ltd.}},
    author = {Austin, P. C. and Lee, D.},
    citeulike-article-id = {13872022},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.1733},
    doi = {10.1002/pds.1733},
    isbn = {1053-8569; 1099-1557 ;},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {bias---selection, exportrecords, propensity-scores, sensitivity-analysis},
    number = {6},
    pages = {469--482},
    posted-at = {2015-12-09 01:08:58},
    priority = {3},
    title = {{The concept of the marginally matched subject in propensity-score matched analyses}},
    url = {http://dx.doi.org/10.1002/pds.1733},
    volume = {18},
    year = {2009}
}

@article{17375,
    abstract = {{The propensity score is defined to be a subject's probability of treatment selection, conditional on observed baseline covariates. Conditional on the propensity score, treated and untreated subjects have similar distributions of observed baseline covariates. In the medical literature, there are three commonly employed propensity-score methods: stratification (subclassification) on the propensity score, matching on the propensity score, and covariate adjustment using the propensity score. Methods have been developed to assess the adequacy of the propensity score model in the context of stratification on the propensity score and propensity-score matching. However, no comparable methods have been developed for covariate adjustment using the propensity score. Inferences about treatment effect made using propensity-score methods are only valid if, conditional on the propensity score, treated and untreated subjects have similar distributions of baseline covariates. We develop both quantitative and qualitative methods to assess the balance in baseline covariates between treated and untreated subjects. The quantitative method employs the weighted conditional standardized difference. This is the conditional difference in the mean of a covariate between treated and untreated subjects, in units of the pooled standard deviation, integrated over the distribution of the propensity score. The qualitative method employs quantile regression models to determine whether, conditional on the propensity score, treated and untreated subjects have similar distributions of continuous covariates. We illustrate our methods using a large dataset of patients discharged from hospital with a diagnosis of a heart attack (acute myocardial infarction). The exposure was receipt of a prescription for a beta-blocker at hospital discharge. Copyright {\copyright} 2008 John Wiley \& Sons, Ltd.}},
    author = {Austin, P. C.},
    citeulike-article-id = {13872021},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.1673},
    doi = {10.1002/pds.1673},
    isbn = {1053-8569; 1099-1557},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {exportrecords, propensity-scores, statistics},
    number = {12},
    pages = {1202--1217},
    posted-at = {2015-12-09 01:08:58},
    priority = {3},
    title = {{Goodness-of-fit diagnostics for the propensity score model when estimating treatment effects using covariate adjustment with the propensity score}},
    url = {http://dx.doi.org/10.1002/pds.1673},
    volume = {17},
    year = {2008}
}

@article{17242,
    abstract = {{Confounding variables can affect the results from studies of children with Down syndrome and their families. Traditional methods for addressing confounders are often limited, providing control for only a few confounding variables. This study introduces propensity score matching to control for multiple confounding variables. Using Tennessee birth data as an example, newborns with Down syndrome were compared with a group of typically developing infants on birthweight. Three approaches to matching on confounders-nonmatched, covariate matched, and propensity matched-were compared using 8 potential confounders. Fewer than half of the newborns with Down syndrome were matched using covariate matching, and the matched group was differed from the unmatched newborns. Using propensity scores, 100\% of newborns with Down syndrome could be matched to a group of comparison newborns, a decreased effect size was found on newborn birthweight, and group differences were not statistically significant.}},
    author = {Blackford, J. U.},
    citeulike-article-id = {13872017},
    citeulike-linkout-0 = {http://dx.doi.org/10.1352/1934-9556-47.5.348},
    doi = {10.1352/1934-9556-47.5.348},
    isbn = {1934-9491; 1934-9556;},
    journal = {Intellectual and Developmental Disabilities},
    keywords = {exportrecords, propensity-scores},
    number = {5},
    pages = {348--357},
    posted-at = {2015-12-09 01:08:58},
    priority = {3},
    title = {{Propensity scores: method for matching on multiple variables in down syndrome research}},
    url = {http://dx.doi.org/10.1352/1934-9556-47.5.348},
    volume = {47},
    year = {2009}
}

@article{16852,
    abstract = {{Propensity-score matching allows one to reduce the effects of treatment-selection bias or confounding when estimating the effects of treatments when using observational data. Some authors have suggested that methods of inference appropriate for independent samples can be used for assessing the statistical significance of treatment effects when using propensity-score matching. Indeed, many authors in the applied medical literature use methods for independent samples when making inferences about treatment effects using propensity-score matched samples. Dichotomous outcomes are common in healthcare research. In this study, we used Monte Carlo simulations to examine the effect on inferences about risk differences (or absolute risk reductions) when statistical methods for independent samples are used compared with when statistical methods for paired samples are used in propensity-score matched samples. We found that compared with using methods for independent samples, the use of methods for paired samples resulted in: (i) empirical type I error rates that were closer to the advertised rate; (ii) empirical coverage rates of 95 per cent confidence intervals that were closer to the advertised rate; (iii) narrower 95 per cent confidence intervals; and (iv) estimated standard errors that more closely reflected the sampling variability of the estimated risk difference. Differences between the empirical and advertised performance of methods for independent samples were greater when the treatment-selection process was stronger compared with when treatment-selection process was weaker. We recommend using statistical methods for paired samples when using propensity-score matched samples for making inferences on the effect of treatment on the reduction in the probability of an event occurring. Copyright (c) 2011 John Wiley \& Sons, Ltd.}},
    author = {Austin, P. C.},
    citeulike-article-id = {13872004},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4200},
    doi = {10.1002/sim.4200},
    isbn = {1097-0258 ; 0277-6715 ;},
    journal = {Statistics in Medicine},
    keywords = {bias---selection, exportrecords, propensity-scores, statistics},
    number = {11},
    pages = {1292--1301},
    posted-at = {2015-12-09 01:08:57},
    priority = {3},
    title = {{Comparing paired vs non-paired statistical methods of analyses when making inferences about absolute risk reductions in propensity-score matched samples}},
    url = {http://dx.doi.org/10.1002/sim.4200},
    volume = {30},
    year = {2011}
}

@article{16820,
    abstract = {{Propensity score methods are increasingly being used to estimate the effects of treatments on health outcomes using observational data. There are four methods for using the propensity score to estimate treatment effects: covariate adjustment using the propensity score, stratification on the propensity score, propensity-score matching, and inverse probability of treatment weighting (IPTW) using the propensity score. When outcomes are binary, the effect of treatment on the outcome can be described using odds ratios, relative risks, risk differences, or the number needed to treat. Several clinical commentators suggested that risk differences and numbers needed to treat are more meaningful for clinical decision making than are odds ratios or relative risks. However, there is a paucity of information about the relative performance of the different propensity-score methods for estimating risk differences. We conducted a series of Monte Carlo simulations to examine this issue. We examined bias, variance estimation, coverage of confidence intervals, mean-squared error (MSE), and type I error rates. A doubly robust version of IPTW had superior performance compared with the other propensity-score methods. It resulted in unbiased estimation of risk differences, treatment effects with the lowest standard errors, confidence intervals with the correct coverage rates, and correct type I error rates. Stratification, matching on the propensity score, and covariate adjustment using the propensity score resulted in minor to modest bias in estimating risk differences. Estimators based on IPTW had lower MSE compared with other propensity-score methods. Differences between IPTW and propensity-score matching may reflect that these two methods estimate the average treatment effect and the average treatment effect for the treated, respectively. Copyright {\copyright} 2010 John Wiley \& Sons, Ltd.}},
    author = {Austin, P. C.},
    citeulike-article-id = {13872002},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.3854},
    doi = {10.1002/sim.3854},
    issn = {1097-0258},
    journal = {Statistics in Medicine},
    keywords = {exportrecords, propensity-scores, systematic-reviews---methodologic-studies},
    number = {20},
    pages = {2137--2148},
    posted-at = {2015-12-09 01:08:57},
    priority = {3},
    title = {{The performance of different propensity-score methods for estimating differences in proportions (risk differences or absolute risk reductions) in observational studies}},
    url = {http://dx.doi.org/10.1002/sim.3854},
    volume = {29},
    year = {2010}
}

@article{16807,
    abstract = {{The propensity score is a subject's probability of treatment, conditional on observed baseline covariates. Conditional on the true propensity score, treated and untreated subjects have similar distributions of observed baseline covariates. Propensity-score matching is a popular method of using the propensity score in the medical literature. Using this approach, matched sets of treated and untreated subjects with similar values of the propensity score are formed. Inferences about treatment effect made using propensity-score matching are valid only if, in the matched sample, treated and untreated subjects have similar distributions of measured baseline covariates. In this paper we discuss the following methods for assessing whether the propensity score model has been correctly specified: comparing means and prevalences of baseline characteristics using standardized differences; ratios comparing the variance of continuous covariates between treated and untreated subjects; comparison of higher order moments and interactions; five-number summaries; and graphical methods such as quantile-quantile plots, side-by-side boxplots, and non-parametric density plots for comparing the distribution of baseline covariates between treatment groups. We describe methods to determine the sampling distribution of the standardized difference when the true standardized difference is equal to zero, thereby allowing one to determine the range of standardized differences that are plausible with the propensity score model having been correctly specified. We highlight the limitations of some previously used methods for assessing the adequacy of the specification of the propensity-score model. In particular, methods based on comparing the distribution of the estimated propensity score between treated and untreated subjects are uninformative. Copyright (c) 2009 John Wiley \& Sons, Ltd.}},
    author = {Austin, P. C.},
    citeulike-article-id = {13872000},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.3697},
    doi = {10.1002/sim.3697},
    isbn = {1097-0258 ;},
    journal = {Statistics in Medicine},
    keywords = {exportrecords, medical-tests---diagnostic, propensity-scores},
    number = {25},
    pages = {3083--3107},
    posted-at = {2015-12-09 01:08:57},
    priority = {3},
    title = {{Balance diagnostics for comparing the distribution of baseline covariates between treatment groups in propensity-score matched samples}},
    url = {http://dx.doi.org/10.1002/sim.3697},
    volume = {28},
    year = {2009}
}

@article{16785,
    abstract = {{Propensity-score methods are increasingly being used to reduce the impact of treatment-selection bias in the estimation of treatment effects using observational data. Commonly used propensity-score methods include covariate adjustment using the propensity score, stratification on the propensity score, and propensity-score matching. Empirical and theoretical research has demonstrated that matching on the propensity score eliminates a greater proportion of baseline differences between treated and untreated subjects than does stratification on the propensity score. However, the analysis of propensity-score-matched samples requires statistical methods appropriate for matched-pairs data. We critically evaluated 47 articles that were published between 1996 and 2003 in the medical literature and that employed propensity-score matching. We found that only two of the articles reported the balance of baseline characteristics between treated and untreated subjects in the matched sample and used correct statistical methods to assess the degree of imbalance. Thirteen (28 per cent) of the articles explicitly used statistical methods appropriate for the analysis of matched data when estimating the treatment effect and its statistical significance. Common errors included using the log-rank test to compare Kaplan-Meier survival curves in the matched sample, using Cox regression, logistic regression, chi-squared tests, t-tests, and Wilcoxon rank sum tests in the matched sample, thereby failing to account for the matched nature of the data. We provide guidelines for the analysis and reporting of studies that employ propensity-score matching.}},
    author = {Austin, P. C.},
    citeulike-article-id = {13871997},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.3150},
    doi = {10.1002/sim.3150},
    issn = {0277-6715},
    journal = {Statistics in Medicine},
    keywords = {bias---selection, exportrecords, propensity-scores},
    number = {12},
    pages = {2037--2049},
    posted-at = {2015-12-09 01:08:57},
    priority = {3},
    title = {{A critical appraisal of propensity-score matching in the medical literature between 1996 and 2003}},
    url = {http://dx.doi.org/10.1002/sim.3150},
    volume = {27},
    year = {2008}
}

@article{16710,
    abstract = {{Automated databases are increasingly used in pharmacoepidemiologic studies. These databases include records of prescribed medications and encounters with medical care providers from which one can construct very detailed surrogate measures for both drug exposure and covariates that are potential confounders. Often it is possible to track day-by-day changes in these variables. However, while this information is often critical for study success, its volume can pose challenges for statistical analysis. One common approach is the use of propensity scores. An alternative approach is to construct a disease risk score. This is analogous to the propensity score in that it calculates a summary measure from the covariates. However, the disease risk score estimates the probability or rate of disease occurrence conditional on being unexposed. The association between exposure and disease is then estimated adjusting for the disease risk score in place of the individual covariates. This review describes the use of disease risk scores in pharmacoepidemiologic studies, and includes a brief discussion of their history, a more detailed description of their construction and use, a summary of simulation studies comparing their performance vis-a-vis traditional models, a comparison of their utility with that of propensity scores, and some further topics for future research.}},
    author = {Arbogast, P. G. and Ray, W. A.},
    citeulike-article-id = {13871996},
    citeulike-linkout-0 = {http://dx.doi.org/10.1177/0962280208092347},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Disease Risk Score Methods Papers]},
    doi = {10.1177/0962280208092347},
    isbn = {0962-2802;},
    journal = {Statistical Methods in Medical Research},
    keywords = {disease-risk-scores, exportrecords, propensity-scores},
    number = {1},
    pages = {67--80},
    posted-at = {2015-12-09 01:08:57},
    priority = {3},
    title = {{Use of disease risk scores in pharmacoepidemiologic studies}},
    url = {http://dx.doi.org/10.1177/0962280208092347},
    volume = {18},
    year = {2009}
}

@article{15538,
    abstract = {{OBJECTIVE: Propensity scores for the analysis of observational data are typically estimated using logistic regression. Our objective in this review was to assess machine learning alternatives to logistic regression, which may accomplish the same goals but with fewer assumptions or greater accuracy. STUDY DESIGN AND SETTING: We identified alternative methods for propensity score estimation and/or classification from the public health, biostatistics, discrete mathematics, and computer science literature, and evaluated these algorithms for applicability to the problem of propensity score estimation, potential advantages over logistic regression, and ease of use. RESULTS: We identified four techniques as alternatives to logistic regression: neural networks, support vector machines, decision trees (classification and regression trees [CART]), and meta-classifiers (in particular, boosting). CONCLUSION: Although the assumptions of logistic regression are well understood, those assumptions are frequently ignored. All four alternatives have advantages and disadvantages compared with logistic regression. Boosting (meta-classifiers) and, to a lesser extent, decision trees (particularly CART), appear to be most promising for use in the context of propensity score analysis, but extensive simulation studies are needed to establish their utility in practice. Copyright (c) 2010 Elsevier Inc. All rights reserved.}},
    author = {Westreich, D. and Lessler, J. and Funk, M. J.},
    citeulike-article-id = {13871977},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2009.11.020},
    doi = {10.1016/j.jclinepi.2009.11.020},
    isbn = {1878-5921; 0895-4356},
    journal = {Journal of clinical epidemiology},
    keywords = {exportrecords, propensity-scores},
    number = {8},
    pages = {826--833},
    posted-at = {2015-12-09 01:08:57},
    priority = {3},
    title = {{Propensity score estimation: neural networks, support vector machines, decision trees (CART), and meta-classifiers as alternatives to logistic regression}},
    url = {http://dx.doi.org/10.1016/j.jclinepi.2009.11.020},
    volume = {63},
    year = {2010}
}

@article{15441,
    author = {Tleyjeh, I. M. and Ghomrawi, H. M. and Steckelberg, J. M. and Montori, V. M. and Hoskin, T. L. and Enders, F. and Huskins, W. C. and Mookadam, F. and Wilson, W. R. and Zimmerman, V. and Baddour, L. M.},
    citeulike-article-id = {13871974},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2009.07.017},
    doi = {10.1016/j.jclinepi.2009.07.017},
    isbn = {1878-5921; 0895-4356},
    journal = {Journal of clinical epidemiology},
    keywords = {bias---selection, exportrecords, propensity-scores},
    number = {2},
    pages = {139--140},
    posted-at = {2015-12-09 01:08:57},
    priority = {3},
    title = {{Propensity score analysis with a time-dependent intervention is an acceptable although not an optimal analytical approach when treatment selection bias and survivor bias coexist}},
    url = {http://dx.doi.org/10.1016/j.jclinepi.2009.07.017},
    volume = {63},
    year = {2010}
}

@article{16241,
    abstract = {{BACKGROUND AND OBJECTIVE: The propensity score method (PS) has proven to be an effective tool to reduce bias in nonrandomized studies, especially when the number of (potential) confounders is large and dimensionality problems arise. The PS method introduced by Rosenbaum and Rubin is described in detail for studies with 2 treatment options. Since in clinical practice we are often interested in the comparison of multiple interventions, there was a need to extend the PS method to multiple treatments. It has been shown that in theory a multiple PS method is possible. So far, its practical application is rare and a practical introduction lacking. METHODS: A practical guideline to illustrate the use of the multiple PS method is provided with data from a mental health study. The multiple PS is estimated with a multinomial logistic regression analysis. The multiple PS is the probability of assignment to each treatment category. Subsequently, to estimate the treatment effects while controlling for initial differences, the multiple PSs, calculated for each treatment category, are included as extra predictors in the regression analysis. RESULTS: With the multiple PS method, balance was achieved in all relevant pretreatment variables. The corrected estimated treatment effects were somewhat different from the results without control for initial differences. CONCLUSIONS: Our results indicate that the multiple PS method is a feasible method to adjust for observed pretreatment differences in nonrandomized studies where the number of pretreatment differences is large and multiple treatments are compared.}},
    author = {Spreeuwenberg, M. D. and Bartak, A. and Croon, M. A. and Hagenaars, J. A. and Busschbach, J. J. and Andrea, H. and Twisk, J. and Stijnen, T.},
    citeulike-article-id = {13871967},
    citeulike-linkout-0 = {http://dx.doi.org/10.1097/MLR.0b013e3181c1328f},
    doi = {10.1097/MLR.0b013e3181c1328f},
    isbn = {1537-1948 0025-7079},
    journal = {Medical Care},
    keywords = {bias---selection, exportrecords, propensity-scores},
    number = {2},
    pages = {166--74},
    posted-at = {2015-12-09 01:08:57},
    priority = {3},
    title = {{The multiple propensity score as control for bias in the comparison of more than two treatment arms: an introduction from a case study in mental health}},
    url = {http://dx.doi.org/10.1097/MLR.0b013e3181c1328f},
    volume = {48},
    year = {2010}
}

@article{15695,
    abstract = {{Often, when conducting programme evaluations or studying the effects of policy changes, researchers may only have access to aggregated time series data, presented as observations spanning both the pre- and post-intervention periods. The most basic analytic model using these data requires only a single group and models the intervention effect using repeated measurements of the dependent variable. This model controls for regression to the mean and is likely to detect a treatment effect if it is sufficiently large. However, many potential sources of bias still remain. Adding one or more control groups to this model could strengthen causal inference if the groups are comparable on pre-intervention covariates and level and trend of the dependent variable. If this condition is not met, the validity of the study findings could be called into question. In this paper we describe a propensity score-based weighted regression model, which overcomes these limitations by weighting the control groups to represent the average outcome that the treatment group would have exhibited in the absence of the intervention. We illustrate this technique studying cigarette sales in California before and after the passage of Proposition 99 in California in 1989. While our results were similar to those of the Synthetic Control method, the weighting approach has the advantage of being technically less complicated, rooted in regression techniques familiar to most researchers, easy to implement using any basic statistical software, may accommodate any number of treatment units, and allows for greater flexibility in the choice of treatment effect estimators. {\copyright} 2010 Blackwell Publishing Ltd.}},
    author = {Linden, A. and Adams, J. L.},
    citeulike-article-id = {13871885},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.1365-2753.2010.01504.x},
    doi = {10.1111/j.1365-2753.2010.01504.x},
    isbn = {1365-2753; 1356-1294},
    journal = {Journal of Evaluation in Clinical Practice},
    keywords = {exportrecords, propensity-scores, statistics},
    number = {6},
    pages = {1231--1238},
    posted-at = {2015-12-09 01:08:55},
    priority = {3},
    title = {{Applying a propensity score-based weighting model to interrupted time series data: improving causal inference in programme evaluation}},
    url = {http://dx.doi.org/10.1111/j.1365-2753.2010.01504.x},
    volume = {17},
    year = {2011}
}

@article{16285,
    abstract = {{The propensity score is a balancing score: conditional on the propensity score, treated and untreated subjects have the same distribution of observed baseline characteristics. Four methods of using the propensity score have been described in the literature: stratification on the propensity score, propensity score matching, inverse probability of treatment weighting using the propensity score, and covariate adjustment using the propensity score. However, the relative ability of these methods to reduce systematic differences between treated and untreated subjects has not been examined. The authors used an empirical case study and Monte Carlo simulations to examine the relative ability of the 4 methods to balance baseline covariates between treated and untreated subjects. They used standardized differences in the propensity score matched sample and in the weighted sample. For stratification on the propensity score, within-quintile standardized differences were computed comparing the distribution of baseline covariates between treated and untreated subjects within the same quintile of the propensity score. These quintile-specific standardized differences were then averaged across the quintiles. For covariate adjustment, the authors used the weighted conditional standardized absolute difference to compare balance between treated and untreated subjects. In both the empirical case study and in the Monte Carlo simulations, they found that matching on the propensity score and weighting using the inverse probability of treatment eliminated a greater degree of the systematic differences between treated and untreated subjects compared with the other 2 methods. In the Monte Carlo simulations, propensity score matching tended to have either comparable or marginally superior performance compared with propensity-score weighting.}},
    author = {Austin, P. C.},
    citeulike-article-id = {13871770},
    citeulike-linkout-0 = {http://dx.doi.org/10.1177/0272989X09341755},
    doi = {10.1177/0272989X09341755},
    isbn = {1552-681X; 0272-989X;},
    journal = {Medical Decision Making},
    keywords = {exportrecords, propensity-scores, systematic-reviews---methodologic-studies},
    number = {6},
    pages = {661--677},
    posted-at = {2015-12-09 01:08:53},
    priority = {3},
    title = {{The Relative Ability of Different Propensity Score Methods to Balance Measured Covariates Between Treated and Untreated Subjects in Observational Studies}},
    url = {http://dx.doi.org/10.1177/0272989X09341755},
    volume = {29},
    year = {2009}
}

@article{14941,
    abstract = {{Confounding due to population stratification (PS) arises when differences in both allele and disease frequencies exist in a population of mixed racial/ethnic subpopulations. Genomic control, structured association, principal components analysis (PCA), and multidimensional scaling (MDS) approaches have been proposed to address this bias using genetic markers. However, confounding due to PS can also be due to non-genetic factors. Propensity scores are widely used to address confounding in observational studies but have not been adapted to deal with PS in genetic association studies. We propose a genomic propensity score (GPS) approach to correct for bias due to PS that considers both genetic and non-genetic factors. We compare the GPS method with PCA and MDS using simulation studies. Our results show that GPS can adequately adjust and consistently correct for bias due to PS. Under no/mild, moderate, and severe PS, GPS yielded estimated with bias close to 0 (mean=-0.0044, standard error=0.0087). Under moderate or severe PS, the GPS method consistently outperforms the PCA method in terms of bias, coverage probability (CP), and type I error. Under moderate PS, the GPS method consistently outperforms the MDS method in terms of CP. PCA maintains relatively high power compared to both MDS and GPS methods under the simulated situations. GPS and MDS are comparable in terms of statistical properties such as bias, type I error, and power. The GPS method provides a novel and robust tool for obtaining less-biased estimates of genetic associations that can consider both genetic and non-genetic factors. Genet. Epidemiol. 2009. (c) 2009 Wiley-Liss, Inc.}},
    author = {Zhao, H. and Rebbeck, T. R. and Mitra, N.},
    citeulike-article-id = {13871751},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/gepi.20419},
    doi = {10.1002/gepi.20419},
    isbn = {0741-0395; 1098-2272},
    journal = {Genetic Epidemiology},
    keywords = {exportrecords, propensity-scores},
    number = {8},
    pages = {679--690},
    posted-at = {2015-12-09 01:08:52},
    priority = {3},
    title = {{A propensity score approach to correction for bias due to population stratification using genetic and non-genetic factors}},
    url = {http://dx.doi.org/10.1002/gepi.20419},
    volume = {33},
    year = {2009}
}

@article{15036,
    abstract = {{In cancer observational studies, differences between groups on confounding variables may have a significant effect on results when examining health outcomes. This study demonstrates the utility of propensity score matching to balance a non-cancer and cancer cohort of older adults on multiple relevant covariates. This approach matches cases to controls on a single indicator, the propensity score, rather than multiple variables. Results indicated that propensity score matching is an efficient and useful way to create a matched case-control study out of a large cohort study, and allows confidence in the strength of the observed outcomes of the study.}},
    author = {Reeve, B. B. and Smith, A. W. and Arora, N. K. and Hays, R. D.},
    citeulike-article-id = {13871713},
    isbn = {0195-8631; 1554-9887},
    journal = {Health Care Financing Review},
    keywords = {exportrecords, propensity-scores},
    number = {4},
    pages = {69--80},
    posted-at = {2015-12-09 01:08:51},
    priority = {3},
    title = {{Reducing bias in cancer research: application of propensity score matching}},
    volume = {29},
    year = {2008}
}

@article{14877,
    abstract = {{BACKGROUND: Adjusting for large numbers of covariates ascertained from patients' health care claims data may improve control of confounding, as these variables may collectively be proxies for unobserved factors. Here, we develop and test an algorithm that empirically identifies candidate covariates, prioritizes covariates, and integrates them into a propensity-score-based confounder adjustment model. METHODS: We developed a multistep algorithm to implement high-dimensional proxy adjustment in claims data. Steps include (1) identifying data dimensions, eg, diagnoses, procedures, and medications; (2) empirically identifying candidate covariates; (3) assessing recurrence of codes; (4) prioritizing covariates; (5) selecting covariates for adjustment; (6) estimating the exposure propensity score; and (7) estimating an outcome model. This algorithm was tested in Medicare claims data, including a study on the effect of Cox-2 inhibitors on reduced gastric toxicity compared with nonselective nonsteroidal anti-inflammatory drugs (NSAIDs). RESULTS: In a population of 49,653 new users of Cox-2 inhibitors or nonselective NSAIDs, a crude relative risk (RR) for upper GI toxicity (RR = 1.09 [95\% confidence interval = 0.91-1.30]) was initially observed. Adjusting for 15 predefined covariates resulted in a possible gastroprotective effect (0.94 [0.78-1.12]). A gastroprotective effect became stronger when adjusting for an additional 500 algorithm-derived covariates (0.88 [0.73-1.06]). Results of a study on the effect of statin on reduced mortality were similar. Using the algorithm adjustment confirmed a null finding between influenza vaccination and hip fracture (1.02 [0.85-1.21]). CONCLUSIONS: In typical pharmacoepidemiologic studies, the proposed high-dimensional propensity score resulted in improved effect estimates compared with adjustment limited to predefined covariates, when benchmarked against results expected from randomized trials.}},
    author = {Schneeweiss, S. and Rassen, J. A. and Glynn, R. J. and Avorn, J. and Mogun, H. and Brookhart, M. A.},
    citeulike-article-id = {13871705},
    citeulike-linkout-0 = {http://dx.doi.org/10.1097/EDE.0b013e3181a663cc},
    doi = {10.1097/EDE.0b013e3181a663cc},
    isbn = {1044-3983; 1531-5487},
    journal = {Epidemiology},
    keywords = {data---administrative-billing, exportrecords, propensity-scores},
    number = {4},
    pages = {512--522},
    posted-at = {2015-12-09 01:08:51},
    priority = {3},
    title = {{High-dimensional Propensity Score Adjustment in Studies of Treatment Effects Using Health Care Claims Data}},
    url = {http://dx.doi.org/10.1097/EDE.0b013e3181a663cc},
    volume = {20},
    year = {2009}
}

@article{15168,
    abstract = {{BACKGROUND: In medical research both propensity score methods and logistic regression analysis are used to estimate treatment effects in observational studies. From literature reviews it has been concluded that treatment effect estimates from both methods are quite similar. With this study we will show that there are systematic differences which can be substantial. METHODS: We used a simulated population with a known marginal treatment effect and applied a propensity score method and logistic regression analysis to adjust for confounding. RESULTS: The adjusted treatment effect in logistic regression is in general further away from the true marginal treatment effect than the adjusted effect in propensity score methods. The difference is systematic and dependent on the incidence proportion, the number of prognostic factors and the magnitude of the treatment effect. For instance, a substantial difference of 20\% is found when the treatment effect is 2.0, the incidence proportion is 0.20 and there are more than 11 prognostic factors. CONCLUSIONS: Propensity score methods give in general treatment effect estimates that are closer to the true marginal treatment effect than a logistic regression model in which all confounders are modelled.}},
    author = {Martens, E. P. and Pestman, W. R. and Boer, A. D. and Belitser, S. V. and Klungel, O. H.},
    citeulike-article-id = {13871665},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/ije/dyn079},
    doi = {10.1093/ije/dyn079},
    isbn = {0300-5771; 1464-3685;},
    journal = {International Journal of Epidemiology},
    keywords = {exportrecords, propensity-scores},
    number = {5},
    pages = {1142--1147},
    posted-at = {2015-12-09 01:08:50},
    priority = {3},
    title = {{Systematic differences in treatment effect estimates between propensity score methods and logistic regression}},
    url = {http://dx.doi.org/10.1093/ije/dyn079},
    volume = {37},
    year = {2008}
}

@article{14417,
    abstract = {{BACKGROUND: The impact of early surgery on mortality in patients with native valve endocarditis (NVE) is unresolved. This study sought to evaluate valve surgery compared with medical therapy for NVE and to identify characteristics of patients who are most likely to benefit from early surgery. METHODS AND RESULTS: Using a prospective, multinational cohort of patients with definite NVE, the effect of early surgery on in-hospital mortality was assessed by propensity-based matching adjustment for survivor bias and by instrumental variable analysis. Patients were stratified by propensity quintile, paravalvular complications, valve perforation, systemic embolization, stroke, Staphylococcus aureus infection, and congestive heart failure. Of the 1552 patients with NVE, 720 (46\%) underwent early surgery and 832 (54\%) were treated with medical therapy. Compared with medical therapy, early surgery was associated with a significant reduction in mortality in the overall cohort (12.1\% [87/720] versus 20.7\% [172/832]) and after propensity-based matching and adjustment for survivor bias (absolute risk reduction [ARR] -5.9\%, P<0.001). With a combined instrument, the instrumental-variable-adjusted ARR in mortality associated with early surgery was -11.2\% (P<0.001). In subgroup analysis, surgery was found to confer a survival benefit compared with medical therapy among patients with a higher propensity for surgery (ARR -10.9\% for quintiles 4 and 5, P=0.002) and those with paravalvular complications (ARR -17.3\%, P<0.001), systemic embolization (ARR -12.9\%, P=0.002), S aureus NVE (ARR -20.1\%, P<0.001), and stroke (ARR -13\%, P=0.02) but not those with valve perforation or congestive heart failure. CONCLUSIONS: Early surgery for NVE is associated with an in-hospital mortality benefit compared with medical therapy alone.}},
    author = {Lalani, T. and Cabell, C. H. and Benjamin, D. K. and Lasca, O. and Naber, C. and Fowler and Corey, G. R. and Chu, V. H. and Fenely, M. and Pachirat, O. and Tan, R. S. and Watkin, R. and Ionac, A. and Moreno, A. and Mestres, C. A. and Casab\'{e}, J. and Chipigina, N. and Eisen, D. P. and Spelman, D. and Delahaye, F. and Peterson, G. and Olaison, L. and Wang, A. and International Collaboration on Endocarditis-Prospective Cohort Study ICE-PCS Investigators},
    citeulike-article-id = {13871637},
    citeulike-linkout-0 = {http://dx.doi.org/10.1161/CIRCULATIONAHA.109.864488},
    doi = {10.1161/CIRCULATIONAHA.109.864488},
    isbn = {0009-7322; 1524-4539;},
    journal = {Circulation},
    keywords = {exportrecords, propensity-scores, subgroup-analysis},
    number = {8},
    pages = {1005--1013},
    posted-at = {2015-12-09 01:08:50},
    priority = {3},
    title = {{Analysis of the Impact of Early Surgery on In-Hospital Mortality of Native Valve Endocarditis. Use of Propensity Score and Instrumental Variable Methods to Adjust for Treatment-Selection Bias}},
    url = {http://dx.doi.org/10.1161/CIRCULATIONAHA.109.864488},
    volume = {121},
    year = {2010}
}

@article{15151,
    abstract = {{Propensity-score matching is frequently used in the medical literature to reduce or eliminate the effect of treatment selection bias when estimating the effect of treatments or exposures on outcomes using observational data. In propensity-score matching, pairs of treated and untreated subjects with similar propensity scores are formed. Recent systematic reviews of the use of propensity-score matching found that the large majority of researchers ignore the matched nature of the propensity-score matched sample when estimating the statistical significance of the treatment effect. We conducted a series of Monte Carlo simulations to examine the impact of ignoring the matched nature of the propensity-score matched sample on Type I error rates, coverage of confidence intervals, and variance estimation of the treatment effect. We examined estimating differences in means, relative risks, odds ratios, rate ratios from Poisson models, and hazard ratios from Cox regression models. We demonstrated that accounting for the matched nature of the propensity-score matched sample tended to result in type I error rates that were closer to the advertised level compared to when matching was not incorporated into the analyses. Similarly, accounting for the matched nature of the sample tended to result in confidence intervals with coverage rates that were closer to the nominal level, compared to when matching was not taken into account. Finally, accounting for the matched nature of the sample resulted in estimates of standard error that more closely reflected the sampling variability of the treatment effect compared to when matching was not taken into account.}},
    author = {Austin, P. C.},
    citeulike-article-id = {13871587},
    citeulike-linkout-0 = {http://dx.doi.org/10.2202/1557-4679.1146},
    doi = {10.2202/1557-4679.1146},
    issn = {1557-4679},
    journal = {International Journal of Biostatistics},
    keywords = {bias---selection, exportrecords, propensity-scores, statistics},
    number = {1},
    pages = {Article 13+},
    posted-at = {2015-12-09 01:08:49},
    priority = {3},
    title = {{Type I error rates, coverage of confidence intervals, and variance estimation in propensity-score matched analyses}},
    url = {http://dx.doi.org/10.2202/1557-4679.1146},
    volume = {5},
    year = {2009}
}

@article{13520,
    abstract = {{Frailty, a poorly measured confounder in older patients, can promote treatment in some situations and discourage it in others. This can create unmeasured confounding and lead to nonuniform treatment effects over the propensity score (PS). The authors compared bias and mean squared error for various PS implementations under PS trimming, thereby excluding persons treated contrary to prediction. Cohort studies were simulated with a binary treatment T as a function of 8 covariates X. Two of the covariates were assumed to be unmeasured strong risk factors for the outcome and present in persons treated contrary to prediction. The outcome Y was simulated as a Poisson function of T and all X's. In analyses based on measured covariates only, the range of PS's was trimmed asymmetrically according to the percentile of PS in treated patients at the lower end and in untreated patients at the upper end. PS trimming reduced bias due to unmeasured confounders and mean squared error in most scenarios assessed. Treatment effect estimates based on PS range restrictions do not correspond to a causal parameter but may be less biased by such unmeasured confounding. Increasing validity based on PS trimming may be a unique advantage of PS's over conventional outcome models.}},
    author = {St\"{u}rmer and Rothman, K. J. and Avorn, J. and Glynn, R. J.},
    citeulike-article-id = {13871527},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/aje/kwq198},
    doi = {10.1093/aje/kwq198},
    isbn = {1476-6256; 0002-9262;},
    journal = {American Journal of Epidemiology},
    keywords = {bias---general, exportrecords, propensity-scores, statistics},
    number = {7},
    pages = {843--854},
    posted-at = {2015-12-09 01:08:47},
    priority = {3},
    title = {{Treatment Effects in the Presence of Unmeasured Confounding: Dealing With Observations in the Tails of the Propensity Score Distribution--A Simulation Study}},
    url = {http://dx.doi.org/10.1093/aje/kwq198},
    volume = {172},
    year = {2010}
}

@article{13248,
    abstract = {{BACKGROUND: In propensity score modeling, it is a standard practice to optimize the prediction of exposure status based on the covariate information. In a simulation study, we examined in what situations analyses based on various types of exposure propensity score (EPS) models using data mining techniques such as recursive partitioning (RP) and neural networks (NN) produce unbiased and/or efficient results. METHOD: We simulated data for a hypothetical cohort study (n = 2000) with a binary exposure/outcome and 10 binary/continuous covariates with seven scenarios differing by non-linear and/or non-additive associations between exposure and covariates. EPS models used logistic regression (LR) (all possible main effects), RP1 (without pruning), RP2 (with pruning), and NN. We calculated c-statistics (C), standard errors (SE), and bias of exposure-effect estimates from outcome models for the PS-matched dataset. RESULTS: Data mining techniques yielded higher C than LR (mean: NN, 0.86; RPI, 0.79; RP2, 0.72; and LR, 0.76). SE tended to be greater in models with higher C. Overall bias was small for each strategy, although NN estimates tended to be the least biased. C was not correlated with the magnitude of bias (correlation coefficient [COR] = -0.3, p = 0.1) but increased SE (COR = 0.7, p < 0.001). CONCLUSIONS: Effect estimates from EPS models by simple LR were generally robust. NN models generally provided the least numerically biased estimates. C was not associated with the magnitude of bias but was with the increased SE.}},
    author = {Setoguchi, S. and Schneeweiss, S. and Brookhart, M. A. and Glynn, R. J. and Cook, E. F.},
    citeulike-article-id = {13871525},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.1555},
    doi = {10.1002/pds.1555},
    isbn = {1099-1557; 1053-8569},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {data---mining, exportrecords, propensity-scores},
    number = {6},
    pages = {546--555},
    posted-at = {2015-12-09 01:08:47},
    priority = {3},
    title = {{Evaluating uses of data mining techniques in propensity score estimation: a simulation study}},
    url = {http://dx.doi.org/10.1002/pds.1555},
    volume = {17},
    year = {2008}
}

@article{13842,
    abstract = {{OBJECTIVE: To demonstrate the use of propensity scores to evaluate the comparative effectiveness of laparoscopic and open appendectomy. DESIGN: Retrospective cohort study. SETTING: Academic and private hospitals. PATIENTS: All patients undergoing open or laparoscopic appendectomy (n = 21 475) in the Public Use File of the American College of Surgeons National Surgical Quality Improvement Program were included in the study. We first evaluated the surgical approach (laparoscopic vs open) using multivariate logistic regression. We next generated propensity scores and compared outcomes for open and laparoscopic appendectomy in a 1:1 matched cohort. Covariates in the model for propensity scores included comorbidities, age, sex, race, and evidence of perforation. MAIN OUTCOME MEASURES: Patient morbidity and mortality, rate of return to operating room, and hospital length of stay. RESULTS: Twenty-eight percent of patients underwent open appendectomy, and 72\% had a laparoscopic approach; 33\% (open) vs 14\% (laparoscopic) had evidence of a ruptured appendix. In the propensity-matched cohort, there was no difference in mortality (0.3\% vs 0.2\%), reoperation (1.8\% vs 1.5\%), or incidence of major complications (5.9\% vs 5.4\%) between groups. Patients undergoing laparoscopic appendectomy experienced fewer wound infections (odds ratio [OR], 0.4; 95\% confidence interval [CI], 0.3-0.5) and fewer episodes of sepsis (0.8; 0.6-1.0) but had a greater risk of intra-abdominal abscess (1.7; 1.3-2.2). An analysis using multivariate adjustment resulted in similar findings. CONCLUSIONS: After accounting for patient severity, open and laparoscopic appendectomy had similar clinical outcomes. In this case study, propensity score methods and multivariate adjustment yielded nearly identical results.}},
    author = {Hemmila, M. R. and Birkmeyer, N. J. and Arbabi, S. and Osborne, N. H. and Wahl, W. L. and Dimick, J. B.},
    citeulike-article-id = {13871453},
    citeulike-linkout-0 = {http://dx.doi.org/10.1001/archsurg.2010.193},
    doi = {10.1001/archsurg.2010.193},
    isbn = {1538-3644; 0004-0010},
    journal = {Archives of Surgery},
    keywords = {data---clinical, exportrecords, propensity-scores},
    number = {10},
    pages = {939--945},
    posted-at = {2015-12-09 01:08:45},
    priority = {3},
    title = {{Introduction to propensity scores: A case study on the comparative effectiveness of laparoscopic vs open appendectomy}},
    url = {http://dx.doi.org/10.1001/archsurg.2010.193},
    volume = {145},
    year = {2010}
}

@article{12871,
    abstract = {{The propensity score collapses the covariates of an observational study into a single measure summarizing their joint association with treatment conditions; prognostic scores summarize covariates' association with potential responses. As with propensity scores, stratification on prognostic scores brings to uncontrolled studies a concrete and desirable form of balance, a balance that is more familiar as an objective of experimental control. Like propensity scores, prognostic scores can reduce the dimension of the covariate, yet causal inferences conditional on them are as valid as are inferences conditional only on the unreduced covariate. As a method of adjustment unto itself, prognostic scoring has limitations not shared with propensity scoring, but it holds promise as a complement to the propensity score, particularly in certain designs for which unassisted propensity adjustment is difficult or infeasible.}},
    author = {Hansen, B. B.},
    citeulike-article-id = {13871433},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/biomet/asn004},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Disease Risk Score Methods Papers]},
    doi = {10.1093/biomet/asn004},
    isbn = {1464-3510; 0006-3444},
    journal = {Biometrika},
    keywords = {exportrecords, propensity-scores},
    number = {2},
    pages = {481--488},
    posted-at = {2015-12-09 01:08:45},
    priority = {3},
    title = {{The prognostic analogue of the propensity score}},
    url = {http://dx.doi.org/10.1093/biomet/asn004},
    volume = {95},
    year = {2008}
}

@article{12811,
    abstract = {{PURPOSE: Residual confounding is a potential limitation of pharmacoepidemiologic studies, and in particular, studies based on administrative claims data that do not capture lifestyle and clinical confounders. We describe an application of the case-cohort design to assess residual confounding by thromboembolic risk factors (e.g., smoking and obesity) not captured in claims data in a claims-based cohort study of thromboembolism among matched oral contraceptive (OC) initiators. METHODS: This study was conducted using the Ingenix Research Data Mart, a database containing medical claims for approximately 12 million members of a large health plan of the United States. We randomly sampled 701 OC initiators from cohorts of ethinyl estradiol/drospirenone (n = 22,429) and other OC initiators (n = 44,858) identified in the years 2001-2004 and matched by propensity score in a claims-based cohort study. Supplementary data on risk factors not measured in the cohort study were collected from medical records for the sample. We estimated the risk ratio of thromboembolism adjusted for the supplementary variables using Cox regression modified for a case-cohort design, and compared it to the rate ratio from the cohort study. RESULTS: The risk ratio adjusted for the supplementary variables was 0.90 (95 per cent (\%) confidence interval (CI): 0.49, 1.68) which was similar to the rate ratio (0.92; 95\%CI: 0.50, 1.63), indicating negligible confounding by the supplementary variables in the cohort study. CONCLUSIONS: Case-cohort methods were used to assess residual confounding in a claims-based cohort study. This approach adds to a growing number of methods to evaluate residual confounding in cohort studies. Copyright 2008 John Wiley \& Sons, Ltd.}},
    author = {Eng, P. M. and Seeger, J. D. and Loughlin, J. and Clifford, C. R. and Mentor, S. and Walker, A. M.},
    citeulike-article-id = {13871429},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.1554},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Methods Papers]},
    doi = {10.1002/pds.1554},
    isbn = {1099-1557; 1053-8569},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {cohort-study---methods, confounding, data---administrative-billing, exportrecords, propensity-scores},
    number = {3},
    pages = {297--305},
    posted-at = {2015-12-09 01:08:45},
    priority = {3},
    title = {{Supplementary data collection with case-cohort analysis to address potential confounding in a cohort study of thromboembolism in oral contraceptive initiators matched on claims-based propensity scores}},
    url = {http://dx.doi.org/10.1002/pds.1554},
    volume = {17},
    year = {2008}
}

@article{13521,
    abstract = {{Propensity-score matching is increasingly being used to estimate the effects of treatments using observational data. In many-to-one (M:1) matching on the propensity score, M untreated subjects are matched to each treated subject using the propensity score. The authors used Monte Carlo simulations to examine the effect of the choice of M on the statistical performance of matched estimators. They considered matching 1-5 untreated subjects to each treated subject using both nearest-neighbor matching and caliper matching in 96 different scenarios. Increasing the number of untreated subjects matched to each treated subject tended to increase the bias in the estimated treatment effect; conversely, increasing the number of untreated subjects matched to each treated subject decreased the sampling variability of the estimated treatment effect. Using nearest-neighbor matching, the mean squared error of the estimated treatment effect was minimized in 67.7\% of the scenarios when 1:1 matching was used. Using nearest-neighbor matching or caliper matching, the mean squared error was minimized in approximately 84\% of the scenarios when, at most, 2 untreated subjects were matched to each treated subject. The authors recommend that, in most settings, researchers match either 1 or 2 untreated subjects to each treated subject when using propensity-score matching.}},
    author = {Austin, P. C.},
    citeulike-article-id = {13871381},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/aje/kwq224},
    doi = {10.1093/aje/kwq224},
    isbn = {1476-6256; 0002-9262},
    journal = {American Journal of Epidemiology},
    keywords = {exportrecords, propensity-scores, statistics},
    number = {9},
    pages = {1092--1097},
    posted-at = {2015-12-09 01:08:44},
    priority = {3},
    title = {{Statistical criteria for selecting the optimal number of untreated subjects matched to each treated subject when using many-to-one matching on the propensity score}},
    url = {http://dx.doi.org/10.1093/aje/kwq224},
    volume = {172},
    year = {2010}
}

@article{19829,
    abstract = {{This article compares Donald Campbell's and Donald Rubin's work on causal inference in field settings on issues of epistemology, theories of cause and effect, methodology, statistics, generalization, and terminology. The two approaches are quite different but compatible, differing mostly in matters of bandwidth versus fidelity. Campbell's work demonstrates broad narrative scope that covers a wide array of concepts related to causation, with a powerful appreciation for human fallibility in making causal judgments, with a more elaborate theory of cause and generalization, and with a preference for design over analysis. Rubin's approach is a more narrow and formal quantitative analysis of effect estimation, sharing a preference for design but best known for analysis, with compelling quantitative approaches to obtaining unbiased quantitative effect estimates from nonrandomized designs and with comparatively little to say about generalization. Much could be gained by joining the emphasis on design in Campbell with the emphasis on analysis in Rubin. However, the 2 approaches also speak modestly different languages that leave some questions about their total commensurability that only continued dialogue can fully clarify.}},
    author = {Shadish, W. R.},
    citeulike-article-id = {13871353},
    citeulike-linkout-0 = {http://dx.doi.org/10.1037/a0015916},
    doi = {10.1037/a0015916},
    isbn = {1939-1463; 1082-989X},
    journal = {Psychological Methods},
    keywords = {exportrecords, propensity-scores},
    number = {1},
    pages = {3--17},
    posted-at = {2015-12-09 01:08:43},
    priority = {3},
    title = {{Campbell and Rubin: A primer and comparison of their approaches to causal inference in field settings}},
    url = {http://dx.doi.org/10.1037/a0015916},
    volume = {15},
    year = {2010}
}

@article{20852,
    abstract = {{This article describes the core features of outcome research and then explores issues confronting researchers who engage in outcome studies. Using an intervention research perspective, descriptive and explanatory methods are distinguished. Emphasis is placed on the counterfactual causal perspective, designing programs that fit culture and context, and developing nuanced explanations for program outcomes. Five emerging challenges are discussed: (a) adapting interventions to the contexts and cultures in which programs are to be implemented, (b) avoiding potentially false attributions of program failure due to differential implementation, (c) making causal inferences from observational data with propensity score analysis (PSA), (d) examining person-centered outcomes in program evaluation, and (e) adjusting for rater effects in longitudinal research. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Fraser, M. W. and Guo, S. and Ellis, A. R. and Thompson, A. M. and Wike, T. L. and Li, J.},
    citeulike-article-id = {13871002},
    citeulike-linkout-0 = {http://dx.doi.org/10.1177/1049731511406136},
    doi = {10.1177/1049731511406136},
    isbn = {U13  - No},
    journal = {Research on Social Work Practice},
    keywords = {exportrecords, propensity-scores},
    number = {6},
    pages = {619--635},
    posted-at = {2015-12-09 01:08:35},
    priority = {3},
    title = {{Outcome studies of social, behavioral, and educational interventions: Emerging issues and challenges}},
    url = {http://dx.doi.org/10.1177/1049731511406136},
    volume = {21},
    year = {2011}
}

@article{20859,
    abstract = {{Longitudinal research has demonstrated a link between exposure to sexual content in media and subsequent changes in adolescent sexual behavior, including initiation of intercourse and various noncoital sexual activities. Based on a reanalysis of one of the data sets involved, Steinberg and Monahan (2011) have challenged these findings. However, propensity score approaches-especially the version of this method used by Steinberg and Monahan, which lacks covariates-do not necessarily result in more accurate estimates of treatment effects than does the regression with covariates approach employed by prior research. There are also a number of problems with the specific set of analyses presented by Steinberg and Monahan and the conclusion they draw from them. In contrast to Steinberg and Monahan's claim, there is substantial evidence of an association between sexual media exposure and adolescent sexual initiation. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Collins, R. L. and Martino, S. C. and Elliott, M. N.},
    citeulike-article-id = {13871000},
    citeulike-linkout-0 = {http://dx.doi.org/10.1037/a0022564},
    doi = {10.1037/a0022564},
    isbn = {0012-1649; 1939-0599},
    journal = {Developmental Psychology},
    keywords = {exportrecords, propensity-scores},
    number = {2},
    pages = {577--579},
    posted-at = {2015-12-09 01:08:35},
    priority = {3},
    title = {{Propensity scoring and the relationship between sexual media and adolescent sexual behavior: Comment on Steinberg and Monahan (2011)}},
    url = {http://dx.doi.org/10.1037/a0022564},
    volume = {47},
    year = {2011}
}

@article{20841,
    abstract = {{Propensity score methods allow investigators to estimate causal treatment effects using observational or nonrandomized data. In this article we provide a practical illustration of the appropriate steps in conducting propensity score analyses. For illustrative purposes, we use a sample of current smokers who were discharged alive after being hospitalized with a diagnosis of acute myocardial infarction. The exposure of interest was receipt of smoking cessation counseling prior to hospital discharge and the outcome was mortality with 3 years of hospital discharge. We illustrate the following concepts: first, how to specify the propensity score model; second, how to match treated and untreated participants on the propensity score; third, how to compare the similarity of baseline characteristics between treated and untreated participants after stratifying on the propensity score, in a sample matched on the propensity score, or in a sample weighted by the inverse probability of treatment; fourth, how to estimate the effect of treatment on outcomes when using propensity score matching, stratification on the propensity score, inverse probability of treatment weighting using the propensity score, or covariate adjustment using the propensity score. Finally, we compare the results of the propensity score analyses with those obtained using conventional regression adjustment. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Austin, P. C.},
    citeulike-article-id = {13870998},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/00273171.2011.540480},
    doi = {10.1080/00273171.2011.540480},
    isbn = {0027-3171; 1532-7906},
    journal = {Multivariate Behavioral Research},
    keywords = {bias---selection, exportrecords, propensity-scores},
    number = {1},
    pages = {119--151},
    posted-at = {2015-12-09 01:08:35},
    priority = {3},
    title = {{A tutorial and case study in propensity score analysis: An application to estimating the effect of in-hospital smoking cessation counseling on mortality}},
    url = {http://dx.doi.org/10.1080/00273171.2011.540480},
    volume = {46},
    year = {2011}
}

@article{20840,
    abstract = {{The propensity score is the probability of treatment assignment conditional on observed baseline characteristics. The propensity score allows one to design and analyze an observational (nonrandomized) study so that it mimics some of the particular characteristics of a randomized controlled trial. In particular, the propensity score is a balancing score: conditional on the propensity score, the distribution of observed baseline covariates will be similar between treated and untreated subjects. I describe 4 different propensity score methods: matching on the propensity score, stratification on the propensity score, inverse probability of treatment weighting using the propensity score, and covariate adjustment using the propensity score. I describe balance diagnostics for examining whether the propensity score model has been adequately specified. Furthermore, I discuss differences between regression-based methods and propensity score-based methods for the analysis of observational data. I describe different causal average treatment effects and their relationship with propensity score analyses. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Austin, P. C.},
    citeulike-article-id = {13870997},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/00273171.2011.568786},
    doi = {10.1080/00273171.2011.568786},
    isbn = {0027-3171; 1532-7906},
    journal = {Multivariate Behavioral Research},
    keywords = {bias---selection, exportrecords, propensity-scores},
    number = {3},
    pages = {399--424},
    posted-at = {2015-12-09 01:08:35},
    priority = {3},
    title = {{An introduction to propensity score methods for reducing the effects of confounding in observational studies}},
    url = {http://dx.doi.org/10.1080/00273171.2011.568786},
    volume = {46},
    year = {2011}
}

@article{20897,
    abstract = {{Comments on an article by Daniel B. Rubin and Mark J. van der Laan (see record 2010-23942-005). For missing data and causal inference problems, Rubin and van der Laan (2008) proposed estimators to achieve so-called improved local efficiency. We show that their estimators agree with existing estimators in the case of linear models, point out that one particular version of their estimators is also doubly robust, and suggest an extension for where the propensity score is estimated. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Tan, Z.},
    citeulike-article-id = {13870995},
    citeulike-linkout-0 = {http://dx.doi.org/10.2202/1557-4679.1109},
    doi = {10.2202/1557-4679.1109},
    isbn = {1557-4679;},
    journal = {International Journal of Biostatistics},
    keywords = {exportrecords, propensity-scores},
    number = {1},
    pages = {1--9},
    posted-at = {2015-12-09 01:08:35},
    priority = {3},
    title = {{Comment: Improved local efficiency and double robustness.}},
    url = {http://dx.doi.org/10.2202/1557-4679.1109},
    volume = {4},
    year = {2008}
}

@article{20894,
    abstract = {{Matching methods such as nearest neighbor propensity score matching are increasingly popular techniques for controlling confounding in nonexperimental studies. However, simple k:1 matching methods, which select k well-matched comparison individuals for each treated individual, are sometimes criticized for being overly restrictive and discarding data (the unmatched comparison individuals). The authors illustrate the use of a more flexible method called full matching. Full matching makes use of all individuals in the data by forming a series of matched sets in which each set has either 1 treated individual and multiple comparison individuals or 1 comparison individual and multiple treated individuals. Full matching has been shown to be particularly effective at reducing bias due to observed confounding variables. The authors illustrate this approach using data from the Woodlawn Study, examining the relationship between adolescent marijuana use and adult outcomes. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Stuart, E. A. and Green, K. M.},
    citeulike-article-id = {13870994},
    citeulike-linkout-0 = {http://dx.doi.org/10.1037/0012-1649.44.2.395},
    doi = {10.1037/0012-1649.44.2.395},
    isbn = {U13  - No},
    journal = {Developmental Psychology},
    keywords = {exportrecords, propensity-scores},
    number = {2},
    pages = {395--406},
    posted-at = {2015-12-09 01:08:35},
    priority = {3},
    title = {{Using full matching to estimate causal effects in nonexperimental studies: Examining the relationship between adolescent marijuana use and adult outcomes.}},
    url = {http://dx.doi.org/10.1037/0012-1649.44.2.395},
    volume = {44},
    year = {2008}
}

@article{20883,
    abstract = {{Comments on the articles by Hollister (see record 2008-04094-010) and Nathan (see record 2008-04094-011), who addressed the questions posed by Nathan as Point/Counterpoint editor (see record 2008-04094-009), regarding the use of and alternatives to random assignment (RA) in evaluating public programs. The current authors suggest that the Hollister/Nathan debate was a nonstarter. Nathan did not answer his own second question: Are there alternatives to RA that are nearly as good? Instead, he emphasized implementation and performance management studies, which do not address how well and under what circumstances a program works, if at all? Dissatisfied with the debate, the current authors identified 18 articles that explicitly compared estimates using propensity score matching, difference in differences, or regression discontinuity design with results from randomized social experiments to determine whether these statistical corrections reduce or eliminate differences in impact estimates arising from selection bias in quasi-experimental studies. It is concluded that econometric correction techniques do not uniformly and consistently reproduce experimental results; therefore, they cannot be relied upon to provide a satisfactory substitute for RA experiments. Although regression discontinuity designs can replicate some RA studies, many public programs do not have the sharp eligibility cutoffs required to estimate these models. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Pirog, M. A. and Buffardi, A. L. and Chrisinger, C. K. and Singh, P. and Briney, J.},
    citeulike-article-id = {13870982},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pam.20411},
    doi = {10.1002/pam.20411},
    isbn = {0276-8739; 1520-6688},
    journal = {Journal of Policy Analysis and Management},
    keywords = {exportrecords, propensity-scores, systematic-reviews---methodologic-studies},
    number = {1},
    pages = {169--172},
    posted-at = {2015-12-09 01:08:35},
    priority = {3},
    title = {{Are the alternatives to randomized assignment nearly as good? Statistical corrections to nonrandomized evaluations.}},
    url = {http://dx.doi.org/10.1002/pam.20411},
    volume = {28},
    year = {2009}
}

@article{20848,
    abstract = {{This issue includes six articles that present logic, methods, and models for causal analyses of observational data, in particular those based on propensity score (PS) methods. The articles include a general introduction to propensity score analysis (PSA), uses of PSA in mediation studies, issues involved in choosing covariates, challenges that often arise in PSA applications, hierarchical data issues and models, and an application in an educational testing context. In this editorial I briefly summarize each article and make a few recommendations that relate to future applications in this field: the first pertains to how propensity score (PS) work could profit by connecting it with stronger forms of randomized experiments, not just simple randomization; the second to how and why graphical methods could be used to greater advantage in PSA studies; then why it might be helpful to reconsider the meaning of the term "treatments" in observational studies and why conventional usage might be modified; and finally, to the distinction between retrospective and prospective approaches to observational study design, noting the advantages, when feasible, of the latter approach. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Pruzek, R. M.},
    citeulike-article-id = {13870981},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/00273171.2011.576618},
    doi = {10.1080/00273171.2011.576618},
    isbn = {0027-3171; 1532-7906},
    journal = {Multivariate Behavioral Research},
    keywords = {exportrecords, propensity-scores},
    number = {3},
    pages = {389--398},
    posted-at = {2015-12-09 01:08:35},
    priority = {3},
    title = {{Introduction to the special issue on propensity score methods in behavioral research.}},
    url = {http://dx.doi.org/10.1080/00273171.2011.576618},
    volume = {46},
    year = {2011}
}

@article{20889,
    abstract = {{While the randomized controlled trial (RCT) remains the gold-standard study design for evaluating treatment effect, outcomes researchers turn to powerful quasi-experimental designs when only observational studies can be conducted. Within these designs, propensity score matching is one of the most popular to evaluate disease management (DM) programme effectiveness. Given that DM programmes generally have a much smaller number of participants than non-participants in the population, propensity score matching will typically result in all or nearly all participants finding successful matches, while most of the non-participants in the population remain unmatched and thereby excluded from the analysis. By excluding data from the unmatched population, the effect of non-treatment in the remaining population with the disease is not captured. In the present study, we examine changes in hospitalization rates stratified by propensity score quintiles across the entire population allowing us to gain insight as to how well the programme chose its participants, or if the programme could have been effective on those individuals not explicitly targeted for the intervention. These data indicate the presence of regression to the mean, and suggest that the DM programme may be overly limited to only the highest strata when there is evidence of a potential benefit for those in all the lower strata as well. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Linden, A. and Adams, J. L.},
    citeulike-article-id = {13870973},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.1365-2753.2008.01091.x},
    doi = {10.1111/j.1365-2753.2008.01091.x},
    isbn = {U13  - No},
    journal = {Journal of Evaluation in Clinical Practice},
    keywords = {exportrecords, propensity-scores},
    number = {5},
    pages = {914--918},
    posted-at = {2015-12-09 01:08:34},
    priority = {3},
    title = {{Improving participant selection in disease management programmes: Insights gained from propensity score stratification.}},
    url = {http://dx.doi.org/10.1111/j.1365-2753.2008.01091.x},
    volume = {14},
    year = {2008}
}

@article{20854,
    abstract = {{Comments on an article by Cindy D. Kam and Carl L. Palmer (see record 2010-08173-002). In a recent study, Kam and Palmer employ propensity score matching to assess whether college attendance causes participation after reducing selection bias due to pre-adult factors. After matching the authors find no correlation, upending a major pillar in political science. However, we argue that this study has serious flaws and should not be the basis for rejecting the traditional view of an "education effect" on participation. We match on 766,642 propensity scores and use genetic matching to recover better matches with lower covariate imbalances. We consistently find positive effects as covariate balance improves, though no matching approach yields unbiased results. We demonstrate that selection is a serious concern in studying the participatory effects of college attendance and that balance in the covariates and robustness to sensitivity diagnostics should be the ultimate guide for conducting matching analyses. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Henderson, J. and Chatfield, S.},
    citeulike-article-id = {13870972},
    citeulike-linkout-0 = {http://dx.doi.org/10.1017/S0022381611000351},
    doi = {10.1017/S0022381611000351},
    isbn = {0022-3816; 1468-2508},
    journal = {Journal of Politics},
    keywords = {exportrecords, propensity-scores},
    number = {3},
    pages = {646--658},
    posted-at = {2015-12-09 01:08:34},
    priority = {3},
    title = {{Who matches? Propensity scores and bias in the causal effects of education on participation.}},
    url = {http://dx.doi.org/10.1017/S0022381611000351},
    volume = {73},
    year = {2011}
}

@article{20833,
    abstract = {{Comments on an article by Lars Vedel Kessing et al. (see record 2011-22407-012). In this study, Lithium again is shown to be superior to valproate for the management of bipolar disorder. The strength in this case comes from bridging the gap between the relatively brief follow-up in randomized control trials (RCTs) and the real-life situation. The limitations of observational cohort studies are multiple and well documented. One key concern is confounding by indication, but more general problems exist with group biases and masking of cause and effect relationships. Kessing et al. used 'switch to' and 'add on' as proxy outcomes for the efficacy of mood stabilizers. It would have been interesting, if possible, to separate the 'switch to' group from the 'add on' groups. Indeed, their findings suggest that the initial, very rapid increase in incidence of switch/add on is related to tolerability rather than efficacy, whereas in BALANCE this finding would have been lost by drop-out during the run-in period. This is unlikely, however, to explain the superiority of lithium that is clearly present in both outcome measures. This sort of complementary approach, reconfirming findings from RCTs over long follow-up periods, is an important addition to the evidence base for treatment. Bias can be minimized by propensity score matching, although this method was not employed by Kessing et al. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Hayes, J. F. and Osborn, D.},
    citeulike-article-id = {13870971},
    citeulike-linkout-0 = {http://dx.doi.org/10.1192/bjp.199.4.341b},
    doi = {10.1192/bjp.199.4.341b},
    isbn = {0007-1250; 1472-1465},
    journal = {British Journal of Psychiatry},
    keywords = {exportrecords, propensity-scores},
    number = {4},
    pages = {341--342},
    posted-at = {2015-12-09 01:08:34},
    priority = {3},
    title = {{Observational BALANCE.}},
    url = {http://dx.doi.org/10.1192/bjp.199.4.341b},
    volume = {199},
    year = {2011}
}

@article{20832,
    abstract = {{Reply by the current authors to the comments made by Joseph F. Hayes (see record 2012-24051-019) on the original article (see record 2011-22407-012). Kessing et al. certainly agreed on the mentioned advantages and disadvantages of observational studies and on the strengths of combining findings from randomized trials with those of observational studies. Further, they agreed on the possibility of the suggested analyses with 'switch to' and 'add on' as two separate outcomes. One of the advantages of using the combined outcome measure is that the results may turn out to be more clear to guide clinical decisions on whether to use lithium or valproate in long-term treatment of bipolar disorder following a number of clinical situations. Propensity score matching is a viable alternative to the approach based on multiple Cox regression models used in their paper. However, much experience suggests that the results thus obtained would not tend to be substantially different. The limiting factor seems to be the available amount of covariate information. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Kessing, L. V. and Andersen, P. K.},
    citeulike-article-id = {13870970},
    citeulike-linkout-0 = {http://dx.doi.org/10.1192/bjp.199.4.342},
    doi = {10.1192/bjp.199.4.342},
    isbn = {0007-1250; 1472-1465},
    journal = {British Journal of Psychiatry},
    keywords = {exportrecords, propensity-scores},
    number = {4},
    pages = {342+},
    posted-at = {2015-12-09 01:08:34},
    priority = {3},
    title = {{"Observational BALANCE": Reply.}},
    url = {http://dx.doi.org/10.1192/bjp.199.4.342},
    volume = {199},
    year = {2011}
}

@article{23084,
    abstract = {{In recent years, social scientists have increasingly turned to matching as a method for drawing causal inferences from observational data. Matching compares those who receive a treatment to those with similar background attributes who do not receive a treatment. Researchers who use matching frequently tout its ability to reduce bias, particularly when applied to data sets that contain extensive background information. Drawing on a randomized voter mobilization experiment, the authors compare estimates generated by matching to an experimental benchmark. The enormous sample size enables the authors to exactly match each treated subject to 40 untreated subjects. Matching greatly exaggerates the effectiveness of pre-election phone calls encouraging voter participation. Moreover, it can produce nonsensical results: Matching suggests that another pre-election phone call that encouraged people to wear their seat belts also generated huge increases in voter turnout. This illustration suggests that caution is warranted when applying matching estimators to observational data, particularly when one is uncertain about the potential for biased inference.}},
    author = {Arceneaux, K. and Gerber, A. S. and Green, D. P.},
    citeulike-article-id = {13870961},
    citeulike-linkout-0 = {http://dx.doi.org/10.1177/0049124110378098},
    doi = {10.1177/0049124110378098},
    isbn = {U13  - No},
    issn = {0049-1241},
    journal = {Sociological Methods \& Research},
    keywords = {exportrecords, propensity-scores},
    number = {2},
    pages = {256--282},
    posted-at = {2015-12-09 01:08:34},
    priority = {3},
    title = {{A Cautionary Note on the Use of Matching to Estimate Causal Effects: An Empirical Example Comparing Matching Estimates to an Experimental Benchmark}},
    url = {http://dx.doi.org/10.1177/0049124110378098},
    volume = {39},
    year = {2010}
}

@article{20875,
    abstract = {{Aim: A sizable percentage of subjects do not respond to follow-up attempts in smoking cessation studies. The usual procedure in the smoking cessation literature is to assume that non-respondents have resumed smoking. This study used data from a study with a high follow-up rate to assess the degree of bias that may be caused by different methods of imputing missing data. Design and methods: Based on a large data set with very little missing follow-up information at 12 months, a simulation study was undertaken to compare and contrast missing data imputation methods (assuming smoking, propensity score matching and optimal matching) under various assumptions as to how the missing data arose (randomly generated missing values, increased non-response from smokers and a hybrid of the two). Findings: Missing data imputation methods all resulted in some degree of bias which increased with the amount of missing data. Conclusion: None of the missing data imputation methods currently available can compensate for bias when there are substantial amounts of missing data. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Barnes, S. A. and Larsen, M. D. and Schroeder, D. and Hanson, A. and Decker, P. A.},
    citeulike-article-id = {13870960},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.1360-0443.2009.02809.x},
    doi = {10.1111/j.1360-0443.2009.02809.x},
    isbn = {0965-2140; 1360-0443},
    journal = {Addiction},
    keywords = {exportrecords, propensity-scores},
    number = {3},
    pages = {431--437},
    posted-at = {2015-12-09 01:08:34},
    priority = {3},
    title = {{Missing data assumptions and methods in a smoking cessation study.}},
    url = {http://dx.doi.org/10.1111/j.1360-0443.2009.02809.x},
    volume = {105},
    year = {2010}
}

@article{20896,
    abstract = {{Reply by the current authors to the comments made by Zhiqiang Tan (see record 2010-23942-018) on the original article (see record 2010-23942-005). Tan initially points out that when the outcome regression model is linear, the estimators given in our paper can reduce to estimators previously presented by Tan himself and by Robins, Rotnitzky, and Zhao. We had not observed this, and it is an important clarification. Tan also notes that one estimator we introduced has a desired double robustness property, meaning it will be accurate if either an outcome regression model or propensity score model is correctly specified. While superfluous for the randomized experiment setting of our paper, it is nice to know that our "improved local efficiency" can be achieved in observational studies, or experiments with noncompliance or loss to follow-up. Our technique provides a criterion for forming regression fits to minimize asymptotic variance for the resulting parameter estimator, and we hope this property is valuable for data analysis. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Rubin, D. B. and van der Laan, M. J.},
    citeulike-article-id = {13870744},
    citeulike-linkout-0 = {http://dx.doi.org/10.2202/1557-4679.1116},
    doi = {10.2202/1557-4679.1116},
    issn = {1557-4679},
    journal = {International Journal of Biostatistics},
    keywords = {exportrecords, propensity-scores},
    number = {1},
    pages = {1+},
    posted-at = {2015-12-09 01:08:30},
    priority = {3},
    title = {{"Empirical efficiency maximization: Improved locally efficient covariate adjustment in randomized experiments and survival analysis": Rejoinder to Tan}},
    url = {http://dx.doi.org/10.2202/1557-4679.1116},
    volume = {4},
    year = {2008}
}

@article{20860,
    abstract = {{Although much psychiatric research is based on randomized controlled trials (RCTs), where patients are randomly assigned to treatments, sometimes RCTs are not ethical nor feasible. Ethical concerns might preclude randomization, such as when evaluating whether "light cigarettes" produce less health risk by potentially randomizing subjects to smoke different brands, or it may be impractical, such as when the treatment of interest is widely available and commonly used. When RCTs are unethical or infeasible, a carefully constructed nonexperimental study can often be used to estimate treatment effects. Although nonexperimental studies are disadvantaged by lack of randomization, the study costs may be lower, the study sample may be broader, and follow-up may be longer, as compared to an RCT. The causa] effect of a treatment can be unambiguously identified in studies where we are confident that the only difference between those subjects who take one treatment versus another is exposure to the intended treatments. By virtue of randomization, RCTs ensure, on average, the treatment and comparison groups are similar on baseline characteristics, both those that are measured as well as unmeasured ones. In conclusion, propensity score approaches such as matching, weighting, and sub classification are an important step forward in the estimation of treatment effects using observational data. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Stuart, E. A. and Marcus, S. M. and Horvitz-Lennon, M. V. and Gibbons, R. D. and Normand, S. T.},
    citeulike-article-id = {13870743},
    citeulike-linkout-0 = {http://dx.doi.org/10.3928/00485713-20090625-07},
    doi = {10.3928/00485713-20090625-07},
    isbn = {0048-5713; 1938-2456},
    journal = {Psychiatric Annals},
    keywords = {exportrecords, propensity-scores},
    number = {7},
    pages = {719--728},
    posted-at = {2015-12-09 01:08:30},
    priority = {3},
    title = {{Using non-experimental data to estimate treatment effects}},
    url = {http://dx.doi.org/10.3928/00485713-20090625-07},
    volume = {39},
    year = {2009}
}

@article{20872,
    abstract = {{In this article, we note the many ontological, epistemological, and methodological similarities between how Campbell and Rubin conceptualize causation. We then explore 3 differences in their written emphases about individual case matching in observational studies. We contend that (a) Campbell places greater emphasis than Rubin on the special role of pretest measures of outcome among matching variables; (b) Campbell is more explicitly concerned with unreliability in the covariates; and (c) for analyzing the outcome, only Rubin emphasizes the advantages of using propensity score over regression methods. To explore how well these 3 factors reduce bias, we reanalyze and review within-study comparisons that contrast experimental and statistically adjusted nonexperimental causal estimates from studies with the same target population and treatment content. In this context, the choice of covariates counts most for reducing selection bias, and the pretest usually plays a special role relative to all the other covariates considered singly. Unreliability in the covariates also influences bias reduction but by less. Furthermore, propensity score and regression methods produce comparable degrees of bias reduction, though these within-study comparisons may not have met the theoretically specified conditions most likely to produce differences due to analytic method. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Cook, T. D. and Steiner, P. M.},
    citeulike-article-id = {13870728},
    citeulike-linkout-0 = {http://dx.doi.org/10.1037/a0018536},
    doi = {10.1037/a0018536},
    isbn = {1082-989X; 1939-1463},
    journal = {Psychological Methods},
    keywords = {exportrecords, propensity-scores},
    number = {1},
    pages = {56--68},
    posted-at = {2015-12-09 01:08:30},
    priority = {3},
    title = {{Case matching and the reduction of selection bias in quasi-experiments: The relative importance of pretest measures of outcome, of unreliable measurement, and of mode of data analysis.}},
    url = {http://dx.doi.org/10.1037/a0018536},
    volume = {15},
    year = {2010}
}

@article{18357,
    abstract = {{PURPOSE: A key aspect of comparative effectiveness research is the assessment of competing treatment options and multiple outcomes rather than a single treatment option and a single benefit or harm. In this commentary, we describe a methodological framework that supports the simultaneous examination of a "matrix" of treatments and outcomes in non-randomized data. METHODS: We outline the methodological challenges to a matrix-type study (matrix design). We consider propensity score matching with multiple treatment groups, statistical analysis, and choice of association measure when evaluating multiple outcomes. We also discuss multiple testing, use of high-dimensional propensity scores for covariate balancing in light of multiple outcomes, and suitability of available software. CONCLUSION: The matrix design study methods facilitate examination of the comparative benefits and harms of competing treatment choices, and also provides the input required for calculating the numbers needed to treat and for a broader benefit/harm assessment that weighs endpoints of varying severity. Copyright {\copyright} 2011 John Wiley \& Sons, Ltd.}},
    author = {Rassen, J. A. and Solomon, D. H. and Glynn, R. J. and Schneeweiss, S.},
    citeulike-article-id = {13870651},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.2121},
    doi = {10.1002/pds.2121},
    isbn = {1053-8569; 1099-1557},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {exportrecords, propensity-scores, statistics},
    number = {7},
    pages = {675--683},
    posted-at = {2015-12-09 01:08:28},
    priority = {3},
    title = {{Simultaneously assessing intended and unintended treatment effects of multiple treatment options: a pragmatic "matrix design"}},
    url = {http://dx.doi.org/10.1002/pds.2121},
    volume = {20},
    year = {2011}
}

@article{17455,
    author = {Hansen, B. B.},
    citeulike-article-id = {13870456},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.3208},
    comment = {Comment on:

A critical appraisal of propensity-score matching in the medical literature between 1996 and 2003. Austin PC. Stat Med. 2008 May 30; 27(12):2037-49. PMID:18038446;},
    doi = {10.1002/sim.3208},
    issn = {0277-6715},
    journal = {Statistics in Medicine},
    keywords = {bias---selection, exportrecords, propensity-scores},
    number = {12},
    pages = {2050--2054; discussion 2066-2069},
    posted-at = {2015-12-09 01:08:24},
    priority = {3},
    title = {{The essential role of balance tests in propensity-matched observational studies: comments on 'A critical appraisal of propensity-score matching in the medical literature between 1996 and 2003' by Peter Austin, Statistics in Medicine}},
    url = {http://dx.doi.org/10.1002/sim.3208},
    volume = {27},
    year = {2008}
}

@article{16800,
    author = {Shrier, I.},
    citeulike-article-id = {13870372},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.3554},
    comment = {Comment on:

The design versus the analysis of observational studies for causal effects: parallels with the design of randomized trials.Rubin DB. Stat Med. 2007 Jan 15; 26(1):20-36.},
    doi = {10.1002/sim.3554},
    isbn = {0277-6715;},
    journal = {Statistics in Medicine},
    keywords = {exportrecords, propensity-scores},
    number = {8},
    pages = {1317--1318},
    posted-at = {2015-12-09 01:08:23},
    priority = {3},
    title = {{Propensity scores}},
    url = {http://dx.doi.org/10.1002/sim.3554},
    volume = {28},
    year = {2009}
}

@article{16798,
    abstract = {{In a recent issue of Statistics in Medicine, Ian Shrier [Statist. Med. 2008; 27(14):2740-2741] posed a question regarding the use of propensity scores [Biometrika 1983; 70(1):41-55]. He considered an lsquoM-structurersquo illustrated by the directed acyclic graph (DAG) in Figure 1. In Figure 1, z is a binary exposure, r is a response of interest, x is a measured covariate, and u1 and u2 are two unmeasured covariates. Shrier stated that for the M-structure, lsquo... it remains unclear if the propensity method described by Rubin would introduce selection bias or notrsquo. In the same issue, Donald Rubin [Statist. Med. 2002; 27(14):2741-2742] replied by clarifying several key points in the use of propensity scores. He did not, however, discuss the original question posed by Shrier. Given the popularity of both propensity score methods and graphical models, I think any confusion regarding the appropriateness of these methods deserves serious attention and I would therefore like to answer Shrier's question here. The short answer is that for the M-structure, propensity score methods do indeed induce a bias. Below, I will clarify this statement. I will first briefly review the basic idea of propensity scores and then explain why the idea does not apply to the M-structure. I will use a notation which is consistent with Rosenbaum and Rubin [Biometrika 1983; 70(1):41-55]. Copyright {\copyright} 2009 John Wiley \& Sons, Ltd.}},
    author = {Sj\"{o}lander, A.},
    citeulike-article-id = {13870371},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.3532},
    comment = {Comment on:

Re: The design versus the analysis of observational studies for causal effects: parallels with the design of randomized trials.Shrier I. Stat Med. 2008 Jun 30; 27(14):2740-1; author reply 2741-2.},
    doi = {10.1002/sim.3532},
    isbn = {1097-0258;},
    journal = {Statistics in Medicine},
    keywords = {exportrecords, propensity-scores},
    number = {9},
    pages = {1416--1420},
    posted-at = {2015-12-09 01:08:23},
    priority = {3},
    title = {{Propensity scores and M-structures}},
    url = {http://dx.doi.org/10.1002/sim.3532},
    volume = {28},
    year = {2009}
}

@article{16796,
    author = {Pearl, J.},
    citeulike-article-id = {13870360},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.3521},
    comment = {Comment on:

Re: The design versus the analysis of observational studies for causal effects: parallels with the design of randomized trials.Shrier I. Stat Med. 2008 Jun 30; 27(14):2740-1; author reply 2741-2.

The design versus the analysis of observational studies for causal effects: parallels with the design of randomized trials.Rubin DB. Stat Med. 2007 Jan 15; 26(1):20-36.},
    doi = {10.1002/sim.3521},
    isbn = {1097-0258;},
    journal = {Statistics in Medicine},
    keywords = {exportrecords, propensity-scores},
    number = {9},
    pages = {1415--1416},
    posted-at = {2015-12-09 01:08:23},
    priority = {3},
    title = {{Remarks on the method of propensity score}},
    url = {http://dx.doi.org/10.1002/sim.3521},
    volume = {28},
    year = {2009}
}

@article{15737,
    abstract = {{Recent modifications to traditional clinical research designs include propensity scores, equivalence, and non-inferiority trials, as well as greater use of pooled endpoints for primary outcome measures. Each of these innovations offers benefits, but they have been misused. Propensity score techniques can account for imbalance in treatment group allocation to provide more accurate estimates of benefit or risk. Unlike clinical trials, they typically represent real world, everyday practice and so their findings may in fact be less biased. Equivalence and non-inferiority designs can tailor clinical trials to address clinically meaningful questions: Is a proposed new technique at least as good as current treatment? Pooled endpoints can summarize a range of beneficial outcomes as well as reduce the required sample size. A clearer understanding of bias and confounding, and the interpretation of the 95\% confidence interval of the estimated treatment effect are central to proper use of these techniques.}},
    author = {Myles, P. S.},
    citeulike-article-id = {13870139},
    issn = {0022-1058},
    journal = {Journal of Extra-Corporeal Technology},
    keywords = {controlled-trials---equivalence---non-inferiority, exportrecords, propensity-scores},
    number = {4},
    pages = {P6--P10},
    posted-at = {2015-12-09 01:08:18},
    priority = {3},
    title = {{What's new in trial design: propensity scores, equivalence, and non-inferiority}},
    volume = {41},
    year = {2009}
}

@article{15436,
    author = {Austin, P. C. and Platt, R. W.},
    citeulike-article-id = {13870055},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2009.05.009},
    comment = {Comment on:

Purification and characterization of a barley aleurone abscisic acid-binding protein.Razem FA, Luo M, Liu JH, Abrams SR, Hill RD. J Biol Chem. 2004 Mar 12; 279(11):9922-9. Epub 2003 Dec 29.},
    doi = {10.1016/j.jclinepi.2009.05.009},
    isbn = {1878-5921; 0895-4356;},
    journal = {Journal of clinical epidemiology},
    keywords = {exportrecords, propensity-scores},
    number = {2},
    pages = {136--138},
    posted-at = {2015-12-09 01:08:17},
    priority = {3},
    title = {{Survivor treatment bias, treatment selection bias, and propensity scores in observational research}},
    url = {http://dx.doi.org/10.1016/j.jclinepi.2009.05.009},
    volume = {63},
    year = {2010}
}

@article{14437,
    abstract = {{BACKGROUND: The high cost and undesirable consequences of polypharmacy are well-recognized problems among elderly long-term care (LTC) residents. Despite the implementation of the 1987 Omnibus Budget Reconciliation Act, which requires pharmacist review of drug regimens in this setting, medical and drug costs for LTC residents have continued to increase. OBJECTIVE: This study evaluates the North Carolina Long-Term Care Polypharmacy Initiative, a large-scale medication therapy management program (MTMP) that combined drug utilization review activities with drug regimen review techniques. METHODS: This was a prospective records-based study that used a difference-in-difference model with both historical and nonintervention group controls. To ensure equivalence among subjects, propensity scoring was used to match study subjects from participating LTC facilities with comparison subjects from nonparticipating facilities. Residents with interventions were grouped for analysis by intervention type-retrospective only, prospective only, or dual type (residents with both prospective and retrospective interventions)-and by intervention stage-review, recommendation, and drug change-plus an all-inclusive "all types" grouping that aggregated groups by intervention type, for a total of 10 total cohorts. RESULTS: In the overall population of 5255 study subjects identified, a US \$21.63 per member per month drug-cost savings was observed. Although only 1 of 10 cohorts had a change in the number of drug fills, substantial reductions in 2 of 5 types of drug alerts were observed in all 10 cohorts. A reduction in the relative risk for hospitalization (0.84 [95\% CI, 0.71-1.00]) was observed in the cohort of residents receiving a retrospective review. CONCLUSIONS: This Initiative suggests that an MTMP can be quickly launched in a large number of LTC facility residents to produce monetary drug-cost savings and improved health outcomes. Additionally, the evaluation of this program illustrates the utility of using propensity scoring techniques to target future intervention groups in a cost-effective manner.}},
    author = {Trygstad, T. K. and Christensen, D. B. and Wegner, S. E. and Sullivan, R. and Garmise, J. M.},
    citeulike-article-id = {13870045},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.clinthera.2009.09.006},
    doi = {10.1016/j.clinthera.2009.09.006},
    isbn = {0149-2918 1879-114X},
    journal = {Clinical Therapeutics},
    keywords = {exportrecords, propensity-scores},
    number = {9},
    pages = {2018--2037},
    posted-at = {2015-12-09 01:08:16},
    priority = {3},
    title = {{Analysis of the North Carolina long-term care polypharmacy initiative: a multiple-cohort approach using propensity-score matching for both evaluation and targeting}},
    url = {http://dx.doi.org/10.1016/j.clinthera.2009.09.006},
    volume = {31},
    year = {2009}
}

@article{13517,
    abstract = {{In choosing covariates for adjustment or inclusion in propensity score analysis, researchers must weigh the benefit of reducing confounding bias carried by those covariates against the risk of amplifying residual bias carried by unmeasured confounders. The latter is characteristic of covariates that act like instrumental variables-that is, variables that are more strongly associated with the exposure than with the outcome. In this issue of the Journal (Am J Epidemiol. 2011;000(0):000-000), Myers et al. compare the bias amplification of a near-instrumental variable with its bias-reducing potential and suggest that, in practice, the latter outweighs the former. The author of this commentary sheds broader light on this comparison by considering the cumulative effects of conditioning on multiple covariates and showing that bias amplification may build up at a faster rate than bias reduction. The author further derives a partial order on sets of covariates which reveals preference for conditioning on outcome-related, rather than exposure-related, confounders.}},
    author = {Pearl, J.},
    citeulike-article-id = {13869851},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/aje/kwr352},
    comment = {Comment on:

Effects of adjusting for instrumental variables on bias and precision of effect estimates.Myers JA, Rassen JA, Gagne JJ, Huybrechts KF, Schneeweiss S, Rothman KJ, Joffe MM, Glynn RJ. Am J Epidemiol. 2011 Dec 1; 174(11):1213-22. Epub 2011 Oct 24.},
    doi = {10.1093/aje/kwr352},
    isbn = {1476-6256; 0002-9262},
    journal = {American Journal of Epidemiology},
    keywords = {exportrecords, propensity-scores, statistics},
    number = {11},
    pages = {1223--1227},
    posted-at = {2015-12-09 01:08:13},
    priority = {3},
    title = {{Invited Commentary: Understanding Bias Amplification}},
    url = {http://dx.doi.org/10.1093/aje/kwr352},
    volume = {174},
    year = {2011}
}

@article{13689,
    author = {Griswold, M. E. and Localio, A. R. and Mulrow, C.},
    citeulike-article-id = {13869822},
    citeulike-linkout-0 = {http://dx.doi.org/10.1059/0003-4819-152-6-201003160-00010},
    comment = {Comment on:

Outcomes with concurrent use of clopidogrel and proton-pump inhibitors: a cohort study.Ray WA, Murray KT, Griffin MR, Chung CP, Smalley WE, Hall K, Daugherty JR, Kaltenbach LA, Stein CM. Ann Intern Med. 2010 Mar 16; 152(6):337-45.},
    doi = {10.1059/0003-4819-152-6-201003160-00010},
    isbn = {0003-4819; 1539-3704;},
    journal = {Annals of Internal Medicine},
    keywords = {exportrecords, propensity-scores},
    number = {6},
    pages = {393--395},
    posted-at = {2015-12-09 01:08:12},
    priority = {3},
    title = {{Propensity score adjustment with multilevel data: setting your sites on decreasing selection bias}},
    url = {http://dx.doi.org/10.1059/0003-4819-152-6-201003160-00010},
    volume = {152},
    year = {2010}
}

@book{12865,
    abstract = {{This book offers readers a systematic review of the origins, history, and statistical foundations of PSM and illustrates how to use PSM methods for solving evaluation problems. TABLE OF CONTENTS: Counterfactual framework and assumptions -- Conventional methods for data balancing -- Sample selection and related models -- Propensity score matching and related models -- Matching estimators -- Propensity score analysis with nonparametric regression -- Selection bias and sensitivity analysis -- Concluding remarks.}},
    author = {Guo, S. Y. and Fraser, M. W.},
    booktitle = {Advanced quantitative techniques in the social sciences},
    citeulike-article-id = {13869678},
    comment = {Cited in:

Hempel S, Miles J, Suttorp M, Wang Z, Johnsen B, Morton S, Perry T, Valentine D, Shekelle P. Hempel S, Miles J, Suttorp M, Wang Z, Johnsen B, Morton S, Perry T, Valentine D, Shekelle P. Detection of Associations between Trial Quality and Effect Sizes. Methods Research Report. Prepared by the Southern California Evidence-based Practice Center under Contract No. 290-2007-10062-I. AHRQ Publication No. 12-EHC010-EF. Rockville, MD: Agency for Healthcare Research and Quality; January 2012.},
    isbn = {9781412953566;1412953561;},
    keywords = {exportrecords, propensity-scores},
    location = {Thousand Oaks, CA},
    pages = {370+},
    posted-at = {2015-12-09 01:08:09},
    priority = {3},
    publisher = {Sage},
    title = {{Propensity Score Analysis: Statistical Methods and Applications.}},
    year = {2010}
}

@incollection{20891,
    abstract = {{(from the chapter) This chapter aims to familiarize readers with the use of propensity score methodology to adjust estimates of treatment effects for selection bias. These comments are relevant both to the situation where there is some effort to assign or withhold treatment on a nonrandom basis and to situations where exposure to a treatment variable is only observed and not manipulated. We begin by discussing the strength and weaknesses of available bias reduction methods and contrast them with those of propensity score methodology. We then go on to introduce the logic of propensity score methods and offer a nontechnical review of the steps involved in estimating and using the propensity score to adjust estimates of treatment effects for selection bias. We conclude with some recommendations and a cautionary tale. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Yanovitzky, I. and Hornik, R. and Zanutto, E.},
    booktitle = {The Sage sourcebook of advanced data analysis methods for communication research},
    citeulike-article-id = {13869646},
    editor = {Hayes, A. F. and Slater, M. D. and Snyder, L. B.},
    isbn = {978-1-4129-2790-1;},
    keywords = {bias---selection, exportrecords, propensity-scores},
    location = {Los Angeles, CA},
    pages = {159--184},
    posted-at = {2015-12-09 01:08:09},
    priority = {3},
    publisher = {Sage},
    title = {{Estimating causal effects in observational studies: The propensity score approach.}},
    year = {2008}
}

@phdthesis{20864,
    abstract = {{There has been considerable growth in the statistics literature on methods for estimating causal effects from randomized controlled trials in which non-compliance occurs. However, the focus has been limited to all-or-none compliance. This thesis develops new methodology to estimate causal effects in a randomized trial setting in which non-compliance can be better classified as "full-partial-none" compliance and where subjects in both the experimental and control arm could receive experimental treatment to varying degrees regardless of treatment assignment. This new approach to address the problem is based on principal stratification theory. We define compliance stratification effects as a special case of principal stratification and use dual propensity scores (propensity scores estimated under both possible treatment assignments) to estimate compliance principal effects. We demonstrate that dual propensity scores have many of the attractive properties of the ordinary propensity score and that compliance stratification effects become estimable by adjusting for the estimated dual propensity scores using stratification, matching or regression. We apply our methodology to a breastfeeding promotion intervention trial and assess the causal effects of prolonged and exclusive breastfeeding on infant growth (weight or length) at one year of age. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Guo, T.},
    citeulike-article-id = {13869645},
    isbn = {978-0-494-61883-7;},
    keywords = {exportrecords, propensity-scores},
    location = {Montreal, CA},
    pages = {1--182},
    posted-at = {2015-12-09 01:08:09},
    priority = {3},
    school = {McGil University},
    title = {{Causal effects in randomized trials in the presence of partial compliance: Breastfeeding effect on infant growth}},
    year = {2009}
}

@article{20910,
    abstract = {{Many evaluations of public health education campaigns attempt to draw conclusions regarding the effect of messages on audiences' attitudes, beliefs, and behaviors based on observational data. To make causal inferences in these instances, it is necessary to adjust estimated campaign effects for possible selection bias due to systematic differences between respondents exposed to the campaign and those that were not. In particular, it is necessary to adjust for the impact of confounding variables that are likely to be determinants of both campaign exposure and outcomes. In comparison to other available methods for adjusting for selection bias such as multiple regression and instrumental variable methods, propensity scores offer a particularly simple way of adjusting estimates of campaign exposure effects for selection bias. This paper discusses the logic of this approach and illustrates its application to the evaluation of the National Youth Anti-Drug Media Campaign. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Yanovitzky, I. and Zanutto, E. and Hornik, R.},
    citeulike-article-id = {13869414},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.evalprogplan.2005.01.004},
    doi = {10.1016/j.evalprogplan.2005.01.004},
    isbn = {U13  - sent},
    journal = {Evaluation and Program Planning},
    keywords = {exportrecords, propensity-scores},
    number = {2},
    pages = {209--220},
    posted-at = {2015-12-09 01:07:12},
    priority = {3},
    title = {{Estimating causal effects of public health education campaigns using propensity score methodology}},
    url = {http://dx.doi.org/10.1016/j.evalprogplan.2005.01.004},
    volume = {28},
    year = {2005}
}

@phdthesis{20888,
    abstract = {{This dissertation research is to understand the statistical biases in estimating parameters in linear statistical models for analyzing data from observational and quasi-experimental designs directed toward estimating the effect of interventions. Some of the parameters in these models can be interpreted as measures of the intervention effect. The statistical biases affect inference one may draw about effect size, for instance. Three variable types were simulated, Type A variables were related to both outcome and treatment assignment, Type B variables were related to outcome but not treatment, while Type C variables were related to treatment but not outcome. This research examined ordinary least squares (OLS), pairwise propensity score matching (PSM), naive pairwise matching (NPM), naive triplet matching (NTM), Mahalanobis distance triplet matching, Horvitz-Thompson estimator (with and without common support enforced), and cluster analysis using Ward's method (5, 7, and 9 cluster solutions). The author undertook a comprehensive simulation to determine which estimators yielded smallest biases and under what conditions. The simulations manipulated seven factors: sample size, number of variables in the true outcome equation, the sample size in intervention groups, degree of overlap in the distributions of covariates. The fifth factor manipulated was the kind of estimator used. The sixth and seventh conditions are predicated on a true outcomes model with variables of type A,B and C . In the seventh condition variables of type B and C are left in or out of the fitted model. In the eighth condition, the importance of variables C are manipulated at three levels in the true outcome model. The overall analysis of bias suggests that OLS and PSM have no bias under these conditions with large samples. Results of this dissertation are to be expected given the model and the mathematics underlying the estimates. The most severe biases are associated with Mahalanobis Distance Triplet Matching and the Horvitz-Thompson estimator with the inverse propensity score serving as the weighting unit. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Victor, T. W.},
    citeulike-article-id = {13869413},
    isbn = {0419-4209;},
    keywords = {bias---selection, exportrecords, propensity-scores},
    location = {Philadelphia, PA},
    pages = {3 v.},
    posted-at = {2015-12-09 01:07:12},
    priority = {3},
    school = {University of Pennsylvania},
    title = {{A Monte Carlo evaluation of different ways to estimate effect sizes in quasi-experiments and observational studies}},
    year = {2007}
}

@article{20913,
    abstract = {{Causal effect modeling with naturalistic rather than experimental data is challenging. In observational studies participants in different treatment conditions may also differ on pretreatment characteristics that influence outcomes. Propensity score methods can theoretically eliminate these confounds for all observed covariates, but accurate estimation of propensity scores is impeded by large numbers of covariates, uncertain functional forms for their associations with treatment selection, and other problems. This article demonstrates that boosting, a modern statistical technique, can overcome many of these obstacles. The authors illustrate this approach with a study of adolescent probationers in substance abuse treatment programs. Propensity score weights estimated using boosting eliminate most pretreatment group differences and substantially alter the apparent relative effects of adolescent substance abuse treatment. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {McCaffrey, D. F. and Ridgeway, G. and Morral, A. R.},
    citeulike-article-id = {13869399},
    citeulike-linkout-0 = {http://dx.doi.org/10.1037/1082-989X.9.4.403},
    doi = {10.1037/1082-989X.9.4.403},
    isbn = {1082-989X; 1939-1463},
    journal = {Psychological Methods},
    keywords = {exportrecords, propensity-scores},
    number = {4},
    pages = {403--425},
    posted-at = {2015-12-09 01:07:11},
    priority = {3},
    title = {{Propensity Score Estimation With Boosted Regression for Evaluating Causal Effects in Observational Studies}},
    url = {http://dx.doi.org/10.1037/1082-989X.9.4.403},
    volume = {9},
    year = {2004}
}

@article{20909,
    abstract = {{Propensity score analysis is a relatively recent statistical innovation that is useful in the analysis of data from quasi-experiments. The goal of propensity score analysis is to balance two nonequivalent groups on observed covariates to get more accurate estimates of the effects of a treatment on which the two groups differ. This article presents a general introduction to propensity score analysis, provides an example using data from a quasi-experiment compared to a benchmark randomized experiment, offers practical advice about how to do such analyses, and discusses some limitations of the approach. It also presents the first detailed instructions to appear in the literature on how to use classification tree analysis and bagging for classification trees in the construction of propensity scores. The latter two examples serve as an introduction for researchers interested in computing propensity scores using more complex classification algorithms known as ensemble methods. (PsycINFO Database Record (c) 2013 APA, all rights reserved) (journal abstract)}},
    author = {Luellen, J. K. and Shadish, W. R. and Clark, M. H.},
    citeulike-article-id = {13869393},
    citeulike-linkout-0 = {http://dx.doi.org/10.1177/0193841X05275596},
    doi = {10.1177/0193841X05275596},
    isbn = {0193-841X; 1552-3926},
    journal = {Evaluation Review},
    keywords = {exportrecords, propensity-scores},
    number = {6},
    pages = {530--558},
    posted-at = {2015-12-09 01:07:11},
    priority = {3},
    title = {{Propensity scores: An introduction and experimental test.}},
    url = {http://dx.doi.org/10.1177/0193841X05275596},
    volume = {29},
    year = {2005}
}

@article{20904,
    abstract = {{Randomized Clinical Trials (RCTs) remain the gold standard for determining the utility of pharmaceuticals especially from a safety and efficacy standpoint. However, restrictive entry criteria and stringent protocols can be barriers to generalizing RCT findings to real world practices and outcomes. Observational studies overcome these limitations of RCTs since they are representative of real world populations and practices. Nonetheless, attributing causality remains a major limitation in observational studies, due to the non-random assignment of subjects to treatment. Non-random assignment can lead to imbalances in risk-factors between the groups being compared and thus bias the estimates of the treatment effect. Non-random assignment can be particularly problematic in observational studies comparing older versus newer pharmaceuticals from similar therapeutic classes due to the phenomenon of channeling. Channeling occurs when drug therapies with similar indications are preferentially prescribed to groups of patients with varying baseline prognoses. In this manuscript we discuss the phenomenon of channeling and the use of a statistical technique known an propensity scores analysis which potentially adjusts for the effects of channeling. During the course of this manuscript we discuss tests for determining the quality of the derived propensity score, various techniques for utilizing propensity scores, and also the potential limitations of this technique. With the increasing availability of high quality pharmaceutical and medical claims data for use in observational studies, increased attention must be given to analytic techniques that adjust optimally for non-random assignment and resulting channeling bias. For research studies using observational study designs, propensity score analysis offers a reasonable solution to address the limitation of non-random assignment, especially when RCTs are too costly, time-consuming or not ethically feasible. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Lobo, F. S. and Wagner, S. and Gross, C. R. and Schommer, J. C.},
    citeulike-article-id = {13869392},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.sapharm.2005.12.001},
    doi = {10.1016/j.sapharm.2005.12.001},
    isbn = {1551-7411;},
    journal = {Research in Social \& Administrative Pharmacy},
    keywords = {exportrecords, propensity-scores},
    number = {1},
    pages = {143--151},
    posted-at = {2015-12-09 01:07:11},
    priority = {3},
    title = {{Addressing the issue of channeling bias in observational studies with propensity scores analysis}},
    url = {http://dx.doi.org/10.1016/j.sapharm.2005.12.001},
    volume = {2},
    year = {2006}
}

@phdthesis{20899,
    abstract = {{Faced with potential selection bias resulting from nonequivalent groups, researchers employing quasi-experimental designs have become increasingly interested in statistical adjustments to the estimates of treatment effects based upon the propensity score. Propensity score analysis is the process of trying to balance nonequivalent groups by estimating each participant's conditional probability of treatment assignment using observed covariates and then using these probabilities (i.e., propensity scores) for case matching, stratification, covariance adjustment, or weighting of observations. Numerous propensity score methods have been proposed in the literature. This study used simulated data to examine the relative performance of five methods of estimating propensity scores (logistic regression, classification trees, bootstrap aggregation, boosted regression, and random forests) crossed with four types of adjustments that utilize propensity scores (matching, stratification, covariance adjustment, and weighting) at two levels of sample sizes (N = 200 and N = 1,000). One thousand Monte Carlo replicates were used per level of sample size. All combinations of propensity score methods led to at least some average reduction in selection bias, and for most combinations of methods these reductions were statistically significant. However, this seemingly promising finding is tempered by the fact that bias was actually introduced in many replicates, especially when the level of sample size was 200. The traditional approach to estimating propensity scores, logistic regression, worked well at reducing selection bias, on average, at both sample sizes and tended to result in more precise estimates of the treatment effect with less potential for introducing bias. Other combinations of propensity score methods performed better than logistic regression, on average, but with less precision in the estimates and greater potential for introducing bias. These included random forests at N = 200 and boosted regression and random forests at N = 1,000. Of the ensemble methods, boosted regression, in particular, might be a useful alternative to logistic regression for large sample sizes once the default settings have been changed to favor PSA. With regard to methods of adjusting outcomes using propensity scores, weighting tended to perform poorly. Otherwise, matching, stratification, and covariance adjustment were fairly competitive and a clear favorite was not discerned. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Luellen, J. K.},
    citeulike-article-id = {13869391},
    keywords = {bias---selection, exportrecords, propensity-scores},
    location = {Memphis, TN},
    pages = {1--199},
    posted-at = {2015-12-09 01:07:11},
    priority = {3},
    school = {University of Memphis},
    title = {{A comparison of propensity score estimation and adjustment methods on simulated data}},
    year = {2007}
}

@article{20914,
    abstract = {{In behavioral sciences, it is often difficult to execute an experimental study with random assignment. Therefore researchers usually do a quasi-experiment or a survey study without random assignment. However, under these studies the distributions of the covariates that would affect dependent variables usually differ with the values of the independent variables. To eliminate the influence of the covariates, various adjustment methods such as analysis of covariance have been applied to these data. Recently new adjustment methods using the propensity score proposed by Rosenbaum \& Rubin (1983) have been applied to many researches especially in the areas of. medicine or economics, and these methods also attract attention in behavioral sciences. The propensity score methods are also used for adjustment of survey data. In this paper, we give a detailed explanation of several estimation methods of causal effect using the propensity scores and related topics. We also review adjustment methods of biased survey data using the propensity scores. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Hoshino, T. and Shigemasu, K.},
    citeulike-article-id = {13869385},
    citeulike-linkout-0 = {http://dx.doi.org/10.2333/jbhmk.31.43},
    doi = {10.2333/jbhmk.31.43},
    issn = {0385-5481},
    journal = {Japanese Journal of Behaviormetrics},
    keywords = {exportrecords, propensity-scores},
    number = {1},
    pages = {43--61},
    posted-at = {2015-12-09 01:07:11},
    priority = {3},
    title = {{Estimation of Causal Effect and Adjustment of Survey Data using Propensity Scores}},
    url = {http://dx.doi.org/10.2333/jbhmk.31.43},
    volume = {31},
    year = {2004}
}

@article{20903,
    abstract = {{In the behavioral and social sciences, quasi-experimental and observational studies are used due to the difficulty achieving a random assignment. However, the estimation of differences between groups in observational studies frequently suffers from bias due to differences in the distributions of covariates. To estimate average treatment effects when the treatment variable is binary, Rosenbaum and Rubin (1983a) proposed adjustment methods for pretreatment variables using the propensity score. However, these studies were interested only in estimating the average causal effect and/or marginal means. In the behavioral and social sciences, a general estimation method is required to estimate parameters in multiple group structural equation modeling where the differences of covariates are adjusted. We show that a Horvitz-Thompson-type estimator, propensity score weighted M estimator (PWME) is consistent, even when we use estimated propensity scores, and the asymptotic variance of the PWME is shown to be less than that with true propensity scores. Furthermore, we show that the asymptotic distribution of the propensity score weighted statistic under a null hypothesis is a weighted sum of independent 1 variables. We show the method can compare latent variable means with covariates adjusted using propensity scores, which was not feasible by previous methods. We also apply the proposed method for correlated longitudinal binary responses with informative dropout using data from the Longitudinal Study of Aging (LSOA). The results of a simulation study indicate that the proposed estimation method is more robust than the maximum likelihood (ML) estimation method, in that PWME does not require the knowledge of the relationships among dependent variables and covariates. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Hoshino, T. and Kurata, H. and Shigemasu, K.},
    citeulike-article-id = {13869384},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s11336-005-1370-2},
    doi = {10.1007/s11336-005-1370-2},
    isbn = {U13  - sent},
    journal = {Psychometrika},
    keywords = {exportrecords, propensity-scores},
    number = {4},
    pages = {691--712},
    posted-at = {2015-12-09 01:07:11},
    priority = {3},
    title = {{A propensity score adjustment for multiple group structural equation modeling}},
    url = {http://dx.doi.org/10.1007/s11336-005-1370-2},
    volume = {71},
    year = {2006}
}

@article{20902,
    abstract = {{This study proposes the adoption of a neural network as an alternative to logistic regression analysis, which is conventionally used to estimate the propensity score (Rosenbaum \& Rubin, 1983). Moreover, covariates that are frequently obscured are presented. Considering the response pattern to a mail survey by random sampling as a criterion, we examined how is the response pattern to a Web survey by purposive selection rectified using the propensity score. The propensity score was estimated using the subjects' demographic variables as covariates. The results of adopting a neural network were compared with those of the logistic regression analysis. As a result, the accuracy of bias reduction by the threelayer neural networks was found to be greater than that by the logistic regression analysis. In addition, detailed contents of the covariates were presented, and a decision tree was produced to examine the influence of covariates on allocation of the subjects to survey forms. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Hideki, T. and Ikko, K. and Kentaro, N. and Hotaka, K.},
    citeulike-article-id = {13869383},
    citeulike-linkout-0 = {http://dx.doi.org/10.2333/jbhmk.34.101},
    doi = {10.2333/jbhmk.34.101},
    isbn = {0385-5481;},
    journal = {Japanese Journal of Behaviormetrics},
    keywords = {exportrecords, propensity-scores},
    number = {1},
    pages = {101--110},
    posted-at = {2015-12-09 01:07:11},
    priority = {3},
    title = {{An adjustment of survey data using propensity score weighting: An estimation of the propensity score by a neural network}},
    url = {http://dx.doi.org/10.2333/jbhmk.34.101},
    volume = {34},
    year = {2007}
}

@article{20901,
    abstract = {{This paper builds upon two prior papers by Haviland and Nagin (Psychometrika 70:1-22, 2005) and Haviland, Nagin, and Rosenbaum (Working paper, 2006) that attempt to bring the key attributes of an experiment to the analysis of non-experimental longitudinal data. Using a case study of the facilitation effect of gang membership on violence, it systematically examines the contribution of group-based trajectory modeling to the achievement of covariate balance in observational data. In this case study, inclusion of the posterior probabilities of group membership (PPGM), from a model on the pre-treatment measures of the outcome variable, created closer balance on these key covariates than did analyses that did not include them. Still closer balance was obtained on these key covariates by stratifying the analysis by trajectory group. This stratification was achieved by fitting separate propensity score models and matching gang joiners to gang abstainers within trajectory group. In addition, we demonstrated that further balance could be obtained on additional covariates by including PPGM from a model on pre-treatment longitudinal data of these covariates. While this case study is only one empirical example, we believe that it provides useful empirical evidence on the value of performing within trajectory group causal inference in observational longitudinal data and on the use of the PPGM in achieving balance in propensity score-based causal inference. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Haviland, A. M. and Nagin, D. S.},
    citeulike-article-id = {13869382},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s11292-007-9023-3},
    doi = {10.1007/s11292-007-9023-3},
    isbn = {U13  - sent},
    journal = {Journal of Experimental Criminology},
    keywords = {exportrecords, propensity-scores},
    number = {1},
    pages = {65--82},
    posted-at = {2015-12-09 01:07:11},
    priority = {3},
    title = {{Using group-based trajectory modeling in conjunction with propensity scores to improve balance}},
    url = {http://dx.doi.org/10.1007/s11292-007-9023-3},
    volume = {3},
    year = {2007}
}

@article{20900,
    abstract = {{In a nonrandomized or observational study, propensity scores may be used to balance observed covariates and trajectory groups may be used to control baseline or pretreatment measures of outcome. The trajectory groups also aid in characterizing classes of subjects for whom no good matches are available and to define substantively interesting groups between which treatment effects may vary. These and related methods are illustrated using data from a Montreal-based study. The effects on subsequent violence of gang joining at age 14 are studied while controlling for measured characteristics of boys prior to age 14. The boys are divided into trajectory groups based on violence from ages 11 to 13. Within trajectory group, joiners are optimally matched to a variable number of controls using propensity scores, Mahalanobis distances, and a combinatorial optimization algorithm. Use of variable ratio matching results in greater efficiency than pair matching and also greater bias reduction than matching at a fixed ratio. The possible impact of failing to adjust for an important but unmeasured covariate is examined using sensitivity analysis. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Haviland, A. and Nagin, D. S. and Rosenbaum, P. R.},
    citeulike-article-id = {13869381},
    citeulike-linkout-0 = {http://dx.doi.org/10.1037/1082-989X.12.3.247},
    doi = {10.1037/1082-989X.12.3.247},
    isbn = {1082-989X; 1939-1463},
    journal = {Psychological Methods},
    keywords = {exportrecords, propensity-scores},
    number = {3},
    pages = {247--267},
    posted-at = {2015-12-09 01:07:11},
    priority = {3},
    title = {{Combining propensity score matching and group-based trajectory analysis in an observational study.}},
    url = {http://dx.doi.org/10.1037/1082-989X.12.3.247},
    volume = {12},
    year = {2007}
}

@article{20898,
    abstract = {{Due to the difficulty in achieving a random assignment, a quasi-experimental or observational study design is frequently used in the behavioral and social sciences. If a nonrandom assignment depends on the covariates, multiple group structural equation modeling, that includes the regression function of the dependent variables on the covariates that determine the assignment, can provide reasonable estimates under the condition of correct specification of the regression function. However, it is usually difficult to specify the correct regression function because the dimensions of the dependent variables and covariates are typically large. Therefore, the propensity score adjustment methods have been proposed, since they do not require the specification of the regression function and have been applied to several applied studies. However, these methods produce biased estimates if the assignment mechanism is incorrectly specified. In order to make a more robust inference, it would be more useful to develop an estimation method that integrates the regression approach with the propensity score methodology. In this study we propose a doubly robust-type estimation method for marginal multiple group structural equation modeling. This method provides a consistent estimator if either the regression function or the assignment mechanism is correctly specified. A simulation study indicates that the proposed estimation method is more robust than the existing methods. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Hoshino, T.},
    citeulike-article-id = {13869380},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s11336-007-9007-2},
    doi = {10.1007/s11336-007-9007-2},
    isbn = {U13  - sent},
    journal = {Psychometrika},
    keywords = {exportrecords, propensity-scores},
    number = {4},
    pages = {535--549},
    posted-at = {2015-12-09 01:07:11},
    priority = {3},
    title = {{Doubly robust-type estimation for covariate adjustment in latent variable modeling}},
    url = {http://dx.doi.org/10.1007/s11336-007-9007-2},
    volume = {72},
    year = {2007}
}

@article{20885,
    abstract = {{Prospective observational studies, which provide information on the effectiveness of interventions in natural settings, may complement results from randomised clinical trials in the evaluation of health technologies. However, observational studies are subject to a number of potential methodological weaknesses, mainly selection and observer bias. This paper reviews and applies various methods to control for selection bias in the estimation of treatment effects and proposes novel ways to assess the presence of observer bias. We also address the issues of estimation and inference in a multilevel setting. We describe and compare the use of regression methods, propensity score matching, fixed-effects models incorporating investigator characteristics, and a multilevel, hierarchical model using Bayesian estimation techniques in the control of selection bias. We also propose to assess the existence of observer bias in observational studies by comparing patient- and investigator-reported outcomes. To illustrate these methods, we have used data from the SOHO (Schizophrenia Outpatient Health Outcomes) study, a large, prospective, observational study of health outcomes associated with the treatment of schizophrenia. The methods used to adjust for differences between treatment groups that could cause selection bias yielded comparable results, reinforcing the validity of the findings. Also, the assessment of observer bias did not show that it existed in the SOHO study. Observational studies, when properly conducted and when using adequate statistical methods, can provide valid information on the evaluation of health technologies. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Haro, J. M. and Kontodimas, S. and Negr\'{\i}n, M. A. and Ratcliffe, M. and Suarez, D. and Windmeijer, F.},
    citeulike-article-id = {13869379},
    citeulike-linkout-0 = {http://dx.doi.org/10.2165/00148365-200605010-00003},
    doi = {10.2165/00148365-200605010-00003},
    isbn = {1175-5652; 1179-1896},
    journal = {Applied Health Economics and Health Policy},
    keywords = {bias---selection, exportrecords, propensity-scores},
    number = {1},
    pages = {11--25},
    posted-at = {2015-12-09 01:07:11},
    priority = {3},
    title = {{Methodological Aspects in the Assessment of Treatment Effects in Observational Health Outcomes Studies.}},
    url = {http://dx.doi.org/10.2165/00148365-200605010-00003},
    volume = {5},
    year = {2006}
}

@article{20906,
    abstract = {{Propensity score analysis is one statistical technique that can be applied to observational data to mimic randomization and thus can be used to estimate causal effects in studies in which the researchers have not applied randomization. In this article the authors (a) describe propensity score methodology and (b) demonstrate its application using elementary student data from the Early Childhood Longitudinal Study-Kindergarten Class of 1998-99 (ECLS-K). The authors also discuss methodological considerations that need to be addressed when using data from complex samples as in this analysis. Furthermore, the authors provide a tutorial that can be used by researchers to understand the methodology behind and to emulate the steps of conducting propensity score analysis. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {HahsVaughn, D. L. and Onwuegbuzie, A. J.},
    citeulike-article-id = {13869364},
    citeulike-linkout-0 = {http://dx.doi.org/10.3200/JEXE.75.1.31-65},
    doi = {10.3200/JEXE.75.1.31-65},
    isbn = {0022-0973; 1940-0683},
    journal = {Journal of Experimental Education},
    keywords = {bias---selection, complex-multicomponent-interventions, exportrecords, propensity-scores},
    number = {1},
    pages = {31--65},
    posted-at = {2015-12-09 01:07:11},
    priority = {3},
    title = {{Estimating and Using Propensity Score Analysis with Complex Samples}},
    url = {http://dx.doi.org/10.3200/JEXE.75.1.31-65},
    volume = {75},
    year = {2006}
}

@article{23993,
    abstract = {{While different design features of medical studies ostensibly serve different functions, many fall under the umbrella of methods aimed at ensuring the comparability of the comparison groups. Randomization rightly occupies the top spot in the hierarchy of design types, as it eliminates some biases (that is, systematic differences in comparison groups) that no other design can claim to eliminate. It is often assumed, and sometimes even asserted explicitly, that randomization by itself suffices to ensure that the comparison groups are sufficiently comparable that they would differ only randomly, but two points need to be made in this context. First, the assertion is not true. Second, even if it were true, it would still not be a cause for complacency, because even random baseline imbalances can wreck havoc on the valid interpretation of randomized clinical trials. Additional methods, beyond randomization, are therefore seen to be essential to the design of a good randomized clinical trial. Such methods include masking, allocation concealment, restrictions on the randomization, adjustment for prognostic variables, and the intent-to-treat approach to data analysis. Masking aims to ensure that those individuals in any one group formed by randomization are treated as similarly as possible subsequent to randomization as those in any other group formed by randomization. In contrast, allocation concealment and restricted randomization aim to create groups that start off as comparable. Adjustment for prognostic variables aims to change the comparison groups themselves to make them comparable. For example, one might find gender to be both predictive of outcome and unbalanced across treatment groups, and so one would compare the treatment groups not overall but rather first only among females and second only among males. The intent-to-treat approach aims to keep similar groups similar by not allowing for patient selection based on post-randomization outcomes (including failure to comply with the protocol). The key to understanding masking, allocation concealment, and randomization is to recognize that none of them are binary phenomena, even though they are often incorrectly understood to be. So one must question how these methods are actually carried out, rather than contenting oneself with the vague statement that these methods were performed. This review will shed light on the distinction between the process and the outcome of each of these methods (masking, allocation concealment, and randomization), and will also consider issues related to adjustment for prognostic covariates.}},
    author = {Berger, V. W.},
    citeulike-article-id = {13869258},
    citeulike-linkout-0 = {http://dx.doi.org/10.2174/157488706775246139},
    doi = {10.2174/157488706775246139},
    issn = {1574-8871},
    journal = {Reviews on recent clinical trials},
    keywords = {allocation-concealment, exportrecords, intention-to-treat-analysis, propensity-scores, randomization},
    number = {1},
    pages = {81--86},
    posted-at = {2015-12-09 01:07:09},
    priority = {3},
    title = {{A review of methods for ensuring the comparability of comparison groups in randomized clinical trials}},
    url = {http://dx.doi.org/10.2174/157488706775246139},
    volume = {1},
    year = {2006}
}

@article{17762,
    abstract = {{PURPOSE: To document which established criteria for logistic regression modeling researchers consider when using propensity scores in observational studies. METHODS: We performed a systematic review searching Medline and Science Citation to identify observational studies published in 2001 that addressed clinical questions using propensity score methods to adjust for treatment assignment. We abstracted aspects of propensity score model development (e.g. variable selection criteria, continuous variables included in correct functional form, interaction inclusion criteria), model discrimination and goodness of fit for 47 studies meeting inclusion criteria. RESULTS: We found few studies reporting on the propensity score model development or evaluation of model fit. CONCLUSIONS: Reporting of aspects related to propensity score model development is limited and raises questions about the value of these principles in developing propensity scores from which unbiased treatment effects are estimated. Copyright 2004 John Wiley \& Sons, Ltd.}},
    author = {Weitzen, S. and Lapane, K. L. and Toledano, A. Y. and Hume, A. L. and Mor, V.},
    citeulike-article-id = {13869237},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.969},
    doi = {10.1002/pds.969},
    isbn = {1053-8569 ;1099-1557},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {exportrecords, observational-study---methods, propensity-scores, reporting},
    number = {12},
    pages = {841--853},
    posted-at = {2015-12-09 01:07:08},
    priority = {3},
    title = {{Principles for modeling propensity scores in medical research: a systematic literature review}},
    url = {http://dx.doi.org/10.1002/pds.969},
    volume = {13},
    year = {2004}
}

@proceedings{17821,
    abstract = {{Background: Both PSC and MI can be used to adjust main study estimates for unmeasured confounding if additional information on confounders is available from a validation study. PSC does not rely on outcome data in the validation study but assumes that the error-prone propensity score (PSEP) based on the covariates measured in the main study is a surrogate for the gold-standard PSGS, i.e. that the unmeasured confounding goes in the same direction as the measured one. MI does not rely on surrogacy, but on outcome data in the validation study. Objectives: To compare the performance of PSC and MI to control for unmeasured confounding in the main study using data from a validation study. Methods: We simulated 1 000 cohort studies each with a binary exposure E and outcome Y, and three independent standard normal confounders, of which one (C) is only observed in a validation sample, varying parameter values over a wide range. We implemented PSC as single imputation of the expected value of PSGS based on a linear regression model in the validation study with PSGS (estimated including C) as dependent and PSEP (estimated without C) and E as independent variables. Unexposed observations were matched to exposed ones on the imputed PSGS. Confidence bounds were boostrapped. MI was implemented based on a linear regression model fitted in the validation study with C as dependent and the measured covariates, E, and Yas independent variables. C was then imputed 5 times based on the posterior distribution of the parameter estimates. Results: PSC results depend largely on the adequacy of the surrogacy assumption. If surrogacy holds, PSC leads to bias reduction between 74 and 106 percent (>100\% representing}},
    author = {St\"{u}rmer, T. and Schneeweiss, S. and Rothman, K. J. and Avorn, J. and Glynn, R. J.},
    booktitle = {22nd International Conference on Pharmacoepidemiology \& Therapeutic Risk Management},
    citeulike-article-id = {13869225},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.1295},
    doi = {10.1002/pds.1295},
    isbn = {1053-8569; 1099-1557},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {bias---selection, confounding, exportrecords, propensity-scores},
    location = {Lisbon, Portugal},
    number = {Suppl 1},
    pages = {S39+},
    posted-at = {2015-12-09 01:07:08},
    priority = {3},
    title = {{Comparison of performance of propensity score calibration (PSC) and multiple imputation (MI) to control for unmeasured confounding using an internal validation study}},
    url = {http://dx.doi.org/10.1002/pds.1295},
    volume = {15},
    year = {2006}
}

@article{17789,
    abstract = {{OBJECTIVE: To determine whether adjusting for confounder bias in observational studies using propensity scores gives different results than using traditional regression modeling. METHODS: Medline and Embase were used to identify studies that described at least one association between an exposure and an outcome using both traditional regression and propensity score methods to control for confounding. From 43 studies, 78 exposure-outcome associations were found. Measures of the quality of propensity score implementation were determined. The statistical significance of each association using both analytical methods was compared. The odds or hazard ratios derived using both methods were compared quantitatively. RESULTS: Statistical significance differed between regression and propensity score methods for only 8 of the associations (10\%), kappa = 0.79 (95\% CI = 0.65-0.92). In all cases, the regression method gave a statistically significant association not observed with the propensity score method. The odds or hazard ratio derived using propensity scores was, on average, 6.4\% closer to unity than that derived using traditional regression. CONCLUSIONS: Observational studies had similar results whether using traditional regression or propensity scores to adjust for confounding. Propensity scores gave slightly weaker associations; however, many of the reviewed studies did not implement propensity scores well.}},
    author = {Shah, B. R. and Laupacis, A. and Hux, J. E. and Austin, P. C.},
    citeulike-article-id = {13869221},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2004.10.016},
    doi = {10.1016/j.jclinepi.2004.10.016},
    isbn = {1878-5921 0895-4356},
    journal = {Journal of clinical epidemiology},
    keywords = {bias---general, exportrecords, propensity-scores},
    number = {6},
    pages = {550--9},
    posted-at = {2015-12-09 01:07:08},
    priority = {3},
    title = {{Propensity score methods gave similar results to traditional regression modeling in observational studies: a systematic review.}},
    url = {http://dx.doi.org/10.1016/j.jclinepi.2004.10.016},
    volume = {58},
    year = {2005}
}

@article{17829,
    abstract = {{BACKGROUND: Large health care utilization databases are frequently used to analyze unintended effects of prescription drugs and biologics. Confounders that require detailed information on clinical parameters, lifestyle, or over-the-counter medications are often not measured in such datasets, causing residual confounding bias. OBJECTIVE: This paper provides a systematic approach to sensitivity analyses to investigate the impact of residual confounding in pharmacoepidemiologic studies that use health care utilization databases. METHODS: Four basic approaches to sensitivity analysis were identified: (1) sensitivity analyses based on an array of informed assumptions; (2) analyses to identify the strength of residual confounding that would be necessary to explain an observed drug-outcome association; (3) external adjustment of a drug-outcome association given additional information on single binary confounders from survey data using algebraic solutions; (4) external adjustment considering the joint distribution of multiple confounders of any distribution from external sources of information using propensity score calibration. CONCLUSION: Sensitivity analyses and external adjustments can improve our understanding of the effects of drugs and biologics in epidemiologic database studies. With the availability of easy-to-apply techniques, sensitivity analyses should be used more frequently, substituting qualitative discussions of residual confounding.}},
    author = {Schneeweiss, S.},
    citeulike-article-id = {13869209},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.1200},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Miscellaneous Papers]},
    doi = {10.1002/pds.1200},
    isbn = {1053-8569; 1099-1557},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {confounding, exportrecords, propensity-scores, sensitivity-analysis},
    number = {5},
    pages = {291--303},
    posted-at = {2015-12-09 01:07:08},
    priority = {3},
    title = {{Sensitivity analysis and external adjustment for unmeasured confounders in epidemiologic database studies of therapeutics.}},
    url = {http://dx.doi.org/10.1002/pds.1200},
    volume = {15},
    year = {2006}
}

@article{17385,
    abstract = {{BACKGROUND: Confounding by indication is a common problem in pharmacoepidemiology, where predictors of treatment also have prognostic value for the outcome of interest. The tools available to the epidemiologist that can be used to mitigate the effects of confounding by indication often have limits with respect to the number of variables that can be simultaneously incorporated as components of the confounding. This constraint becomes particularly apparent in the context of a rich data source (such as administrative claims data), applied to the study of an outcome that occurs infrequently. In such settings, there will typically be many more variables available for control as potential confounders than traditional epidemiologic techniques will allow. METHODS: One tool that can indirectly permit control of a large number of variables is the propensity score approach. This paper illustrates the application of the propensity score to a study conducted in an administrative database, and raises critical issues to be addressed in such an analysis. In this example, the effect of statin therapy on the occurrence of myocardial infarction was examined, and numerous potential confounders of this association were adjusted simultaneously using a propensity score to form matched cohorts of statin initiators and non-initiators. RESULTS: The incidence of myocardial infarction observed in the statin treated cohort was lower than the incidence in the untreated cohort, and the magnitude of this effect was consistent with results from randomized placebo controlled clinical trials of statin therapy. CONCLUSIONS: This example illustrates how confounding by indication can be mitigated by the propensity score matching technique. Concerns remain over the generalizability of estimates obtained from such a study, and how to know when propensity scores are removing bias, since apparent balance between compared groups on measured variables could leave variables not included in the propensity score unbalanced and lead to confounded effect estimates. Copyright 2005 John Wiley \& Sons, Ltd.}},
    author = {Seeger, J. D. and Williams, P. L. and Walker, A. M.},
    citeulike-article-id = {13869161},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.1062},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Clinical Papers]},
    doi = {10.1002/pds.1062},
    isbn = {1053-8569; 1099-1557},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {data---administrative-billing, exportrecords, propensity-scores},
    number = {7},
    pages = {465--476},
    posted-at = {2015-12-09 01:07:07},
    priority = {3},
    title = {{An application of propensity score matching using claims data}},
    url = {http://dx.doi.org/10.1002/pds.1062},
    volume = {14},
    year = {2005}
}

@article{17384,
    abstract = {{PURPOSE: To compare the relative risks of upper GI haemorrhage (UGIH) in users of Newer versus Older, non-specific NSAIDs when adjusted for channelling bias by regression on individual covariates, a propensity score and both. METHODS: Cohort study of patients prescribed NSAIDs between June 1987 and January 2000. Exposure to Newer and Older non-specific NSAIDs was identified, and risk factors evaluated for each patient. Results of multiple covariate analyses and the propensity scoring technique to assess potential channelling bias in comparisons between Newer and Older non-specific NSAIDs were compared. RESULTS: This study included 7.1 thousand patient years (tpy) exposure to meloxicam, 1.6 tpy exposure to coxibs, and 628 tpy exposure to Older non-specific NSAIDs. Patients receiving Newer NSAIDs were older, more likely to have a history of GI symptoms, and at higher risk for GI complications. Adjusting for these risk factors reduced the relative risks of UGIH on meloxicam and coxibs versus Older non-specific NSAIDs to 0.84 (95\%CI 0.60, 1.17) and 0.36 (0.14, 0.97) respectively. CONCLUSIONS: Channelling towards high GI risk patients occurred in the prescribing of Newer NSAIDs. Propensity scores highlighted the markedly different risk profiles of users of Newer and Older non-specific NSAID. Correcting for channelling bias, coxib exposure, but not meloxicam exposure, was associated with less UGIH than Older non-specific NSAID exposure. In the present study, corrections made by regression on a propensity score and on individual covariates were similar. Copyright 2004 John Wiley \& Sons, Ltd.}},
    author = {Morant, S. V. and Pettitt, D. and MacDonald, T. M. and Burke, T. A. and Goldstein, J. L.},
    citeulike-article-id = {13869151},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.946},
    doi = {10.1002/pds.946},
    isbn = {1053-8569 1099-1557},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {exportrecords, propensity-scores},
    number = {6},
    pages = {345--53},
    posted-at = {2015-12-09 01:07:07},
    priority = {3},
    title = {{Application of a propensity score to adjust for channelling bias with NSAIDs}},
    url = {http://dx.doi.org/10.1002/pds.946},
    volume = {13},
    year = {2004}
}

@article{17342,
    abstract = {{OBJECTIVE: I conducted a systematic review of the use of propensity score matching in the cardiovascular surgery literature. I examined the adequacy of reporting and whether appropriate statistical methods were used. METHODS: I examined 60 articles published in the Annals of Thoracic Surgery, European Journal of Cardio-thoracic Surgery, Journal of Cardiovascular Surgery, and the Journal of Thoracic and Cardiovascular Surgery between January 1, 2004, and December 31, 2006. RESULTS: Thirty-one of the 60 studies did not provide adequate information on how the propensity score-matched pairs were formed. Eleven (18\%) of studies did not report on whether matching on the propensity score balanced baseline characteristics between treated and untreated subjects in the matched sample. No studies used appropriate methods to compare baseline characteristics between treated and untreated subjects in the propensity score-matched sample. Eight (13\%) of the 60 studies explicitly used statistical methods appropriate for the analysis of matched data when estimating the effect of treatment on the outcomes. Two studies used appropriate methods for some outcomes, but not for all outcomes. Thirty-nine (65\%) studies explicitly used statistical methods that were inappropriate for matched-pairs data when estimating the effect of treatment on outcomes. Eleven studies did not report the statistical tests that were used to assess the statistical significance of the treatment effect. CONCLUSIONS: Analysis of propensity score-matched samples tended to be poor in the cardiovascular surgery literature. Most statistical analyses ignored the matched nature of the sample. I provide suggestions for improving the reporting and analysis of studies that use propensity score matching.}},
    author = {Austin, P. C.},
    citeulike-article-id = {13869098},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jtcvs.2007.07.021},
    doi = {10.1016/j.jtcvs.2007.07.021},
    isbn = {0022-5223; 1097-685X;},
    journal = {Journal of Thoracic and Cardiovascular Surgery},
    keywords = {exportrecords, propensity-scores},
    number = {5},
    pages = {1128--1135},
    posted-at = {2015-12-09 01:07:05},
    priority = {3},
    title = {{Propensity-score matching in the cardiovascular surgery literature from 2004 to 2006: A systematic review and suggestions for improvement.}},
    url = {http://dx.doi.org/10.1016/j.jtcvs.2007.07.021},
    volume = {134},
    year = {2007}
}

@article{16772,
    abstract = {{There is an increasing interest in the use of propensity score methods to estimate causal effects in observational studies. However, recent systematic reviews have demonstrated that propensity score methods are inconsistently used and frequently poorly applied in the medical literature. In this study, we compared the following propensity score methods for estimating the reduction in all-cause mortality due to statin therapy for patients hospitalized with acute myocardial infarction: propensity-score matching, stratification using the propensity score, covariate adjustment using the propensity score, and weighting using the propensity score. We used propensity score methods to estimate both adjusted treated effects and the absolute and relative risk reduction in all-cause mortality. We also examined the use of statistical hypothesis testing, standardized differences, box plots, non-parametric density estimates, and quantile-quantile plots to assess residual confounding that remained after stratification or matching on the propensity score. Estimates of the absolute reduction in 3-year mortality ranged from 2.1 to 4.5 per cent, while estimates of the relative risk reduction ranged from 13.3 to 17.0 per cent. Adjusted estimates of the reduction in the odds of 3-year death varied from 15 to 24 per cent across the different propensity score methods.}},
    author = {Austin, P. C. and Mamdani, M. M.},
    citeulike-article-id = {13869090},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.2328},
    doi = {10.1002/sim.2328},
    issn = {0277-6715},
    journal = {Statistics in Medicine},
    keywords = {exportrecords, propensity-scores},
    number = {12},
    pages = {2084--2106},
    posted-at = {2015-12-09 01:07:05},
    priority = {3},
    title = {{A comparison of propensity score methods: a case-study estimating the effectiveness of post-AMI statin use}},
    url = {http://dx.doi.org/10.1002/sim.2328},
    volume = {25},
    year = {2006}
}

@article{16757,
    abstract = {{The propensity score which is the probability of exposure to a specific treatment conditional on observed variables. Conditioning on the propensity score results in unbiased estimation of the expected difference in observed responses to two treatments. In the medical literature, propensity score methods are frequently used for estimating odds ratios. The performance of propensity score methods for estimating marginal odds ratios has not been studied. We performed a series of Monte Carlo simulations to assess the performance of propensity score matching, stratifying on the propensity score, and covariate adjustment using the propensity score to estimate marginal odds ratios. We assessed bias, precision, and mean-squared error (MSE) of the propensity score estimators, in addition to the proportion of bias eliminated due to conditioning on the propensity score. When the true marginal odds ratio was one, then matching on the propensity score and covariate adjustment using the propensity score resulted in unbiased estimation of the true treatment effect, whereas stratification on the propensity score resulted in minor bias in estimating the true marginal odds ratio. When the true marginal odds ratio ranged from 2 to 10, then matching on the propensity score resulted in the least bias, with a relative biases ranging from 2.3 to 13.3 per cent. Stratifying on the propensity score resulted in moderate bias, with relative biases ranging from 15.8 to 59.2 per cent. For both methods, relative bias was proportional to the true odds ratio. Finally, matching on the propensity score tended to result in estimators with the lowest MSE.}},
    author = {Austin, P. C.},
    citeulike-article-id = {13869089},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.2781},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Methods Papers]},
    doi = {10.1002/sim.2781},
    issn = {0277-6715},
    journal = {Statistics in Medicine},
    keywords = {exportrecords, propensity-scores},
    number = {16},
    pages = {3078--3094},
    posted-at = {2015-12-09 01:07:05},
    priority = {3},
    title = {{The performance of different propensity score methods for estimating marginal odds ratios}},
    url = {http://dx.doi.org/10.1002/sim.2781},
    volume = {26},
    year = {2007}
}

@article{16753,
    abstract = {{Propensity score methods are increasingly being used to estimate causal treatment effects in the medical literature. Conditioning on the propensity score results in unbiased estimation of the expected difference in observed responses to two treatments. The degree to which conditioning on the propensity score introduces bias into the estimation of the conditional odds ratio or conditional hazard ratio, which are frequently used as measures of treatment effect in observational studies, has not been extensively studied. We conducted Monte Carlo simulations to determine the degree to which propensity score matching, stratification on the quintiles of the propensity score, and covariate adjustment using the propensity score result in biased estimation of conditional odds ratios, hazard ratios, and rate ratios. We found that conditioning on the propensity score resulted in biased estimation of the true conditional odds ratio and the true conditional hazard ratio. In all scenarios examined, treatment effects were biased towards the null treatment effect. However, conditioning on the propensity score did not result in biased estimation of the true conditional rate ratio. In contrast, conventional regression methods allowed unbiased estimation of the true conditional treatment effect when all variables associated with the outcome were included in the regression model. The observed bias in propensity score methods is due to the fact that regression models allow one to estimate conditional treatment effects, whereas propensity score methods allow one to estimate marginal treatment effects. In several settings with non-linear treatment effects, marginal and conditional treatment effects do not coincide.}},
    author = {Austin, P. C. and Grootendorst, P. and Normand, S. L. and Anderson, G. M.},
    citeulike-article-id = {13869088},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.2618},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Methods Papers]},
    doi = {10.1002/sim.2618},
    issn = {0277-6715},
    journal = {Statistics in Medicine},
    keywords = {bias---general, exportrecords, propensity-scores},
    number = {4},
    pages = {754--768},
    posted-at = {2015-12-09 01:07:05},
    priority = {3},
    title = {{Conditioning on the propensity score can result in biased estimation of common measures of treatment effect: a Monte Carlo study.}},
    url = {http://dx.doi.org/10.1002/sim.2618},
    volume = {26},
    year = {2007}
}

@article{16250,
    abstract = {{BACKGROUND: Non-experimental studies of drug effects in large automated databases can provide timely assessment of real-life drug use, but are prone to confounding by variables that are not contained in these databases and thus cannot be controlled. OBJECTIVES: To describe how information on additional confounders from validation studies can help address the problem of unmeasured confounding in the main study. RESEARCH DESIGN: Review types of validation studies that allow adjustment for unmeasured confounding and illustrate these with an example. SUBJECTS: Main study: New Jersey residents age 65 years or older hospitalized between 1995 and 1997, who filled prescriptions within Medicaid or a pharmaceutical assistance program. Validation study: representative sample of Medicare beneficiaries. MEASURES: Association between nonsteroidal antiinflammatory drugs (NSAIDs) and mortality. RESULTS: Validation studies are categorized as internal (ie, additional information is collected on participants of the main study) or external. Availability of information on disease outcome will affect choice of analytic strategies. Using an external validation study without data on disease outcome to adjust for unmeasured confounding, propensity score calibration (PSC) leads to a plausible estimate of the association between NSAIDs and mortality in the elderly, if the biases caused by measured and unmeasured confounders go in the same direction. CONCLUSIONS: Estimates of drug effects can be adjusted for confounders that are not available in the main, but can be measured in a validation study. PSC uses validation data without information on disease outcome under a strong assumption. The collection and integration of validation data in pharmacoepidemiology should be encouraged.}},
    author = {St\"{u}rmer, T. and Glynn, R. J. and Rothman, K. J. and Avorn, J. and Schneeweiss, S.},
    citeulike-article-id = {13869070},
    citeulike-linkout-0 = {http://dx.doi.org/10.1097/MLR.0b013e318070c045},
    doi = {10.1097/MLR.0b013e318070c045},
    isbn = {1537-1948; 0025-7079;},
    journal = {Medical Care},
    keywords = {confounding, data---clinical, exportrecords, propensity-scores},
    number = {10 Suppl 2},
    pages = {S158--S165},
    posted-at = {2015-12-09 01:07:05},
    priority = {3},
    title = {{Adjustments for unmeasured confounders in pharmacoepidemiologic database studies using external information.}},
    url = {http://dx.doi.org/10.1097/MLR.0b013e318070c045},
    volume = {45},
    year = {2007}
}

@article{16213,
    abstract = {{BACKGROUND: When using observational data to compare the effectiveness of medications, it is essential to account parsimoniously for patients' longitudinal characteristics that lead to changes in treatments over time. OBJECTIVES: We developed a method of estimating effects of longitudinal treatments that uses subclassification on a longitudinal propensity score to compare outcomes between a new drug (exenatide) and established drugs (insulin and oral medications) assuming knowledge of the variables influencing the treatment assignment. RESEARCH DESIGN/SUBJECTS: We assembled a retrospective cohort of patients with diabetes mellitus from among a population of employed persons and their dependents. METHODS: The data, from i3Innovus, includes claims for utilization of medications and inpatient and outpatient services. We estimated a model for the longitudinal propensity score process of receiving a medication of interest. We used our methods to estimate the effect of the new versus established drugs on total health care charges and hospitalization. RESULTS: We had data from 131,714 patients with diabetes filling prescriptions from June through December 2005. Within propensity score quintiles, the explanatory covariates were well-balanced. We estimated that the total health care charges per month that would have occurred if all patients had been continually on exenatide compared with if the same patients had been on insulin were minimally higher, with a mean monthly difference of \$397 [95\% confidence interval (CI), \$218-\$1054]. The odds of hospitalization were also comparable (relative odds, 1.02; 95\% CI, 0.33-1.98). CONCLUSIONS: We used subclassification of a longitudinal propensity score for reducing the multidimensionality of observational data, including treatments changing over time. In our example, evaluating a new diabetes drug, there were no demonstrable differences in outcomes relative to existing therapies.}},
    author = {Segal, J. B. and Griswold, M. and Achy-Brou, A. and Herbert, R. and Bass, E. B. and Dy, S. M. and Millman, A. E. and Wu, A. W. and Frangakis, C. E.},
    citeulike-article-id = {13869067},
    citeulike-linkout-0 = {http://dx.doi.org/10.1097/MLR.0b013e31804ffd6d},
    doi = {10.1097/MLR.0b013e31804ffd6d},
    isbn = {1537-1948; 0025-7079},
    journal = {Medical Care},
    keywords = {exportrecords, longitudinal-study---methods, propensity-scores},
    number = {10 Suppl 2},
    pages = {S149--S157},
    posted-at = {2015-12-09 01:07:05},
    priority = {3},
    title = {{Using Propensity Scores Subclassification to Estimate Effects of Longitudinal Treatments: An Example Using a New Diabetes Medication}},
    url = {http://dx.doi.org/10.1097/MLR.0b013e31804ffd6d},
    volume = {45},
    year = {2007}
}

@article{16023,
    abstract = {{CONTEXT: Comparisons of outcomes between patients treated and untreated in observational studies may be biased due to differences in patient prognosis between groups, often because of unobserved treatment selection biases. OBJECTIVE: To compare 4 analytic methods for removing the effects of selection bias in observational studies: multivariable model risk adjustment, propensity score risk adjustment, propensity-based matching, and instrumental variable analysis. DESIGN, SETTING, AND PATIENTS: A national cohort of 122,124 patients who were elderly (aged 65-84 years), receiving Medicare, and hospitalized with acute myocardial infarction (AMI) in 1994-1995, and who were eligible for cardiac catheterization. Baseline chart reviews were taken from the Cooperative Cardiovascular Project and linked to Medicare health administrative data to provide a rich set of prognostic variables. Patients were followed up for 7 years through December 31, 2001, to assess the association between long-term survival and cardiac catheterization within 30 days of hospital admission. MAIN OUTCOME MEASURE: Risk-adjusted relative mortality rate using each of the analytic methods. RESULTS: Patients who received cardiac catheterization (n = 73 238) were younger and had lower AMI severity than those who did not. After adjustment for prognostic factors by using standard statistical risk-adjustment methods, cardiac catheterization was associated with a 50\% relative decrease in mortality (for multivariable model risk adjustment: adjusted relative risk [RR], 0.51; 95\% confidence interval [CI], 0.50-0.52; for propensity score risk adjustment: adjusted RR, 0.54; 95\% CI, 0.53-0.55; and for propensity-based matching: adjusted RR, 0.54; 95\% CI, 0.52-0.56). Using regional catheterization rate as an instrument, instrumental variable analysis showed a 16\% relative decrease in mortality (adjusted RR, 0.84; 95\% CI, 0.79-0.90). The survival benefits of routine invasive care from randomized clinical trials are between 8\% and 21\%. CONCLUSIONS: Estimates of the observational association of cardiac catheterization with long-term AMI mortality are highly sensitive to analytic method. All standard risk-adjustment methods have the same limitations regarding removal of unmeasured treatment selection biases. Compared with standard modeling, instrumental variable analysis may produce less biased estimates of treatment effects, but is more suited to answering policy questions than specific clinical questions.}},
    author = {Stukel, T. A. and Fisher, E. S. and Wennberg, D. E. and Alter, D. A. and Gottlieb, D. J. and Vermeulen, M. J.},
    citeulike-article-id = {13869065},
    citeulike-linkout-0 = {http://dx.doi.org/10.1001/jama.297.3.278},
    doi = {10.1001/jama.297.3.278},
    isbn = {1538-3598; 0098-7484;},
    journal = {JAMA},
    keywords = {exportrecords, propensity-scores},
    number = {3},
    pages = {278--285},
    posted-at = {2015-12-09 01:07:05},
    priority = {3},
    title = {{Analysis of observational studies in the presence of treatment selection bias effects of invasive cardiac management on AMI survival using propensity score and instrumental variable methods}},
    url = {http://dx.doi.org/10.1001/jama.297.3.278},
    volume = {297},
    year = {2007}
}

@article{15340,
    abstract = {{BACKGROUND AND OBJECTIVE: To review methods that seek to adjust for confounding in observational studies when assessing intended drug effects. METHODS: We reviewed the statistical, economical and medical literature on the development, comparison and use of methods adjusting for confounding. RESULTS: In addition to standard statistical techniques of (logistic) regression and Cox proportional hazards regression, alternative methods have been proposed to adjust for confounding in observational studies. A first group of methods focus on the main problem of nonrandomization by balancing treatment groups on observed covariates: selection, matching, stratification, multivariate confounder score, and propensity score methods, of which the latter can be combined with stratification or various matching methods. Another group of methods look for variables to be used like randomization in order to adjust also for unobserved covariates: instrumental variable methods, two-stage least squares, and grouped-treatment approach. Identifying these variables is difficult, however, and assumptions are strong. Sensitivity analyses are useful tools in assessing the robustness and plausibility of the estimated treatment effects to variations in assumptions about unmeasured confounders. CONCLUSION: In most studies regression-like techniques are routinely used for adjustment for confounding, although alternative methods are available. More complete empirical evaluations comparing these methods in different situations are needed.}},
    author = {Klungel, O. H. and Martens, E. P. and Psaty, B. M. and Grobbee, D. E. and Sullivan, S. D. and Stricker, B. H. C. and Leufkens, H. G. M. and de Boer, A.},
    citeulike-article-id = {13869027},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2004.03.011},
    doi = {10.1016/j.jclinepi.2004.03.011},
    isbn = {1878-5921; 0895-4356;},
    journal = {Journal of clinical epidemiology},
    keywords = {exportrecords, propensity-scores},
    number = {12},
    pages = {1223--1231},
    posted-at = {2015-12-09 01:07:04},
    priority = {3},
    title = {{Methods to assess intended effects of drug treatment in observational studies are reviewed}},
    url = {http://dx.doi.org/10.1016/j.jclinepi.2004.03.011},
    volume = {57},
    year = {2004}
}

@article{16203,
    abstract = {{Inverse probability-weighted estimation is a powerful tool for use with observational data. In this article, we describe how this propensity score-based method can be used to compare the effectiveness of 2 or more treatments. First, we discuss the inherent problems in using observational data to assess comparative effectiveness. Next, we provide a conceptual explanation of inverse probability-weighted estimation and point readers to sources that address the method in more formal, technical terms. Finally, we offer detailed guidance about how to implement the estimators in comparative effectiveness analyses.}},
    author = {Curtis, L. H. and Hammill, B. G. and Eisenstein, E. L. and Kramer, J. M. and Anstrom, K. J.},
    citeulike-article-id = {13869012},
    citeulike-linkout-0 = {http://dx.doi.org/10.1097/MLR.0b013e31806518ac},
    doi = {10.1097/MLR.0b013e31806518ac},
    isbn = {1537-1948; 0025-7079},
    journal = {Medical Care},
    keywords = {bias---selection, exportrecords, propensity-scores},
    number = {10 Suppl 2},
    pages = {S103--S107},
    posted-at = {2015-12-09 01:07:04},
    priority = {3},
    title = {{Using inverse probability-weighted estimators in comparative effectiveness analyses with observational databases}},
    url = {http://dx.doi.org/10.1097/MLR.0b013e31806518ac},
    volume = {45},
    year = {2007}
}

@article{15161,
    abstract = {{BACKGROUND: Two recent case-control studies by Meier et al. and van Staa et al. used the UK General Practice Research Database (GPRD) to examine the association between the use of statins and the risk of fractures, with different results. The objective of the present study was to examine methodological explanations for the discrepant results. METHODS: We created two datasets, which mimicked the previous study designs: a 'selected population' (SP) case-control dataset, with fracture cases matched to controls nested within a selected cohort (Meier et al.), and an 'entire population' (EP) case-control dataset, with both cases and controls sampled from the total GPRD population (van Staa et al.). Cases and controls were matched by gender, age (year of birth or 5 year age bands), and general practice. RESULTS: The study included 131 855 fracture cases. The crude odds ratio (OR) for hip fracture in statin users was 0.37 (95\% CI 0.27-0.52) in the SP and 0.54 (95\% CI 0.39-0.74) in the EP dataset. This difference was reduced when matching by year of birth, rather than by 5 year age bands: crude ORs were 0.58 (95\% CI 0.43-0.79) and 0.61 (95\% CI 0.44-0.88), respectively. In the SP dataset, 37\% of the cases could be matched by year of birth, while this was achieved for 99\% in the 'EP' dataset. The exposure time-window, the selection of confounders, and exclusion of high-risk patients also influenced results. CONCLUSION: Residual confounding by a matching variable and different definitions of the exposure time window explained differences in results. In case-control studies of drug use and fracture risk, broad matching criteria for age should be avoided and the selection of the time-window for exposure should be carefully considered.}},
    author = {de Vries, F. and de Vries, C. and Cooper, C. and Leufkens, B. and van Staa, T. P.},
    citeulike-article-id = {13868916},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/ije/dyl147},
    doi = {10.1093/ije/dyl147},
    isbn = {0300-5771; 1464-3685},
    journal = {International Journal of Epidemiology},
    keywords = {exportrecords, propensity-scores},
    number = {5},
    pages = {1301--1308},
    posted-at = {2015-12-09 01:07:02},
    priority = {3},
    title = {{Reanalysis of two studies with contrasting results on the association between statin use and fracture risk: the General Practice Research Database}},
    url = {http://dx.doi.org/10.1093/ije/dyl147},
    volume = {35},
    year = {2006}
}

@article{13220,
    abstract = {{Confounding can be a major source of bias in nonexperimental research. The authors recently introduced propensity score calibration (PSC), which combines propensity scores and regression calibration to address confounding by variables unobserved in the main study by using variables observed in a validation study. Here, the authors assess the performance of PSC using simulations in settings with and without violation of the key assumption of PSC: that the error-prone propensity score estimated in the main study is a surrogate for the gold-standard propensity score (i.e., it contains no additional information on the outcome). The assumption can be assessed if data on the outcome are available in the validation study. If data are simulated allowing for surrogacy to be violated, results depend largely on the extent of violation. If surrogacy holds, PSC leads to bias reduction between 32\% and 106\% (>100\% representing overcorrection). If surrogacy is violated, PSC can lead to an increase in bias. Surrogacy is violated when the direction of confounding of the exposure-disease association caused by the unobserved variable(s) differs from that of the confounding due to observed variables. When surrogacy holds, PSC is a useful approach to adjust for unmeasured confounding using validation data.}},
    author = {St\"{u}rmer, T. and Schneeweiss, S. and Rothman, K. J. and Avorn, J. and Glynn, R. J.},
    citeulike-article-id = {13868866},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/aje/kwm074},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Methods Papers]

Chou R, Aronson N, Atkins D, et al. Assessing harms when comparing medical interventions. In: Agency for Healthcare Research and Quality. Methods Reference Guide for Comparative Effectiveness Reviews [posted November 2008]. Rockville, MD. Available at: http://effectivehealthcare.ahrq.gov/healthInfo.cfm?infotype=rr\&ProcessID=60.},
    doi = {10.1093/aje/kwm074},
    issn = {0002-9262},
    journal = {American Journal of Epidemiology},
    keywords = {confounding, exportrecords, propensity-scores},
    number = {10},
    pages = {1110--1118},
    posted-at = {2015-12-09 01:07:01},
    priority = {3},
    title = {{Performance of propensity score calibration--a simulation study}},
    url = {http://dx.doi.org/10.1093/aje/kwm074},
    volume = {165},
    year = {2007}
}

@article{13198,
    abstract = {{OBJECTIVE: Propensity score (PS) analyses attempt to control for confounding in nonexperimental studies by adjusting for the likelihood that a given patient is exposed. Such analyses have been proposed to address confounding by indication, but there is little empirical evidence that they achieve better control than conventional multivariate outcome modeling. STUDY DESIGN AND METHODS: Using PubMed and Science Citation Index, we assessed the use of propensity scores over time and critically evaluated studies published through 2003. RESULTS: Use of propensity scores increased from a total of 8 reports before 1998 to 71 in 2003. Most of the 177 published studies abstracted assessed medications (N=60) or surgical interventions (N=51), mainly in cardiology and cardiac surgery (N=90). Whether PS methods or conventional outcome models were used to control for confounding had little effect on results in those studies in which such comparison was possible. Only 9 of 69 studies (13\%) had an effect estimate that differed by more than 20\% from that obtained with a conventional outcome model in all PS analyses presented. CONCLUSIONS: Publication of results based on propensity score methods has increased dramatically, but there is little evidence that these methods yield substantially different estimates compared with conventional multivariable methods.}},
    author = {St\"{u}rmer, T. and Joshi, M. and Glynn, R. J. and Avorn, J. and Rothman, K. J. and Schneeweiss, S.},
    citeulike-article-id = {13868865},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2005.07.004},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Methods Papers]},
    doi = {10.1016/j.jclinepi.2005.07.004},
    isbn = {0895-4356;},
    journal = {Journal of clinical epidemiology},
    keywords = {confounding, exportrecords, propensity-scores, systematic-reviews---methodologic-studies},
    number = {5},
    pages = {437--447},
    posted-at = {2015-12-09 01:07:01},
    priority = {3},
    title = {{A review of the application of propensity score methods yielded increasing use, advantages in specific settings, but not substantially different estimates compared with conventional multivariable methods}},
    url = {http://dx.doi.org/10.1016/j.jclinepi.2005.07.004},
    volume = {59},
    year = {2006}
}

@article{13197,
    abstract = {{Often, data on important confounders are not available in cohort studies. Sensitivity analyses based on the relation of single, but not multiple, unmeasured confounders with an exposure of interest in a separate validation study have been proposed. In this paper, the authors controlled for measured confounding in the main cohort using propensity scores (PS's) and addressed unmeasured confounding by estimating two additional PS's in a validation study. The "error-prone" PS exclusively used information available in the main cohort. The "gold standard" PS additionally included data on covariates available only in the validation study. Based on these two PS's in the validation study, regression calibration was applied to adjust regression coefficients. This propensity score calibration (PSC) adjusts for unmeasured confounding in cohort studies with validation data under certain, usually untestable, assumptions. The authors used PSC to assess the relation between nonsteroidal antiinflammatory drugs (NSAIDs) and 1-year mortality in a large cohort of elderly persons. "Traditional" adjustment resulted in a hazard ratio for NSAID users of 0.80 (95\% confidence interval (CI): 0.77, 0.83) as compared with an unadjusted hazard ratio of 0.68 (95\% CI: 0.66, 0.71). Application of PSC resulted in a more plausible hazard ratio of 1.06 (95\% CI: 1.00, 1.12). Until the validity and limitations of PSC have been assessed in different settings, the method should be seen as a sensitivity analysis.}},
    author = {St\"{u}rmer, T. and Schneeweiss, S. and Avorn, J. and Glynn, R. J.},
    citeulike-article-id = {13868864},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/aje/kwi192},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Methods Papers]},
    doi = {10.1093/aje/kwi192},
    issn = {0002-9262},
    journal = {American Journal of Epidemiology},
    keywords = {cohort-study---general, confounding, effect-size, exportrecords, propensity-scores},
    number = {3},
    pages = {279--289},
    posted-at = {2015-12-09 01:07:01},
    priority = {3},
    title = {{Adjusting effect estimates for unmeasured confounding with validation data using propensity score calibration}},
    url = {http://dx.doi.org/10.1093/aje/kwi192},
    volume = {162},
    year = {2005}
}

@article{13195,
    abstract = {{Little is known about optimal application and behavior of exposure propensity scores (EPS) in small studies. In a cohort of 103,133 elderly Medicaid beneficiaries in New Jersey, the effect of nonsteroidal antiinflammatory drug use on 1-year all-cause mortality was assessed (1995-1997) based on the assumption that there is no protective effect and that the preponderance of any observed effect would be confounded. To study the comparative behavior of EPS, disease risk scores, and "conventional" disease models, the authors randomly resampled 1,000 subcohorts of 10,000, 1,000, and 500 persons. The number of variables was limited in disease models, but not EPS and disease risk scores. Estimated EPS were used to adjust for confounding by matching, inverse probability of treatment weighting, stratification, and modeling. The crude rate ratio of death was 0.68 for users of nonsteroidal antiinflammatory drugs. "Conventional" adjustment resulted in a rate ratio of 0.80 (95\% confidence interval: 0.77, 0.84). The rate ratio closest to 1 (0.85) was achieved by inverse probability of treatment weighting (95\% confidence interval: 0.82, 0.88). With decreasing study size, estimates remained further from the null value, which was most pronounced for inverse probability of treatment weighting (n = 500: rate ratio = 0.72, 95\% confidence interval: 0.26, 1.68). In this setting, analytic strategies using EPS or disease risk scores were not generally superior to "conventional" models. Various ways to use EPS and disease risk scores behaved differently with smaller study size.}},
    author = {St\"{u}rmer, T. and Schneeweiss, S. and Brookhart, M. A. and Rothman, K. J. and Avorn, J. and Glynn, R. J.},
    citeulike-article-id = {13868863},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/aje/kwi106},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Disease Risk Score Methods Papers]},
    doi = {10.1093/aje/kwi106},
    isbn = {0002-9262;},
    journal = {American Journal of Epidemiology},
    keywords = {disease-risk-scores, exportrecords, propensity-scores},
    number = {9},
    pages = {891--898},
    posted-at = {2015-12-09 01:07:01},
    priority = {3},
    title = {{Analytic strategies to adjust confounding using exposure propensity scores and disease risk scores: nonsteroidal antiinflammatory drugs and short-term mortality in the elderly}},
    url = {http://dx.doi.org/10.1093/aje/kwi106},
    volume = {161},
    year = {2005}
}

@article{13086,
    abstract = {{BACKGROUND: In observational research, propensity score techniques can be used to account for baseline differences between compared therapies. Although propensity scores are used increasingly often, their limitations in settings without complete data may not be recognized. OBJECTIVES: We sought to evaluate the ability of propensity score matching to mitigate confounding by indication in an observational study of the effect of statin therapy on acute myocardial infarction (AMI). Matching was performed at random, and with propensity scores that incorporated a reduced or expanded set of variables. RESEARCH DESIGN/SUBJECTS: This was a propensity score matched cohort study using members of a health insurer database. MEASURES: Exposure to statin therapy was assessed at the beginning of follow-up with all cohort members being statin initiators or noninitiators, and the outcome of AMI was identified on the basis of claims codes. RESULTS: Matching on the basis of the propensity score provided results that are similar in magnitude to randomized clinical trials, suggesting that confounding was mitigated. However, matching on a propensity score created on a reduced set of variables yielded a result that suggested no effect of statin therapy, and demonstrated substantial imbalance on some variables that were not part of the propensity score. CONCLUSIONS: Propensity score matching can balance with respect to variables not explicitly included in the score, but external data are required to evaluate this.}},
    author = {Seeger, J. D. and Kurth, T. and Walker, A. M.},
    citeulike-article-id = {13868845},
    citeulike-linkout-0 = {http://dx.doi.org/10.1097/MLR.0b013e318074ce79},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Clinical Papers]},
    doi = {10.1097/MLR.0b013e318074ce79},
    issn = {0025-7079},
    journal = {Medical Care},
    keywords = {exportrecords, propensity-scores},
    number = {10 Supl 2},
    pages = {S143--S148},
    posted-at = {2015-12-09 01:07:00},
    priority = {3},
    title = {{Use of propensity score technique to account for exposure-related covariates: an example and lesson}},
    url = {http://dx.doi.org/10.1097/MLR.0b013e318074ce79},
    volume = {45},
    year = {2007}
}

@article{12971,
    abstract = {{The use of propensity scores to adjust for measured confounding factors has become increasingly popular in cohort studies. However, their use in case-control and case-cohort studies has received little attention. The authors present some theory on the estimation and use of propensity scores in case-control and case-cohort studies and present the results of simulation studies that examine whether large-sample expectations are realized in studies of typical size. The application of propensity scores is less straightforward in case-control and case-cohort studies than in cohort studies. The authors' simulations revealed two potentially important issues. First, when using several potential approaches, there is artifactual effect modification of the odds ratio by level of propensity score. The magnitude of this phenomenon decreases as the sample size increases. Second, several potential approaches produce estimated propensity scores that do not converge to the true value as sample size increases and, thus, can fail to adjust fully for measured confounding factors. However, the magnitude of residual confounding appeared modest in our simulations. Researchers considering using propensity scores in case-control or case-cohort studies should consider the potential for artifactual effect modification and their reduced ability to control for potential confounding factors.}},
    author = {Mansson, R. and Joffe, M. M. and Sun, W. and Hennessy, S.},
    citeulike-article-id = {13868827},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/aje/kwm069},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Methods Papers]},
    doi = {10.1093/aje/kwm069},
    issn = {0002-9262},
    journal = {American Journal of Epidemiology},
    keywords = {case-control-study---methods, cohort-study---methods, exportrecords, propensity-scores},
    number = {3},
    pages = {332--339},
    posted-at = {2015-12-09 01:07:00},
    priority = {3},
    title = {{On the estimation and use of propensity scores in case-control and case-cohort studies}},
    url = {http://dx.doi.org/10.1093/aje/kwm069},
    volume = {166},
    year = {2007}
}

@article{12911,
    abstract = {{In this article we develop the theoretical properties of the propensity function, which is a generalization of the propensity score of Rosenbaum and Rubin. Methods based on the propensity score have long been used for causal inference in observational studies; they are easy to use and can effectively reduce the bias caused by nonrandom treatment assignment. Although treatment regimes need not be binary in practice, the propensity score methods are generally confined to binary treatment scenarios. Two possible exceptions have been suggested for ordinal and categorical treatments. In this article we develop theory and methods that encompass all of these techniques and widen their applicability by allowing for arbitrary treatment regimes. We illustrate our propensity function methods by applying them to two datasets; we estimate the effect of smoking on medical expenditure and the effect of schooling on wages. We also conduct simulation studies to investigate the performance of our methods.}},
    author = {Imai, K. and van Dyk, D. A.},
    citeulike-article-id = {13868811},
    citeulike-linkout-0 = {http://dx.doi.org/10.1198/016214504000001187},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Methods Papers]},
    doi = {10.1198/016214504000001187},
    isbn = {0162-1459; 1537-274X},
    journal = {Journal of the American Statistical Association},
    keywords = {exportrecords, propensity-scores},
    number = {467},
    pages = {854--866},
    posted-at = {2015-12-09 01:07:00},
    priority = {3},
    title = {{Causal inference with general treatment regimes: generalizing the propensity score}},
    url = {http://dx.doi.org/10.1198/016214504000001187},
    volume = {99},
    year = {2004}
}

@article{13213,
    abstract = {{Use of propensity scores to identify and control for confounding in observational studies that relate medications to outcomes has increased substantially in recent years. However, it remains unclear whether, and if so when, use of propensity scores provides estimates of drug effects that are less biased than those obtained from conventional multivariate models. In the great majority of published studies that have used both approaches, estimated effects from propensity score and regression methods have been similar. Simulation studies further suggest comparable performance of the two approaches in many settings. We discuss five reasons that favour use of propensity scores: the value of focus on indications for drug use; optimal matching strategies from alternative designs; improved control of confounding with scarce outcomes; ability to identify interactions between propensity of treatment and drug effects on outcomes; and correction for unobserved confounders via propensity score calibration. We describe alternative approaches to estimate and implement propensity scores and the limitations of the C-statistic for evaluation. Use of propensity scores will not correct biases from unmeasured confounders, but can aid in understanding determinants of drug use and lead to improved estimates of drug effects in some settings.}},
    author = {Glynn, R. J. and Schneeweiss, S. and St\"{u}rmer, T.},
    citeulike-article-id = {13868792},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.1742-7843.2006.pto\_293.x},
    comment = {Cited in:

Johnson ES, Bartman BA, Briesacher BA, Fleming NS, Gerhard T, Kornegay CJ, Nourjah P, Sauer B, Schumock GT, Sedrakyan A, St\"{u}rmer T, West SL, Schneeweiss S. The Incident User Design in Comparative Effectiveness Research. Effective Health Care Program Research Report No. 32. (Prepared under Contract No. HHSA290200500161). AHRQ Publication No. 11(12)-EHC054-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm.

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Methods Papers]},
    doi = {10.1111/j.1742-7843.2006.pto\_293.x},
    isbn = {1742-7835;},
    journal = {Basic \& Clinical Pharmacology \& Toxicology},
    keywords = {exportrecords, propensity-scores},
    number = {3},
    pages = {253--259},
    posted-at = {2015-12-09 01:06:59},
    priority = {3},
    title = {{Indications for propensity scores and review of their use in pharmacoepidemiology}},
    url = {http://dx.doi.org/10.1111/j.1742-7843.2006.pto\_293.x},
    volume = {98},
    year = {2006}
}

@article{13925,
    abstract = {{BACKGROUND: In quality of care research, limited information is found on the relationship between quality of care and disease outcomes. This case-control study was conducted with the aim to assess the effect of guideline adherence for stroke prevention on the occurrence of stroke in general practice. We report on the problems related to a variant of confounding by indication, that may be common in quality of care studies. METHODS: Stroke patients (cases) and controls were recruited from the general practitioner's (GP) patient register, and an expert panel assessed the quality of care of cases and controls using guideline-based review criteria. RESULTS: A total of 86 patients was assessed. Compared to patients without shortcomings in preventive care, patients who received sub-optimal care appeared to have a lower risk of experiencing a stroke (OR 0.60; 95\% CI 0.24 to 1.53). This result was partly explained by the presence of risk factors (6.1 per cases, 4.4 per control), as reflected by the finding that the OR came much closer to 1.00 after adjustment for the number of risk factors (OR 0.82; 95\% CI 0.29 to 2.30). Patients with more risk factors for stroke had a lower risk of sub-optimal care (OR for the number of risk factors present 0.76; 95\% CI 0.61 to 0.94). This finding represents a variant of 'confounding by indication', which could not be fully adjusted for due to incomplete information on risk factors for stroke. CONCLUSIONS: At present, inaccurate recording of patient and risk factor information by GPs seriously limits the potential use of a case-control method to assess the effect of guideline adherence on disease outcome in general practice. We conclude that studies on the effect of quality of care on disease outcomes, like other observational studies of intended treatment effect, should be designed and performed such that confounding by indication is minimized.}},
    author = {de Koning, J. S. and Klazinga, N. S. and Koudstaal, P. J. and Prins, A. and Borsboom, G. J. and Mackenbach, J. P.},
    citeulike-article-id = {13868786},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/1472-6963-5-10},
    doi = {10.1186/1472-6963-5-10},
    isbn = {1472-6963;},
    journal = {BMC Health Services Research},
    keywords = {exportrecords, prevention, propensity-scores},
    number = {1},
    pages = {10+},
    posted-at = {2015-12-09 01:06:59},
    priority = {3},
    title = {{The role of 'confounding by indication' in assessing the effect of quality of care on disease outcomes in general practice: results of a case-control study}},
    url = {http://dx.doi.org/10.1186/1472-6963-5-10},
    volume = {5},
    year = {2005}
}

@article{13201,
    abstract = {{Despite the growing popularity of propensity score (PS) methods in epidemiology, relatively little has been written in the epidemiologic literature about the problem of variable selection for PS models. The authors present the results of two simulation studies designed to help epidemiologists gain insight into the variable selection problem in a PS analysis. The simulation studies illustrate how the choice of variables that are included in a PS model can affect the bias, variance, and mean squared error of an estimated exposure effect. The results suggest that variables that are unrelated to the exposure but related to the outcome should always be included in a PS model. The inclusion of these variables will decrease the variance of an estimated exposure effect without increasing bias. In contrast, including variables that are related to the exposure but not to the outcome will increase the variance of the estimated exposure effect without decreasing bias. In very small studies, the inclusion of variables that are strongly related to the exposure but only weakly related to the outcome can be detrimental to an estimate in a mean squared error sense. The addition of these variables removes only a small amount of bias but can increase the variance of the estimated exposure effect. These simulation studies and other analytical results suggest that standard model-building tools designed to create good predictive models of the exposure will not always lead to optimal PS models, particularly in small studies.}},
    author = {Brookhart, M. A. and Schneeweiss, S. and Rothman, K. J. and Glynn, R. J. and Avorn, J. and St\"{u}rmer, T.},
    citeulike-article-id = {13868775},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/aje/kwj149},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Methods Papers]},
    doi = {10.1093/aje/kwj149},
    issn = {0002-9262},
    journal = {American Journal of Epidemiology},
    keywords = {exportrecords, observational-study---methods, propensity-scores},
    number = {12},
    pages = {1149--1156},
    posted-at = {2015-12-09 01:06:59},
    priority = {3},
    title = {{Variable selection for propensity score models}},
    url = {http://dx.doi.org/10.1093/aje/kwj149},
    volume = {163},
    year = {2006}
}

@article{12706,
    abstract = {{The propensity score--the probability of exposure to a specific treatment conditional on observed variables--is increasingly being used in observational studies. Creating strata in which subjects are matched on the propensity score allows one to balance measured variables between treated and untreated subjects. There is an ongoing controversy in the literature as to which variables to include in the propensity score model. Some advocate including those variables that predict treatment assignment, while others suggest including all variables potentially related to the outcome, and still others advocate including only variables that are associated with both treatment and outcome. We provide a case study of the association between drug exposure and mortality to show that including a variable that is related to treatment, but not outcome, does not improve balance and reduces the number of matched pairs available for analysis. In order to investigate this issue more comprehensively, we conducted a series of Monte Carlo simulations of the performance of propensity score models that contained variables related to treatment allocation, or variables that were confounders for the treatment-outcome pair, or variables related to outcome or all variables related to either outcome or treatment or neither. We compared the use of these different propensity scores models in matching and stratification in terms of the extent to which they balanced variables. We demonstrated that all propensity scores models balanced measured confounders between treated and untreated subjects in a propensity-score matched sample. However, including only the true confounders or the variables predictive of the outcome in the propensity score model resulted in a substantially larger number of matched pairs than did using the treatment-allocation model. Stratifying on the quintiles of any propensity score model resulted in residual imbalance between treated and untreated subjects in the upper and lower quintiles. Greater balance between treated and untreated subjects was obtained after matching on the propensity score than after stratifying on the quintiles of the propensity score. When a confounding variable was omitted from any of the propensity score models, then matching or stratifying on the propensity score resulted in residual imbalance in prognostically important variables between treated and untreated subjects. We considered four propensity score models for estimating treatment effects: the model that included only true confounders; the model that included all variables associated with the outcome; the model that included all measured variables; and the model that included all variables associated with treatment selection. Reduction in bias when estimating a null treatment effect was equivalent for all four propensity score models when propensity score matching was used. Reduction in bias was marginally greater for the first two propensity score models than for the last two propensity score models when stratification on the quintiles of the propensity score model was employed. Furthermore, omitting a confounding variable from the propensity score model resulted in biased estimation of the treatment effect. Finally, the mean squared error for estimating a null treatment effect was lower when either of the first two propensity scores was used compared to when either of the last two propensity score models was used.}},
    author = {Austin, P. C. and Grootendorst, P. and Anderson, G. M.},
    citeulike-article-id = {13868759},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.2580},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Methods Papers]},
    doi = {10.1002/sim.2580},
    issn = {0277-6715},
    journal = {Statistics in Medicine},
    keywords = {exportrecords, observational-study---methods, propensity-scores},
    number = {4},
    pages = {734--753},
    posted-at = {2015-12-09 01:06:59},
    priority = {3},
    title = {{A comparison of the ability of different propensity score models to balance measured variables between treated and untreated subjects: a Monte Carlo study}},
    url = {http://dx.doi.org/10.1002/sim.2580},
    volume = {26},
    year = {2007}
}

@article{17896,
    author = {St\"{u}rmer, T. and Schneeweiss, S. and Rothman, K. J. and Avorn, J. and Glynn, R. J.},
    citeulike-article-id = {13868673},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/aje/kwm068},
    doi = {10.1093/aje/kwm068},
    isbn = {1476-6256; 0002-9262;},
    journal = {American Journal of Epidemiology},
    keywords = {exportrecords, propensity-scores},
    number = {10},
    pages = {1122--1123},
    posted-at = {2015-12-09 01:06:57},
    priority = {3},
    title = {{Propensity Score Calibration and its Alternatives}},
    url = {http://dx.doi.org/10.1093/aje/kwm068},
    volume = {165},
    year = {2007}
}

@article{20915,
    abstract = {{The author eplies to comments by A. V. Diez Roux (see record 2004-12522-011) and S.V.Subramanian (see record 2004-12522-012) on his original article (see record 2004-12522-010.) He acknowledges that Diez Roux makes several important points. The author agrees that the principal modeling issue is "selection", and that propensity score matching and sensitivity analyses are helpful but complicated by endogenous covariates, regression to the mean, and other woeful things. Importantly, he agrees that causal inference is something more than statistical analysis. He also agrees that there is great promise in recent efforts to measure neighborhood contexts through methods such as systematic social observation. Finally, Diez-Roux correctly makes the important point that "success" in a community trial does not necessarily translate into success in the "real world." Subramanian passionately defends the multilevel model for estimating neighborhood effects with observational data. He is certain that existing neighborhood effect estimates are valid parameters of how social forces/factors impact health and that such work should continue unfettered. Diez Roux, Subramanian and the author agree that social epidemiology is an emergent field with enormous potential to improve the public health, for it is abundantly clear that social forces and group dynamics affect health. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Oakes, J. M.},
    citeulike-article-id = {13868667},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.socscimed.2003.05.001},
    doi = {10.1016/j.socscimed.2003.05.001},
    isbn = {0277-9536; 1873-5347},
    journal = {Social Science \& Medicine},
    keywords = {exportrecords, propensity-scores},
    number = {10},
    pages = {1969--1971},
    posted-at = {2015-12-09 01:06:57},
    priority = {3},
    title = {{Causal inference and the relevance of social epidemiology.}},
    url = {http://dx.doi.org/10.1016/j.socscimed.2003.05.001},
    volume = {58},
    year = {2004}
}

@article{20916,
    abstract = {{Comments on an article by J. M. Oakes (see record 2004-12522-010), which raises a series of important questions on the validity of past work on neighborhood health effects and suggests directions the field should take. Indeed the limited nature of the evidence linking neighborhoods to individual-level outcomes, and its many methodological problems, have been noted in health and other fields. Undoubtedly, the selection issue is the key problem in observational studies of neighborhood effects. Epidemiologists have attempted to account for this by controlling for often numerous individual-level variables. One of the problems, as Oakes notes, is that when numerous covariates are included it is likely that sparse data will be found in many cross-tabulated cells, resulting in a greater reliance on assumptions which often cannot be directly tested. Mismeasured and omitted individual-level variables may result in nonexchangeability of individuals across neighborhoods even when measured individual-level covariates are included. Propensity score approach has certain advantages when attempting to control for multiple factors related to selection into treatment groups, however it does not resolve the problems of mismeasured or omitted variables. The combination of propensity score matching with sensitivity analyses may allow better assessment of the potential impact of omitted variable confounding on the associations estimated. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Diez Roux, A. V.},
    citeulike-article-id = {13868660},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0277-9536\%252803\%252900414-3},
    doi = {10.1016/S0277-9536\%252803\%252900414-3},
    isbn = {0277-9536; 1873-5347},
    journal = {Social Science \& Medicine},
    keywords = {exportrecords, propensity-scores},
    number = {10},
    pages = {1953--1960},
    posted-at = {2015-12-09 01:06:57},
    priority = {3},
    title = {{Estimating neighborhood health effects: The challenges of causal inference in a complex world: Comment.}},
    url = {http://dx.doi.org/10.1016/S0277-9536\%252803\%252900414-3},
    volume = {58},
    year = {2004}
}

@article{23083,
    abstract = {{In the social sciences, randomized experimentation is the optimal research design for establishing causation. However, for a number of practical reasons, researchers are sometimes unable to conduct experiments and must rely on observational data. In an effort to develop estimators that can approximate experimental results using observational data, scholars have given increasing attention to matching. In this article, we test the performance of matching by gauging the success with which matching approximates experimental results. The voter mobilization experiment presented here comprises a large number of observations (60,000 randomly assigned to the treatment group and nearly two million assigned to the control group) and a rich set of covariates. This study is analyzed in two ways. The first method, instrumental variables estimation, takes advantage of random assignment in order to produce consistent estimates. The second method, matching estimation, ignores random assignment and analyzes the data as though they were nonexperimental. Matching is found to produce biased results in this application because even a rich set of covariates is insufficient to control for preexisting differences between the treatment and control group. Matching, in fact, produces estimates that are no more accurate than those generated by ordinary least squares regression. The experimental findings show that brief paid get-out-the-vote phone calls do not increase turnout, while matching and regression show a large and significant effect.}},
    author = {Arceneaux, K. and Gerber, A. S. and Green, D. P.},
    citeulike-article-id = {13868659},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/pan/mpj001},
    doi = {10.1093/pan/mpj001},
    isbn = {U13  - No},
    issn = {1476-4989},
    journal = {Political Analysis},
    keywords = {exportrecords, propensity-scores},
    number = {1},
    pages = {37--62},
    posted-at = {2015-12-09 01:06:57},
    priority = {3},
    title = {{Comparing Experimental and Matching Methods Using a Large-Scale Voter Mobilization Experiment}},
    url = {http://dx.doi.org/10.1093/pan/mpj001},
    volume = {14},
    year = {2006}
}

@article{20886,
    abstract = {{Objective: A large number of possible techniques are available when conducting matching procedures, yet coherent guidelines for selecting the most appropriate application do not yet exist. In this article we evaluate several matching techniques and provide a suggested guideline for selecting the best technique. Methods: The main purpose of a matching procedure is to reduce selection bias by increasing the balance between the treatment and control groups. The following approach, consisting of five quantifiable steps, is proposed to check for balance: 1) Using two sample t-statistics to compare the means of the treatment and control groups for each explanatory variable; 2) Comparing the mean difference as a percentage of the average standard deviations; 3) Comparing percent reduction of bias in the means of the explanatory variables before and after matching; 4) Comparing treatment and control density estimates for the explanatory variables; and 5) Comparing the density estimates of the propensity scores of the control units with those of the treated units. We investigated seven different matching techniques and how they performed with regard to proposed five steps. Moreover, we estimate the average treatment effect with multivariate analysis and compared the results with the estimates of propensity score matching techniques. The Medstat MarketScan Data Base provided data for use in empirical examples of the utility of several matching methods. We conducted nearest neighborhood matching (NNM) analyses in seven ways: replacement, 2 to 1 matching, Mahalanobis matching (MM), MM with caliper, kernel matching, radius matching, and the stratification method. Results: Comparing techniques according to the above criteria revealed that the choice of matching has significant effects on outcomes. Patients with asthma are compared with patients without asthma and cost of illness ranged from \$2040 to \$4463 depending on the type of matching. After matching, we looked at the insignificant differences or larger P-values in the mean values (criterion 1); low mean differences as a percentage of the average standard deviation (criterion 2); 100\% reduction bias in the means of explanatory variables (criterion 3); and insignificant differences when comparing the density estimates of the treatment and control groups (criterion 4 and criterion 5). Mahalanobis matching with caliber yielded the better results according all five criteria (Mean = \$4463, SD = \$3252). We also applied multivariate analysis over the matched sample. This decreased the deviation in cost of illness estimates more than threefold (Mean = \$4456, SD = \$996). Conclusion: Sensitivity analysis of the matching techniques is especially important because none of the proposed methods in the literature is a priori superior to the others. The suggested joint consideration of propensity score matching and multivariate analysis offers an approach to assessing the robustness of the estimates. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Baser, O.},
    citeulike-article-id = {13868658},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.1524-4733.2006.00130.x},
    doi = {10.1111/j.1524-4733.2006.00130.x},
    isbn = {1098-3015; 1524-4733},
    journal = {Value in Health},
    keywords = {exportrecords, propensity-scores},
    number = {6},
    pages = {377--385},
    posted-at = {2015-12-09 01:06:57},
    priority = {3},
    title = {{Too Much Ado about Propensity Score Models? Comparing Methods of Propensity Score Matching.}},
    url = {http://dx.doi.org/10.1111/j.1524-4733.2006.00130.x},
    volume = {9},
    year = {2006}
}

@article{15905,
    author = {D'Agostino and D'Agostino},
    citeulike-article-id = {13868399},
    citeulike-linkout-0 = {http://dx.doi.org/10.1001/jama.297.3.314},
    comment = {Comment on:

Analysis of observational studies in the presence of treatment selection bias: effects of invasive cardiac management on AMI survival using propensity score and instrumental variable methods.Stukel TA, Fisher ES, Wennberg DE, Alter DA, Gottlieb DJ, Vermeulen MJ. JAMA. 2007 Jan 17; 297(3):278-85.},
    doi = {10.1001/jama.297.3.314},
    isbn = {1538-3598; 0098-7484},
    journal = {JAMA},
    keywords = {exportrecords, observational-study---criticism, propensity-scores},
    number = {3},
    pages = {314--316},
    posted-at = {2015-12-09 01:06:52},
    priority = {3},
    title = {{Estimating treatment effects using observational data}},
    url = {http://dx.doi.org/10.1001/jama.297.3.314},
    volume = {297},
    year = {2007}
}

@article{15586,
    abstract = {{Observational data are often used for research in critical care. Unlike randomized controlled trials, where randomization theoretically balances confounding factors, studies involving observational data pose the challenge of how to adjust appropriately for the bias and confounding that are inherent when comparing two or more groups of patients. This paper first highlights the potential sources of bias and confounding in critical care research and then reviews the statistical techniques available (matching, stratification, multivariable adjustment, propensity scores, and instrumental variables) to adjust for confounders. Finally, issues that need to be addressed when interpreting the results of observational studies, such as residual confounding, causality, and missing data, are discussed.}},
    author = {Wunsch, H. and Linde-Zwirble, W. T. and Angus, D. C.},
    citeulike-article-id = {13868387},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jcrc.2006.01.004},
    doi = {10.1016/j.jcrc.2006.01.004},
    isbn = {0883-9441; 1557-8615},
    journal = {Journal of Critical Care},
    keywords = {bias---selection, confounding, exportrecords, propensity-scores},
    number = {1},
    pages = {1--7},
    posted-at = {2015-12-09 01:06:52},
    priority = {3},
    title = {{Methods to adjust for bias and confounding in critical care health services research involving observational data}},
    url = {http://dx.doi.org/10.1016/j.jcrc.2006.01.004},
    volume = {21},
    year = {2006}
}

@incollection{13317,
    author = {Csizmadi, I. and Collet, J. P. and Boivin, J. F.},
    booktitle = {Pharmacoepidemiology},
    citeulike-article-id = {13868249},
    editor = {Strom, B. L.},
    isbn = {470866810},
    keywords = {exportrecords, propensity-scores},
    location = {West Sussex, UK},
    pages = {791--809; 47},
    posted-at = {2015-12-09 01:06:49},
    priority = {3},
    publisher = {John Wiley \& Sons, Ltd.},
    title = {{Bias and confounding in pharmacoepidemiology}},
    volume = {4th},
    year = {2005}
}

@proceedings{12809,
    abstract = {{Background: Racemic zopiclone, temazepam, and zolpidem are insomnia treatments that have been used for over 10 years. Objectives: To determine if there are differences in incidence of mild upper respiratory infections (URI), severe respiratory infections (RI), or sexual dysfunction among initiators of zopiclone and comparator drugs, temazepam, and zolpidem. Methods: The study had a retrospective cohort design that used propensity score techniques to control for potential confounding by indication. In the General Practice Research Database (GPRD) of the U.K., we identified initiators of zopiclone (n¼54,592), temazepam (n¼93,011), and zolpidem (n¼11,555) between 1/1/87 and 12/31/02 using GPRD drug product codes. Patients had at least 6 months of enrollment prior to initiation. Demographic and medical variables during the 6 months before initiation were considered for inclusion in propensity score models, and clinically plausible potential confounders were forced into the models. Each patient was assigned a propensity score (the probability of initiating zopiclone given covariates). Within categories of initiator groups and quintiles of propensity scores, persontime was classified in time on drug categories: current, recent, or past use. Outcomes were identified using OXMIS and Read diagnosis codes. For each time on drug category, we calculated incidence rate ratios adjusted for propensity score quintile using Poisson regression. Results: Current temazepam users and recent zolpidem users had higher risks of severe RI compared to zopiclone counterparts (Relative risk (RR): 1.07, 95\% confidence interval (CI): 1.02–1.11 and RR: 1.15, 95\%CI: 1.01–1.31). Current and past temazepam users had lower risk of sexual dysfunction compared to current and past zopiclone users (RR: 0.69, 95\%CI: 0.53–0.91 and RR: 0.88, 95\%CI: 0.79– 0.99). Past temazepam users had lower risk of mild URI compared to past zopiclone users (RR: 0.95, 95\%CI: 0.91– 0.98) while current zolpidem users had higher risk compared to current zopiclone users (RR: 1.15, 95\%CI: 1.01–1.32). There were no statistically significant differences in rates of sexual dysfunction between zolpidem and zopiclone. Conclusions: Our findings are consistent with an elevated risk of severe RI among zolpidem or temazepam users compared to zopiclone users. The reasons for this elevation in risk are unclear, and deserve further study to determine how the pharmacodynamic properties of these drugs influence risk of respiratory infection.}},
    author = {Eng, P. M. and Ziyadeh, N. and Nordstrom, B. L. and Caron, J. and Amato, D. and Seeger, J. D.},
    booktitle = {21st International Conference on Pharmacepidemiology \& Therapeutic Risk Management},
    citeulike-article-id = {13868244},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.1136},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Clinical Papers]},
    doi = {10.1002/pds.1136},
    isbn = {U13  - No},
    issn = {1099-1557},
    keywords = {exportrecords, propensity-scores},
    location = {Nashville, TN},
    number = {Suppl 2},
    pages = {S22--S23},
    posted-at = {2015-12-09 01:06:49},
    priority = {3},
    title = {{Incidence of Selected Outcomes among Matched Cohorts of Initiators of Racemic Zopiclone, Temazepam,and Zolpidem in the General Practice Research Database}},
    url = {http://dx.doi.org/10.1002/pds.1136},
    volume = {14},
    year = {2005}
}

@incollection{20908,
    abstract = {{(from the chapter) The aim of many analyses of social science and medical data sets is to draw causal inferences about the relative effects of treatments. The data available to compare many such treatments are not based on the results of carefully conducted randomized clinical trials, but rather are collected while observing systems as they operate in "normal" practice, without any interventions implemented by randomized assignment rules. Such data are relatively inexpensive to obtain, however, and often do represent the spectrum of actual practice better than do the settings of randomized experiments. Consequently, it is sensible to try to estimate the effects of treatments from such data sets, even if only to help design a new randomized experiment or shed light on the generalizability of results from existing randomized experiments. Standard methods of analysis using routine statistical software, however, can be quite deceptive for these objectives because they provide no warnings about their propriety. Propensity score methods, introduced by Rosenbaum and Rubin (1983a), are more reliable tools for addressing such objectives because the assumptions needed to make their answers appropriate are more assessable and transparent to the investigator. Subclassification on propensity scores is a particularly straightforward technique and is the topic of this chapter. Because these techniques are so straightforward, they seem especially appropriate to review in this Festschrift for Ralph Rosnow, who has made such substantial contributions to the teaching and dissemination of straightforward statistical methods in psychological research. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Rubin, D. B.},
    booktitle = {Advances in social \& organizational psychology: A tribute to Ralph Rosnow},
    citeulike-article-id = {13868236},
    editor = {Hantula, D. A.},
    isbn = {0-8058-5590-4;},
    keywords = {bias---selection, exportrecords, propensity-scores},
    location = {Mahwah, NJ},
    pages = {41--59},
    posted-at = {2015-12-09 01:06:49},
    priority = {3},
    publisher = {Lawrence Erlbaum},
    title = {{Estimating Treatment Effects From Nonrandomized Studies Using Subclassification on Propensity Scores.}},
    year = {2006}
}

@article{20920,
    abstract = {{In the likely event that some clients refuse to participate in a psychosocial field experiment, the estimates of the effects of the experimental treatment on client outcomes may suffer from sample selection bias, regardless of whether the statistical analyses include control variables. This paper explores ways of correcting for this bias with advanced correction strategies, focusing on experiments in which clients refuse assignment into treatment conditions. The sample selection modelling strategy, which is highly recommended but seldom applied to random sample psychosocial experiments, and some alternatives are discussed. Data from an experiment on homelessness and substance abuse are used to compare sample selection, conventional control variable, instrumental variable, and propensity score matching correction strategies. The empirical findings suggest that the sample selection modelling strategy provides reliable estimates of the effects of treatment, that it and some other correction strategies are awkward to apply when there is post-assignment rejection, and that the varying correction strategies provide widely divergent estimates. In light of these findings, researchers might wish regularly to compare estimates across multiple correction strategies.}},
    author = {Sosin, M. R.},
    citeulike-article-id = {13868170},
    citeulike-linkout-0 = {http://dx.doi.org/10.1348/000711002159707},
    doi = {10.1348/000711002159707},
    isbn = {0007-1102; 2044-8317},
    journal = {British Journal of Mathematical and Statistical Psychology},
    keywords = {exportrecords, propensity-scores},
    number = {1},
    pages = {63--92},
    posted-at = {2015-12-09 01:06:04},
    priority = {3},
    title = {{Outcomes and sample selection: The case of a homelessness and substance abuse intervention}},
    url = {http://dx.doi.org/10.1348/000711002159707},
    volume = {55},
    year = {2002}
}

@article{12834,
    abstract = {{Estimation of average treatment effects in observational studies often requires adjustment for differences in pre-treatment variables. If the number of pre-treatment variables is large, standard covariance adjustment methods are often inadequate. Rosenbaum \& Rubin (1983) propose an alternative method for adjusting for pre-treatment variables for the binary treatment case based on the so-called propensity score. Here an extension of the propensity score methodology is proposed that allows for estimation of average casual effects with multi-valued treatments.}},
    author = {Imbens, G. W.},
    citeulike-article-id = {13868160},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/biomet/87.3.706},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Methods Papers]},
    doi = {10.1093/biomet/87.3.706},
    isbn = {U13  - sent},
    journal = {Biometrika},
    keywords = {exportrecords, propensity-scores},
    number = {3},
    pages = {706--710},
    posted-at = {2015-12-09 01:06:04},
    priority = {3},
    title = {{The Role of the Propensity Score in Estimating Dose-Response}},
    url = {http://dx.doi.org/10.1093/biomet/87.3.706},
    volume = {87},
    year = {2000}
}

@article{20918,
    abstract = {{This article reviews propensity score methods and illustrates their use in an analysis of dose response, the relationship between the volume of services received, and treatment outcomes. In mental health policy, this question is central to key issues such as parity. Data for the illustrative analysis are taken from a well-known study of children's mental health services. This analysis estimates the impact of outpatient therapy based on comparisons of individuals receiving different treatment doses. Those comparisons are adjusted for preexisting observed differences among the groups using propensity score methods. The study includes 301 participants aged 5 to 18 years treated at the study sites. The analyses are based on family characteristics and the mental health status of children and adolescents reported in interviews with parents as well as administrative data on service use. Analyses using propensity score matching suggest that added services improve treatment outcomes, especially child functioning. However, at least for the services and outcomes considered, the marginal benefits to high levels of treatment are limited. These analyses illustrate the potential value of propensity score methods to health services researchers. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Foster, E. M.},
    citeulike-article-id = {13868063},
    citeulike-linkout-0 = {http://dx.doi.org/10.1097/01.MLR.0000089629.62884.22},
    doi = {10.1097/01.MLR.0000089629.62884.22},
    isbn = {0025-7079; 1537-1948},
    journal = {Medical Care},
    keywords = {exportrecords, propensity-scores},
    number = {10},
    pages = {1183--1192},
    posted-at = {2015-12-09 01:06:02},
    priority = {3},
    title = {{Propensity Score Matching: An Illustrative Analysis of Dose Response}},
    url = {http://dx.doi.org/10.1097/01.MLR.0000089629.62884.22},
    volume = {41},
    year = {2003}
}

@article{17720,
    abstract = {{In order to detect adverse drug reactions, large observational drug safety studies are necessary as randomized clinical trials rarely have enough power. However, in order to obtain reliable results the issue of confounding, especially confounding by indication, should be addressed. We proposed a multiple propensity score, which is an extension of the propensity score, to reduce the bias in a dose-response analysis in a drug safety study. The multiple propensity score has similar properties to the propensity score in Rosenbaum and Rubin.(1) Using the propensity score for bias reduction of the risk ratio was considered. We used the multiple propensity score in a study of the dose-response relationship between diclofenac prescriptions and hospitalization for gastrointestinal bleeding and perforation using a record linkage database. We found that the unadjusted risk ratios were biased downwards due to confounders and that this bias was reduced by using stratification based on the multiple propensity score.}},
    author = {Wang, J. and Donnan, P. T. and Steinke, D. and MacDonald, T. M.},
    citeulike-article-id = {13867992},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.572},
    doi = {10.1002/pds.572},
    isbn = {1053-8569 1099-1557},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {adverse-events---harms, bias---general, exportrecords, propensity-scores},
    number = {2},
    pages = {105--11},
    posted-at = {2015-12-09 01:06:01},
    priority = {3},
    title = {{The multiple propensity score for analysis of dose-response relationships in drug safety studies}},
    url = {http://dx.doi.org/10.1002/pds.572},
    volume = {10},
    year = {2001}
}

@article{17225,
    abstract = {{Propensity score methodology can be used to help design observational studies in a way analogous to the way randomized experiments are designed: without seeing any answers involving outcome variables. The typical models used to analyze observational data (e.g., least squares regressions, difference of difference methods) involve outcomes, and so cannot be used for design in this sense. Because the propensity score is a function only of covariates, not outcomes, repeated analyses attempting to balance covariate distributions across treatment groups do not bias estimates of the treatment effect on outcome variables. This theme will the primary focus of this article: how to use the techniques of matching, subclassification and/or weighting to help design observational studies. The article also proposes a new diagnostic table to aid in this endeavor, which is especially useful when there are many covariates under consideration. The conclusion of the initial design phase may be that the treatment and control groups are too far apart to produce reliable effect estimates without heroic modeling assumptions. In such cases, it may be wisest to abandon the intended observational study, and search for a more acceptable data set where such heroic modeling assumptions are not necessary. The ideas and techniques will be illustrated using the initial design of an observational study for use in the tobacco litigation based on the NMES data set.}},
    author = {Rubin, D. B.},
    citeulike-article-id = {13867949},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/A:1020363010465},
    doi = {10.1023/A:1020363010465},
    isbn = {1387-3741; 1572-9400},
    journal = {Health Services and Outcomes Research Methodology},
    keywords = {exportrecords, propensity-scores},
    number = {3-4},
    pages = {169--188},
    posted-at = {2015-12-09 01:06:00},
    priority = {3},
    title = {{Using Propensity Scores to Help Design Observational Studies: Application to the Tobacco Litigation}},
    url = {http://dx.doi.org/10.1023/A:1020363010465},
    volume = {2},
    year = {2001}
}

@article{17216,
    abstract = {{BACKGROUND: This research examined the use of the propensity score method to compare proxy-completed responses to self-completed responses in the first three baseline cohorts of the Medicare Health Outcomes Survey, administered in 1998, 1999, and 2000, respectively. A proxy is someone other than the respondent who completes the survey for the respondent. METHODS: The propensity score method of matched sampling was used to compare proxy and self-completed responses. A propensity score is a value that equals the estimated probability of a given individual belonging to a treatment group given the observed background characteristics of that individual. Proxy and self-completed responses were compared on demographics, the SF-36, chronic conditions, activities of daily living, and depression-screening questions. For each individual survey respondent, logistic regression was used to calculate the probability that this individual belonged to the proxy respondent group (propensity score). Pre and post adjustment comparisons were tested by calculating effect sizes. RESULTS: Differences between self and proxy-completed responses were substantially reduced with the use of the propensity score method. However, differences were still found in the SF-36, several demographics, several impaired activities of daily living, several chronic conditions, and one depression-screening question. CONCLUSION: The propensity score method helped to reduce differences between proxy-completed and self-completed survey responses, thereby providing an approximation to a randomized controlled experiment of proxy-completed versus self-completed survey responses.}},
    author = {Ellis, B. H. and Bannister, W. M. and Cox, J. K. and Fowler, B. M. and Shannon, E. D. and Drachman, D. and Adams, R. W. and Giordano, L. A.},
    citeulike-article-id = {13867921},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/1477-7525-1-47},
    doi = {10.1186/1477-7525-1-47},
    isbn = {1477-7525;},
    journal = {Health and Quality of Life Outcomes},
    keywords = {exportrecords, propensity-scores},
    pages = {47+},
    posted-at = {2015-12-09 01:05:59},
    priority = {3},
    title = {{Utilization of the propensity score method: an exploratory comparison of proxy-completed to self-completed responses in the Medicare Health Outcomes Survey}},
    url = {http://dx.doi.org/10.1186/1477-7525-1-47},
    volume = {1},
    year = {2003}
}

@article{13087,
    abstract = {{This investigation quantified the effect of statins on acute myocardial infarction (AMI) in an observational setting where fluvastatin represented most of the statin use. The study applied propensity scores to match statin initiators to statin noninitiators and followed them for the occurrence of AMI. Serum low-density lipoprotein levels were reduced by statin therapy, and there were fewer incidents of AMI in statin initiators than in noninitiators.}},
    author = {Seeger, J. D. and Walker, A. M. and Williams, P. L. and Saperia, G. M. and Sacks, F. M.},
    citeulike-article-id = {13867807},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.amjcard.2003.08.057},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Clinical Papers]},
    doi = {10.1016/j.amjcard.2003.08.057},
    issn = {0002-9149},
    journal = {American Journal of Cardiology},
    keywords = {exportrecords, propensity-scores},
    number = {12},
    pages = {1447--1451},
    posted-at = {2015-12-09 01:05:57},
    priority = {3},
    title = {{A propensity score-matched cohort study of the effect of statins, mainly fluvastatin, on the occurrence of acute myocardial infarction}},
    url = {http://dx.doi.org/10.1016/j.amjcard.2003.08.057},
    volume = {92},
    year = {2003}
}

@proceedings{12904,
    abstract = {{Matching members of a treatment group (cases) to members of a no treatment group (controls) is often used in observational studies to reduce bias and approximate a randomized trial.  There is often a trade-off when matching cases to controls and two types of bias can be introduced. While trying to maximize exact matches, cases may be excluded due to incomplete matching.  While trying to maximize cases, inexact matching may result.  Bias is introduced by both incomplete matching and inexact matching.   Propensity scores are being used in observational studies to reduce bias.  It has been shown that matching on a propensity score can result in similar matched populations.  This paper will describe how to reduce matched-pair bias caused by incomplete matching and inexact matching.  Cases will be matched to controls on the propensity score using the presented matching algorithm.  SAS/STAT LOGISTIC procedure code will be given to create the propensity score.  A user-written SAS macro will be given to create a propensity score matched-pair sample using greedy matching techniques. The results of using the presented code, run on a large observational database of myocardial infarction patients, will be given as an example.}},
    author = {Parsons, L.},
    booktitle = {SUGI 26: Proceedings of the Twenty-Sixth Annual SAS ® Users Group International Conference},
    citeulike-article-id = {13867789},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Methods Papers]},
    isbn = {1-58025-864-6},
    keywords = {disease-risk-scores, exportrecords, information-technology, propensity-scores},
    location = {Cary, NC},
    pages = {214--226},
    posted-at = {2015-12-09 01:05:56},
    priority = {3},
    publisher = {SAS Institute},
    title = {{Reducing Bias in a Propensity Score Matched-Pair Sample Using Greedy Matching Techniques}},
    year = {2001}
}

@article{12741,
    abstract = {{The aim of this study was to use Monte Carlo simulations to compare logistic regression with propensity scores in terms of bias, precision, empirical coverage probability, empirical power, and robustness when the number of events is low relative to the number of confounders. The authors simulated a cohort study and performed 252,480 trials. In the logistic regression, the bias decreased as the number of events per confounder increased. In the propensity score, the bias decreased as the strength of the association of the exposure with the outcome increased. Propensity scores produced estimates that were less biased, more robust, and more precise than the logistic regression estimates when there were seven or fewer events per confounder. The logistic regression empirical coverage probability increased as the number of events per confounder increased. The propensity score empirical coverage probability decreased after eight or more events per confounder. Overall, the propensity score exhibited more empirical power than logistic regression. Propensity scores are a good alternative to control for imbalances when there are seven or fewer events per confounder; however, empirical power could range from 35\% to 60\%. Logistic regression is the technique of choice when there are at least eight events per confounder.}},
    author = {Cepeda, M. S. and Boston, R. and Farrar, J. T. and Strom, B. L.},
    citeulike-article-id = {13867766},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/aje/kwg115},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Methods Papers]},
    doi = {10.1093/aje/kwg115},
    issn = {0002-9262},
    journal = {American Journal of Epidemiology},
    keywords = {confounding, data---rare---zero-events, exportrecords, propensity-scores},
    number = {3},
    pages = {280--287},
    posted-at = {2015-12-09 01:05:56},
    priority = {3},
    title = {{Comparison of logistic regression versus propensity score when the number of events is low and there are multiple confounders}},
    url = {http://dx.doi.org/10.1093/aje/kwg115},
    volume = {158},
    year = {2003}
}

@article{20917,
    abstract = {{This paper analyzes how variation in participant take-up rates affected the impacts of the New Hope project, a random-assignment, anti-poverty program. New Hope offered experimental members four benefits--child care subsidies, wage subsidies, health insurance, and, if needed, a temporary community service job--that were available to families working full time. Take-up of the benefits was far from universal and experimental participants who used one of the benefits rarely used all of them. Clustering and propensity score methods are used to analyze take-up sub-groups and to estimate program impacts within each. The majority of take-up patterns adopted by experimental members were associated with at least one positive program impact. However, the primary beneficiaries were those parents who used the community service jobs. They increased their employment effort, felt less parenting stress, and had children with higher teacher-related academic accomplishment scores. The implication of this method for the evaluation of other multi-benefit programs is discussed. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Gibson, C. M.},
    citeulike-article-id = {13867720},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.ameval.2003.09.002},
    doi = {10.1016/j.ameval.2003.09.002},
    isbn = {U13  - No},
    journal = {American Journal of Evaluation},
    keywords = {exportrecords, propensity-scores},
    number = {4},
    pages = {443--469},
    posted-at = {2015-12-09 01:05:55},
    priority = {3},
    title = {{Privileging the Participant: The Importance of Sub-Group Analysis in Social Welfare Evaluations.}},
    url = {http://dx.doi.org/10.1016/j.ameval.2003.09.002},
    volume = {24},
    year = {2003}
}

@article{20919,
    abstract = {{This article reviews a recent statistical innovation, propensity score analysis, that is increasingly used in the analysis of data from quasi-experiments. Using a data set from a recent quasi-experiment, we show how to compute propensity scores from observed covariates that might predict group membership, and then show how to use propensity scores to equate groups on those observed covariates using matching, stratification, or analysis of covariance. Tentative evidence suggests that the use of such techniques can reduce the amount of bias in quasi-experimental results compared to results from randomized experiments. The article ends with a discussion of potential problems with propensity scores. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)}},
    author = {Shadish, W. R. and Clark, M. H.},
    citeulike-article-id = {13867685},
    isbn = {1575-9105;},
    journal = {Metodolog\'{\i}a de las Ciencias del Comportamiento},
    keywords = {exportrecords, propensity-scores},
    number = {2},
    pages = {291--298},
    posted-at = {2015-12-09 01:05:54},
    priority = {3},
    title = {{An Introduction to Propensity Scores}},
    volume = {4},
    year = {2002}
}

@article{17729,
    author = {Wang, J. and Donnan, P. T.},
    citeulike-article-id = {13867651},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.656},
    doi = {10.1002/pds.656},
    isbn = {1053-8569 1099-1557},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {adverse-events---harms, exportrecords, propensity-scores},
    number = {4},
    pages = {341--4},
    posted-at = {2015-12-09 01:05:54},
    priority = {3},
    title = {{Propensity score methods in drug safety studies: practice, strengths and limitations}},
    url = {http://dx.doi.org/10.1002/pds.656},
    volume = {10},
    year = {2001}
}

@article{17751,
    abstract = {{There has been a resurgence of controversy about the usefulness of observational data to study the efficacy of drugs. Nearly every week a researcher makes some criticism of clinical trials or justifies observational research into intended effects, with other researchers offering a contradictory viewpoint. Literature reviews are not useful in this regard because the contradictory studies will not usually be carried out. Some methods are discussed which may have potential utility in the study of intended effects. There may be a marginal role for statistical techniques such as propensity scores and confounder scores. More promising techniques may include ecological analyses, restriction of subjects and blinded prospective review. Because it is currently unknown when the observational study of drug efficacy is possible, we should arguably always carry out a study of the determinants of prescribing first, and possibly consider using the various techniques that are outlined in this article.}},
    author = {McMahon, A. D.},
    citeulike-article-id = {13867627},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/pds.883},
    doi = {10.1002/pds.883},
    isbn = {1053-8569 1099-1557},
    journal = {Pharmacoepidemiology and Drug Safety},
    keywords = {exportrecords, propensity-scores},
    number = {7},
    pages = {551--8},
    posted-at = {2015-12-09 01:05:52},
    priority = {3},
    title = {{Approaches to combat with confounding by indication in observational studies of intended drug effects}},
    url = {http://dx.doi.org/10.1002/pds.883},
    volume = {12},
    year = {2003}
}

@article{12986,
    abstract = {{Direct adjustment or standardization applies population weights to subclass means in an effort to estimate population quantities from a sample that is not representative of the population. Direct adjustment has several attractive features, but when there are many subclasses it can attach large weights to small quantities of data, often in a fairly erratic manner. In the extreme, direct adjustment can attach infinite weight to nonexistent data, a noticeable inconvenience in practice. This article proposes a method of model-based direct adjustment that preserves the attractive features of conventional direct adjustment while stabilizing the weights attached to small subclasses. The sample mean and conventional direct adjustment are both special cases of model-based direct adjustment under two different extreme models for the subclass-specific selection probabilities. The discussion of this method provides some insights into the behavior of true and estimated propensity scores: the estimated scores are better than the true ones for almost the same reason that direct adjustment can outperform the sample mean in a simple random sample. The method is applied to a nonrandom sample in an effort to estimate a discrete distribution of essay scores in the College Board's Advanced Placement Examination in Biology.}},
    author = {Rosenbaum, P. R.},
    citeulike-article-id = {13867335},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/01621459.1987.10478441},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Methods Papers]},
    doi = {10.1080/01621459.1987.10478441},
    isbn = {U13  - sent},
    journal = {Journal of the American Statistical Association},
    keywords = {exportrecords, propensity-scores, statistics},
    number = {398},
    pages = {387--394},
    posted-at = {2015-12-09 01:05:08},
    priority = {3},
    title = {{Model-Based Direct Adjustment}},
    url = {http://dx.doi.org/10.1080/01621459.1987.10478441},
    volume = {82},
    year = {1987}
}

@article{20921,
    abstract = {{This article proposes an extension of the propensity score (PS) adjustment method to latent variable models. The PS is defined as the conditional probability of assignment to a treatment group given a set of observed covariates. In a typical application of this approach, each observation is associated with a propensity to be assigned to the treatment group. The distribution of PSs is then divided into strata and analyses of treatment group differences are conducted within strata. Comparisons of treatment group differences within and across strata provide evidence for whether or not the bias due to nonrandom selection into treatment groups has been accounted for by the PS adjustment. This article extends the application of the PS approach to the analysis of group differences on latent variables. In particular, multi-sample MIMIC modeling is used to test hypotheses about treatment group differences on latent variables across strata. The role of factorial invariance as it relates to the approach advocated in this article is also discussed. An application to the problem of academic tracking differences in self-concept and locus-of-control, using data from the National Educational Longitudinal Study of 1988, illustrates the procedure. (PsycINFO Database Record (c) 2012 APA, all rights reserved)}},
    author = {Kaplan, D.},
    citeulike-article-id = {13867183},
    citeulike-linkout-0 = {http://dx.doi.org/10.1207/S15327906MBR3404\_4},
    doi = {10.1207/S15327906MBR3404\_4},
    isbn = {0027-3171; 1532-7906},
    journal = {Multivariate Behavioral Research},
    keywords = {exportrecords, propensity-scores},
    number = {4},
    pages = {467--492},
    posted-at = {2015-12-09 01:05:05},
    priority = {3},
    title = {{An extension of the propensity score adjustment method for the analysis of group differences in MIMIC models}},
    url = {http://dx.doi.org/10.1207/S15327906MBR3404\_4},
    volume = {34},
    year = {1999}
}

@article{23082,
    abstract = {{This paper uses propensity score methods to address the question: how well can an observational study estimate the treatment impact of a program? Using data from Lalonde's (1986) influential evaluation of non-experimental methods, we demonstrate that propensity score methods succeed in estimating the treatment impact of the National Supported Work Demonstration. Propensity score methods reduce the task of controlling for differences in pre-intervention variables between the treatment and the non-experimental comparison groups to controlling for differences in the estimated propensity score (the probability of assignment to treatment, conditional on covariates). It is difficult to control for differences in pre-intervention variables when they are numerous and when the treatment and comparison groups are dissimilar, whereas controlling for the estimated propensity score, a single variable on the unit interval, is a straightforward task. We apply several methods, such as stratification on the propensity score and matching on the propensity score, and show that they result in accurate estimates of the treatment impact.}},
    author = {Dehejia, R. H. and Wahba, S.},
    citeulike-article-id = {13867169},
    journal = {Journal of the American Statistical Association},
    keywords = {exportrecords, propensity-scores},
    number = {448},
    pages = {1053--1062},
    posted-at = {2015-12-09 01:05:05},
    priority = {3},
    title = {{Causal Effects in Non-Experimental Studies: Re-Evaluating the Evaluation of Training Programs}},
    volume = {94},
    year = {1999}
}

@article{13878,
    abstract = {{The propensity score is the conditional probability of assignment to a particular treatment given a vector of observed covariates. Both large and small sample theory show that adjustment for the scalar propensity score is sufficient to remove bias due to all observed covariates. Applications include: (i) matched sampling on the univariate propensity score, which is a generalization of discriminant matching, (ii) multivariate adjustment by subclassification on the propensity score where the same subclasses are used to estimate treatment effects for all outcome variables and in all subpopulations, and (iii) visual representation of multivariate covariance adjustment by a two-dimensional plot.}},
    author = {Rosenbaum, P. R. and Rubin, D. B.},
    citeulike-article-id = {13866866},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/biomet/70.1.41},
    comment = {Cited in:

Hempel S, Miles J, Suttorp M, Wang Z, Johnsen B, Morton S, Perry T, Valentine D, Shekelle P. Detection of Associations between Trial Quality and Effect Sizes. Methods Research Report. Prepared by the Southern California Evidence-based Practice Center under Contract No. 290-2007-10062-I. AHRQ Publication No. 12-EHC010-EF. Rockville, MD: Agency for Healthcare Research and Quality; January 2012.

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Methods Papers]},
    doi = {10.1093/biomet/70.1.41},
    isbn = {0006-3444; 1464-3510},
    journal = {Biometrika},
    keywords = {exportrecords, propensity-scores},
    number = {1},
    pages = {41--55},
    posted-at = {2015-12-09 01:04:58},
    priority = {3},
    title = {{The Central Role of the Propensity Score in Observational Studies for Causal Effects}},
    url = {http://dx.doi.org/10.1093/biomet/70.1.41},
    volume = {70},
    year = {1983}
}

@article{13062,
    abstract = {{The aim of many analyses of large databases is to draw causal inferences about the effects of actions, treatments, or interventions. Examples include the effects of various options available to a physician for treating a particular patient, the relative efficacies of various health care providers, and the consequences of implementing a new national health care policy. A complication of using large databases to achieve such aims is that their data are almost always observational rather than experimental. That is, the data in most large data sets are not based on the results of carefully conducted randomized clinical trials, but rather represent data collected through the observation of systems as they operate in normal practice without any interventions implemented by randomized assignment rules. Such data are relatively inexpensive to obtain, however, and often do represent the spectrum of medical practice better than the settings of randomized experiments. Consequently, it is sensible to try to estimate the effects of treatments from such large data sets, even if only to help design a new randomized experiment or shed light on the generalizability of results from existing randomized experiments. However, standard methods of analysis using available statistical software (such as linear or logistic regression) can be deceptive for these objectives because they provide no warnings about their propriety. Propensity score methods are more reliable tools for addressing such objectives because the assumptions needed to make their answers appropriate are more assessable and transparent to the investigator.}},
    author = {Rubin, D. B.},
    citeulike-article-id = {13866860},
    citeulike-linkout-0 = {http://dx.doi.org/10.7326/0003-4819-127-8\_Part\_2-199710151-00064},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Methods Papers]},
    doi = {10.7326/0003-4819-127-8\_Part\_2-199710151-00064},
    issn = {0003-4819},
    journal = {Annals of Internal Medicine},
    keywords = {data---administrative-billing, data---clinical, exportrecords, propensity-scores},
    number = {8 Pt 2},
    pages = {757--763},
    posted-at = {2015-12-09 01:04:58},
    priority = {3},
    title = {{Estimating causal effects from large data sets using propensity scores}},
    url = {http://dx.doi.org/10.7326/0003-4819-127-8\_Part\_2-199710151-00064},
    volume = {127},
    year = {1997}
}

@article{13054,
    abstract = {{The propensity score is the conditional probability of assignment to a particular treatment given a vector of observed covariates. Previous theoretical arguments have shown that subclassification on the propensity score will balance all observed covariates. Subclassification on an estimated propensity score is illustrated, using observational data on treatments for coronary artery disease. Five subclasses defined by the estimated propensity score are constructed that balance 74 covariates, and thereby provide estimates of treatment effects using direct adjustment. These subclasses are applied within sub-populations, and model-based adjustments are then used to provide estimates of treatment effects within these sub-populations. Two appendixes address theoretical issues related to the application: the effectiveness of subclassification on the propensity score in removing bias, and balancing properties of propensity scores with incomplete data.}},
    author = {Rosenbaum, P. R. and Rubin, D. B.},
    citeulike-article-id = {13866857},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/01621459.1984.10478078},
    comment = {Cited in:

 Hempel S, Miles J, Suttorp M, Wang Z, Johnsen B, Morton S, Perry T, Valentine D, Shekelle P. Detection of Associations between Trial Quality and Effect Sizes. Methods Research Report. Prepared by the Southern California Evidence-based Practice Center under Contract No. 290-2007-10062-I. AHRQ Publication No. 12-EHC010-EF. Rockville, MD: Agency for Healthcare Research and Quality; January 2012.},
    doi = {10.1080/01621459.1984.10478078},
    isbn = {0162-1459; 1537-274X},
    journal = {Journal of the American Statistical Association},
    keywords = {exportrecords, propensity-scores, statistics},
    number = {387},
    pages = {516--524},
    posted-at = {2015-12-09 01:04:58},
    priority = {3},
    title = {{Reducing Bias in Observational Studies Using Subclassification on the Propensity Score}},
    url = {http://dx.doi.org/10.1080/01621459.1984.10478078},
    volume = {79},
    year = {1984}
}

@article{13048,
    abstract = {{In order to estimate the causal effects of one or more exposures or treatments on an outcome of interest, one has to account for the effect of "confounding factors" which both covary with the exposures or treatments and are independent predictors of the outcome. In this paper we present regression methods which, in contrast to standard methods, adjust for the confounding effect of multiple continuous or discrete covariates by modelling the conditional expectation of the exposures or treatments given the confounders. In the special case of a univariate dichotomous exposure or treatment, this conditional expectation is identical to what Rosenbaum and Rubin have called the propensity score. They have also proposed methods to estimate causal effects by modelling the propensity score. Our methods generalize those of Rosenbaum and Rubin in several ways. First, our approach straightforwardly allows for multivariate exposures or treatments, each of which may be continuous, ordinal, or discrete. Second, even in the case of a single dichotomous exposure, our approach does not require subclassification or matching on the propensity score so that the potential for "residual confounding," i.e., bias, due to incomplete matching is avoided. Third, our approach allows a rather general formalization of the idea that it is better to use the "estimated propensity score" than the true propensity score even when the true score is known. The additional power of our approach derives from the fact that we assume the causal effects of the exposures or treatments can be described by the parametric component of a semiparametric regression model. To illustrate our methods, we reanalyze the effect of current cigarette smoking on the level of forced expiratory volume in one second in a cohort of 2,713 adult white males. We compare the results with those obtained using standard methods.}},
    author = {Robins, J. M. and Mark, S. D. and Newey, W. K.},
    citeulike-article-id = {13866856},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Methods Papers]},
    issn = {0006-341X},
    journal = {Biometrics},
    keywords = {exportrecords, propensity-scores},
    number = {2},
    pages = {479--495},
    posted-at = {2015-12-09 01:04:58},
    priority = {3},
    title = {{Estimating exposure effects by modelling the expectation of exposure conditional on confounders}},
    volume = {48},
    year = {1992}
}

@article{12768,
    abstract = {{Stratification by a multivariate confounder score or by a propensity score has been proposed for the multi-confounder situations that are commonly encountered in epidemiologic evaluations of the effects of a treatment or a triage decision. However, the use of these scores in clinical research has been limited, perhaps in part because of the concern that the stated level of statistical significance may be exaggerated when there is a high degree of correlation between the exposure and the set of confounders. We present a specific example and computer simulations to suggest that exaggeration of statistical significance occurs only under unusual circumstances when the correlation between the exposure and the confounders is extreme. Our simulations also suggest that an analysis based on stratification by a propensity score is less affected by high correlation between the exposure and the confounders than is an analysis based on a multivariate confounder score.}},
    author = {Cook, E. F. and Goldman, L.},
    citeulike-article-id = {13866809},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0895-4356(89)90036-X},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Disease Risk Score Methods Papers]},
    doi = {10.1016/0895-4356(89)90036-X},
    issn = {0895-4356},
    journal = {Journal of Clinical Epidemiology},
    keywords = {exportrecords, propensity-scores, statistics},
    number = {4},
    pages = {317--324},
    posted-at = {2015-12-09 01:04:57},
    priority = {3},
    title = {{Performance of tests of significance based on stratification by a multivariate confounder score or by a propensity score}},
    url = {http://dx.doi.org/10.1016/0895-4356(89)90036-X},
    volume = {42},
    year = {1989}
}

@article{12710,
    abstract = {{In observational studies, investigators have no control over the treatment assignment. The treated and non-treated (that is, control) groups may have large differences on their observed covariates, and these differences can lead to biased estimates of treatment effects. Even traditional covariance analysis adjustments may be inadequate to eliminate this bias. The propensity score, defined as the conditional probability of being treated given the covariates, can be used to balance the covariates in the two groups, and therefore reduce this bias. In order to estimate the propensity score, one must model the distribution of the treatment indicator variable given the observed covariates. Once estimated the propensity score can be used to reduce bias through matching, stratification (subclassification), regression adjustment, or some combination of all three. In this tutorial we discuss the uses of propensity score methods for bias reduction, give references to the literature and illustrate the uses through applied examples.}},
    author = {D'Agostino},
    citeulike-article-id = {13866806},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/(SICI)1097-0258(19981015)17:19\%3C2265::AID-SIM918\%3E3.0.CO2-B},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm. [listed under Propensity Score Methods Papers]},
    doi = {10.1002/(SICI)1097-0258(19981015)17:19\%3C2265::AID-SIM918\%3E3.0.CO2-B},
    issn = {0277-6715},
    journal = {Statistics in Medicine},
    keywords = {bias---general, exportrecords, propensity-scores},
    number = {19},
    pages = {2265--2281},
    posted-at = {2015-12-09 01:04:57},
    priority = {3},
    title = {{Propensity score methods for bias reduction in the comparison of a treatment to a non-randomized control group}},
    url = {http://dx.doi.org/10.1002/(SICI)1097-0258(19981015)17:19\%3C2265::AID-SIM918\%3E3.0.CO2-B},
    volume = {17},
    year = {1998}
}

@article{23081,
    abstract = {{This paper compares the effect on trainee earnings of an employment program that was run as a field experiment where participants were randomly assigned to treatment and control groups with the estimates that would have been produced by an econometrician. This comparison shows that many of the econometric procedures do not replicate the experimentally determined results, and it suggests that researchers should be aware of the potential for specification errors in other nonexperimental evaluations.}},
    author = {LaLond, R. J.},
    citeulike-article-id = {13866742},
    isbn = {U13  - No},
    issn = {0002-8282},
    journal = {American Economic Review},
    keywords = {exportrecords, propensity-scores},
    number = {4},
    pages = {604--620},
    posted-at = {2015-12-09 01:04:55},
    priority = {3},
    title = {{Evaluating the Econometric Evaluations of Training Programs with Experimental Data}},
    volume = {76},
    year = {1986}
}

@article{12924,
    abstract = {{The propensity score is the conditional probability of exposure to a treatment given observed covariates. In a cohort study, matching or stratifying treated and control subjects on a single variable, the propensity score, tends to balance all of the observed covariates; however, unlike random assignment of treatments, the propensity score may not also balance unobserved covariates. The authors review the uses and limitations of propensity scores and provide a brief outline of associated statistical theory. They also present a new result of using propensity scores in case-cohort studies.}},
    author = {Joffe, M. M. and Rosenbaum, P. R.},
    citeulike-article-id = {13866362},
    comment = {Cited in:

Arbogast PG, Seeger JD, DEcIDE Methods Center Summary Variable Working Group. Summary Variables in Observational Research: Propensity Scores and Disease Risk Scores. Effective Health Care Program Research Report No. 33. (Prepared by DEcIDE Methods Center under Contract No. HHSA 290-2005-0016-I, Task Order 10.) AHRQ Publication No. 11(12)-EHC055-EF. Rockville, MD: Agency for Healthcare Research and Quality. May 2012. http://effectivehealthcare.ahrq.gov/reports/final.cfm.
[listed under Propensity Score Methods Papers]},
    issn = {0002-9262},
    journal = {American Journal of Epidemiology},
    keywords = {exportrecords, propensity-scores},
    number = {4},
    pages = {327--333},
    posted-at = {2015-12-09 01:04:46},
    priority = {3},
    title = {{Invited commentary: propensity scores}},
    volume = {150},
    year = {1999}
}

@article{Austin2014,
    abstract = {{Propensity-score matching is frequently used to estimate the effect of treatments, exposures, and interventions when using observational data. An important issue when using propensity-score matching is how to estimate the standard error of the estimated treatment effect. Accurate variance estimation permits construction of confidence intervals that have the advertised coverage rates and tests of statistical significance that have the correct type I error rates. There is disagreement in the literature as to how standard errors should be estimated. The bootstrap is a commonly used resampling method that permits estimation of the sampling variability of estimated parameters. Bootstrapmethods are rarely used in conjunction with propensity-score matching.We propose two different bootstrapmethods for use when using propensity-scorematching without replacement and examined their performance with a series of Monte Carlo simulations. The first method involved drawing bootstrap samples from the matched pairs in the propensity-score-matched sample. The second method involved drawing bootstrap samples from the original sample and estimating the propensity score separately in each bootstrap sample and creating a matched sample within each of these bootstrap samples. The former approach was found to result in estimates of the standard error that were closer to the empirical standard deviation of the sampling distribution of estimated effects.}},
    author = {Austin, Peter C. and Small, Dylan S.},
    citeulike-article-id = {13323453},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6276},
    doi = {10.1002/sim.6276},
    howpublished = {Published online},
    issn = {0277-6715},
    journal = {Statistics in Medicine},
    keywords = {bootstrap, propensity\_score},
    month = aug,
    pages = {n/a},
    posted-at = {2014-08-12 11:45:40},
    priority = {2},
    title = {{The use of bootstrapping when using propensity-score matching without replacement: a simulation study}},
    url = {http://dx.doi.org/10.1002/sim.6276},
    year = {2014}
}



@article{abadie:imbens:2008,
    abstract = {{Matching estimators are widely used in empirical economics for the evaluation of programs or treatments. Researchers using matching methods often apply the bootstrap to calculate the standard errors. However, no formal justification has been provided for the use of the bootstrap in this setting. In this article, we show that the standard bootstrap is, in general, not valid for matching estimators, even in the simple case with a single continuous covariate where the estimator is root-N consistent and asymptotically normally distributed with zero asymptotic bias. Valid inferential methods in this setting are the analytic asymptotic variance estimator of Abadie and Imbens (2006a) as well as certain modifications of the standard bootstrap, like the subsampling methods in Politis and Romano (1994).}},
    author = {Abadie, Alberto and Imbens, Guido W.},
    citeulike-article-id = {12571645},
    citeulike-linkout-0 = {http://dx.doi.org/10.3982/ecta6474},
    day = {1},
    doi = {10.3982/ecta6474},
    journal = {Econometrica},
    keywords = {bootstrap, causality, treatment\_effect},
    month = nov,
    number = {6},
    pages = {1537--1557},
    posted-at = {2013-08-16 17:08:10},
    priority = {2},
    publisher = {Blackwell Publishing Ltd},
    title = {{On the Failure of the Bootstrap for Matching Estimators}},
    url = {http://dx.doi.org/10.3982/ecta6474},
    volume = {76},
    year = {2008}
}

 
@techreport{NBERw15301,
 title = "Matching on the Estimated Propensity Score",
 author = "Alberto Abadie and Guido W. Imbens",
 institution = "National Bureau of Economic Research",
 type = "Working Paper",
 series = "Working Paper Series",
 number = "15301",
 year = "2009",
 month = "August",
 doi = {10.3386/w15301},
 URL = "http://www.nber.org/papers/w15301",
 abstract = {Propensity score matching estimators (Rosenbaum and Rubin, 1983) are widely used in evaluation research to estimate average treatment effects. In this article, we derive the large sample distribution of propensity score matching estimators. Our derivations take into account that the propensity score is itself estimated in a first step, prior to matching. We prove that first step estimation of the propensity score affects the large sample distribution of propensity score matching estimators. Moreover, we derive an adjustment to the large sample variance of propensity score matching estimators that corrects for first step estimation of the propensity score. In spite of the great popularity of propensity score matching estimators, these results were previously unavailable in the literature.},
}

@Article{AbadieImbens2006,
  author = 	 {Abadie, A. and Imbens, G. W.},
  title = 	 {Large Sample Properties of Matching Estimators for Average Treatment Effects},
  journal = 	 {Econometrica},
  year = 	 {2006},
  OPTkey = 	 {},
  volume = 	 {74},
  number = 	 {1},
  pages = 	 {235–267},
  month = 	 {Jan},
  DOI   =        {10.1111/j.1468-0262.2006.00655.x},
  OPTnote = 	 {},
  OPTannote = 	 {}
}

@book{whitehead1911introduction,
  title={AN INTRODUCTION TO MATHEMATICS},
  author={WHITEHEAD, A.N.},
  DOI={https://books.google.com/books?id=OrYg5Ql6ADkC},
  year={1911}
}
