% Generated by IEEEtran.bst, version: 1.12 (2007/01/11)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{rocSPARSE}
AMD, ``rocsparse,'' https://rocsparse.readthedocs.io/en/master/, 2020.

\bibitem{cuSPARSE}
NVIDIA, ``cusparse,'' https://developer.nvidia.com/cusparse, 2020.

\bibitem{PaoloG2020}
P.~D'Alberto, https://github.com/paolodalberto/SparseFastMM/, 2013.

\bibitem{chollet2015keras}
F.~Chollet \emph{et~al.}, ``Keras,'' \url{https://keras.io}, 2015.

\bibitem{PaoloK2020}
P.~D'Alberto, ``Block sparsity and training,''
  https://github.com/paolodalberto/BlockSparsityyTraning, 2020.

\bibitem{deng2009imagenet}
J.~Deng, W.~Dong, R.~Socher, L.-J. Li, K.~Li, and L.~Fei-Fei, ``Imagenet: A
  large-scale hierarchical image database,'' in \emph{2009 IEEE conference on
  computer vision and pattern recognition}.\hskip 1em plus 0.5em minus
  0.4em\relax Ieee, 2009, pp. 248--255.

\bibitem{pytorch_paper}
\BIBentryALTinterwordspacing
A.~Paszke, S.~Gross, F.~Massa, A.~Lerer, J.~Bradbury, G.~Chanan, T.~Killeen,
  Z.~Lin, N.~Gimelshein, L.~Antiga, A.~Desmaison, A.~Kopf, E.~Yang, Z.~DeVito,
  M.~Raison, A.~Tejani, S.~Chilamkurthy, B.~Steiner, L.~Fang, J.~Bai, and
  S.~Chintala, ``Pytorch: An imperative style, high-performance deep learning
  library,'' in \emph{Advances in Neural Information Processing Systems 32},
  H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett, Eds.\hskip 1em plus 0.5em minus
  0.4em\relax Curran Associates, Inc., 2019, pp. 8026--8037. [Online].
  Available:
  \url{http://papers.nips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
\BIBentrySTDinterwordspacing

\bibitem{yao2020adahessian}
Z.~Yao, A.~Gholami, S.~Shen, K.~Keutzer, and M.~W. Mahoney, ``Adahessian: An
  adaptive second order optimizer for machine learning,'' \emph{AAAI
  (Accepted)}, 2021.

\bibitem{abs-2101-08940}
\BIBentryALTinterwordspacing
S.~Yu, Z.~Yao, A.~Gholami, Z.~Dong, M.~W. Mahoney, and K.~Keutzer,
  ``Hessian-aware pruning and optimal neural implant,'' \emph{CoRR}, vol.
  abs/2101.08940, 2021. [Online]. Available:
  \url{https://arxiv.org/abs/2101.08940}
\BIBentrySTDinterwordspacing

\bibitem{zandonati2022fit}
B.~Zandonati, A.~A. Pol, M.~Pierini, O.~Sirkin, and T.~Kopetz, ``Fit: A metric
  for model sensitivity,'' 2022.

\bibitem{Caffe}
\BIBentryALTinterwordspacing
Y.~Jia, E.~Shelhamer, J.~Donahue, S.~Karayev, J.~Long, R.~Girshick,
  S.~Guadarrama, and T.~Darrell, ``Caffe: Convolutional architecture for fast
  feature embedding,'' in \emph{Proceedings of the 22nd ACM International
  Conference on Multimedia}, ser. MM '14.\hskip 1em plus 0.5em minus
  0.4em\relax New York, NY, USA: Association for Computing Machinery, 2014, p.
  675â€“678. [Online]. Available: \url{https://doi.org/10.1145/2647868.2654889}
\BIBentrySTDinterwordspacing

\bibitem{tensorflow}
\BIBentryALTinterwordspacing
{TensorFlow}. [Online]. Available: \url{https://www.tensorflow.org/}
\BIBentrySTDinterwordspacing

\bibitem{10.1145/3473334}
\BIBentryALTinterwordspacing
P.~D'Alberto, V.~Wu, A.~Ng, R.~Nimaiyar, E.~Delaye, and A.~Sirasao, ``Xdnn:
  Inference for deep convolutional neural networks,'' \emph{ACM Trans.
  Reconfigurable Technol. Syst.}, vol.~15, no.~2, jan 2022. [Online].
  Available: \url{https://doi.org/10.1145/3473334}
\BIBentrySTDinterwordspacing

\bibitem{abs-2110-04327}
\BIBentryALTinterwordspacing
P.~D'Alberto, J.~Ma, J.~Li, Y.~Hu, M.~Bollavaram, and S.~Fang, ``{DPUV3INT8:}
  {A} compiler view to programmable {FPGA} inference engines,'' \emph{CoRR},
  vol. abs/2110.04327, 2021. [Online]. Available:
  \url{https://arxiv.org/abs/2110.04327}
\BIBentrySTDinterwordspacing

\bibitem{frantar2023gptq}
E.~Frantar, S.~Ashkboos, T.~Hoefler, and D.~Alistarh, ``Gptq: Accurate
  post-training quantization for generative pre-trained transformers,'' 2023.

\bibitem{abs-2102-11289}
\BIBentryALTinterwordspacing
B.~Hawks, J.~M. Duarte, N.~J. Fraser, A.~Pappalardo, N.~Tran, and Y.~Umuroglu,
  ``Ps and qs: Quantization-aware pruning for efficient low latency neural
  network inference,'' \emph{CoRR}, vol. abs/2102.11289, 2021. [Online].
  Available: \url{https://arxiv.org/abs/2102.11289}
\BIBentrySTDinterwordspacing

\bibitem{ahmad2019dense}
S.~Ahmad and L.~Scheinkman, ``How can we be so dense? the benefits of using
  highly sparse representations,'' 2019.

\bibitem{Huang2021CoSASB}
\BIBentryALTinterwordspacing
Q.~Huang, M.~Kang, G.~Dinh, T.~Norell, A.~Kalaiah, J.~Demmel, J.~Wawrzynek, and
  Y.~S. Shao, ``Cosa: Scheduling by constrained optimization for spatial
  accelerators,'' \emph{2021 ACM/IEEE 48th Annual International Symposium on
  Computer Architecture (ISCA)}, pp. 554--566, 2021. [Online]. Available:
  \url{https://api.semanticscholar.org/CorpusID:233740109}
\BIBentrySTDinterwordspacing

\bibitem{Russo2023MemoryAwareDA}
\BIBentryALTinterwordspacing
E.~Russo, M.~Palesi, G.~Ascia, D.~Patti, S.~Monteleone, and V.~Catania,
  ``Memory-aware dnn algorithm-hardware mapping via integer linear
  programming,'' \emph{Proceedings of the 20th ACM International Conference on
  Computing Frontiers}, 2023. [Online]. Available:
  \url{https://api.semanticscholar.org/CorpusID:260442361}
\BIBentrySTDinterwordspacing

\bibitem{Cai2023InterlayerSS}
\BIBentryALTinterwordspacing
J.~Cai, Y.~Wei, Z.~Wu, S.~Peng, and K.~Ma, ``Inter-layer scheduling space
  definition and exploration for tiled accelerators,'' \emph{Proceedings of the
  50th Annual International Symposium on Computer Architecture}, 2023.
  [Online]. Available: \url{https://api.semanticscholar.org/CorpusID:259177591}
\BIBentrySTDinterwordspacing

\end{thebibliography}
